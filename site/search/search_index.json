{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Om NADA","text":"<p>NADA er et plattformteam med ansvar for KNADA, Datamarkedsplassen og Metabase.</p> <p>KNADA er en plattform som tilbyr verkt\u00f8y for \u00e5 lese data fra kilder i sky og onprem f\u00f8r bearbeiding av data, enten i form av analyse eller transformasjon og deling av data. Dataprodukter p\u00e5 markedsplassen kan analyseres i notebook og Metabase. Innsikten kan deles som datafortellinger eller som Metabase-dashboard.</p> <p>P\u00e5 Datamarkedsplassen kan team registrere egne og finne andres dataprodukter og datasett samt datafortellinger. Metabase-dashboard kan ogs\u00e5 deles direkte p\u00e5 Datamarkedsplassen.</p>"},{"location":"#kontakt-oss","title":"Kontakt oss","text":"<ul> <li>Slack (#nada)</li> <li>Brukerforum: Annonseres p\u00e5 slack</li> <li>Kurs: Annonseres p\u00e5 Delta</li> <li>E-post (for eksterne): post.nada@nav.no</li> </ul> <p>Tilgjengelighetserkl\u00e6ringen.</p>"},{"location":"ordliste/","title":"Ordliste","text":""},{"location":"ordliste/#datamarkedsplassen","title":"Datamarkedsplassen","text":"<p>Datamarkedsplassen er v\u00e5rt finn.no, der produsenter viser og forvalter data og innsikt, mens konsumenter finner og ber om tilgang til data.</p>"},{"location":"ordliste/#bigquery","title":"BigQuery","text":"<p>BigQuery er en database hostet av Google som er tilgjengelig for team p\u00e5 GCP. BigQuery-tabeller/views kan brukes som datasett.</p>"},{"location":"ordliste/#datafortellinger","title":"Datafortellinger","text":"<p>Datafortellinger er analyser med en \"r\u00f8d tr\u00e5d\". Tidligere har dette v\u00e6rt implementert gjennom v\u00e5rt egenutviklede Datastory. Fra n\u00e5 er det Quarto som gjelder.</p>"},{"location":"ordliste/#dataprodukt","title":"Dataprodukt","text":"<p>Et dataprodukt er en samling av ett eller flere datasett som teamet mener h\u00f8rer sammen. Dataproduktet inneholder en overordnet beskrivelse og har en eier med et tilh\u00f8rende kontaktpunkt.</p>"},{"location":"ordliste/#datasett","title":"Datasett","text":"<p>Et datasett er en del av et dataprodukt. Det best\u00e5r av data, metadata og kode. Data er i dag tilgjengelig i form av views/tabeller p\u00e5 BigQuery.</p>"},{"location":"ordliste/#metabase","title":"Metabase","text":"<p>Metabase er et dashboard-verkt\u00f8y integrert med datasettene p\u00e5 Datamarkedsplassen.</p>"},{"location":"ordliste/#knada","title":"KNADA","text":"<p>KNADA er en kodebasert analyseplattform bygd p\u00e5 Kubernetes i GCP der vi tilbyr Jupyter notebook, Airflow, og KnadaVM. KNADA tilbyr \u00e5pning mot on-prem FSS, som gj\u00f8r det mulig \u00e5 kombinere med data i sky.</p>"},{"location":"ordliste/#airflow","title":"Airflow","text":"<p>Airflow er et orkestreringsverkt\u00f8y for \u00e5 kj\u00f8re jobber. Brukes i dag b\u00e5de til \u00e5 skedulere enkle jobber og til \u00e5 h\u00e5ndtere mer komplekse jobber med avhengigheter. Brukes b\u00e5de av data scientister og data engineers i datavarehus.</p>"},{"location":"ordliste/#jupyter-notebook","title":"Jupyter notebook","text":"<p>Jupyter notebook er et webbasert utviklerverkt\u00f8y for \u00e5 drive med kodebasert utforsking av data i on-prem eller sky. St\u00f8tter Python. Gj\u00f8r det enkelt \u00e5 kj\u00f8re mindre bolker av kode og visualisere resultater i nettleseren.</p>"},{"location":"ordliste/#knada-vm","title":"KNADA VM","text":"<p>Vi tilbyr private virtuelle maskiner gjennom Knorten, disse kj\u00f8rer i GCP prosjektet knada-gcp. Denne maskinen vil ha tilgang til on-premise kilder p\u00e5 lik linje som Notebooks og Airflow som kj\u00f8rer i Les mer om \u00e5 komme i gang under Analyse/KNADA VM.</p>"},{"location":"ordliste/#knorten","title":"Knorten","text":"<p>Knorten er portalen for \u00e5 administrere team som bruker KNADA. Her er det self-service av blant annet  Airflow og Jupyter. Les mer om \u00e5 komme i gang under Analyse/Kom i gang.</p>"},{"location":"analyse/allowlisting/","title":"Allowlisting av trafikk","text":"<p>Vi krever at eksplisitt spesifiserer hvilke eksterne tjenester man skal kommunisere med per tjeneste man bruker i Knada. \u00c5pninger er basert p\u00e5 IP-adresser eller DNS (nettadresser), samt porten for den hosten de \u00f8nsker \u00e5 \u00e5pne mot.</p> <p>Du angir hostene du har lyst til \u00e5 allowliste p\u00e5 formatet <code>&lt;ip-adresse&gt;</code>:<code>&lt;port&gt;</code>. Dersom port utelates vil vi bruke <code>443</code> som standardport.</p> <p>Eksempler:</p> <ul> <li>35.235.240.1:3307</li> <li>oracle.db.no:1521</li> <li>google.com</li> </ul> <p>For \u00e5 konfigurere allowlist for Jupyterhub se Trafikk fra notebooks. For \u00e5 konfigurere allowlist for Airflow se Trafikk ut fra Airflow.</p>"},{"location":"analyse/allowlisting/#standardapninger-for-jupyterhub","title":"Standard\u00e5pninger for Jupyterhub","text":"<ul> <li><code>*.googleapis.com</code>(for Secret manager, Storage buckets, BigQuery etc.)</li> <li><code>github.com</code> (for lesing av repo med kode)</li> <li><code>europe-north1-python.pkg.dev</code> (pypi proxy for installasjon av pakker)</li> </ul>"},{"location":"analyse/allowlisting/#standardapninger-for-airflow","title":"Standard\u00e5pninger for Airflow","text":"<ul> <li><code>*.googleapis.com</code> (for Secret manager, Storage buckets, BigQuery etc.)</li> <li><code>github.com</code> (for lesing av repo med kode)</li> </ul> <p>Dersom man bruker dataverk-airflow vil det avhengig av hvilken operator og opsjoner man bruker ogs\u00e5 bli lagt p\u00e5 n\u00f8dvendige \u00e5pninger. Se repo for dokumentasjon p\u00e5 hva som settes for ulike operatorer.</p>"},{"location":"analyse/allowlisting/#standardapninger-for-knadavm","title":"Standard\u00e5pninger for KnadaVM","text":"<ul> <li><code>private.googleapis.com</code> (for Secret manager, Storage buckets, BigQuery etc.)</li> <li>Cloudflare (for Quarto)</li> <li>Fastly CDN (for Pypi)</li> <li>SSH mot Github.com</li> <li>Knada CoreDNS</li> <li>Alle onprem kilder som er tilgjengelig fra Knada</li> </ul> <p>Komplett oversikt finner man i navikt/knada-gcp.</p>"},{"location":"analyse/allowlisting/#gcp-cloudsql-postgres","title":"GCP CloudSQL Postgres","text":"<p>For \u00e5 f\u00e5 tilgang til en CloudSQL Postgres database p\u00e5 GCP kreves det \u00e5pning mot den offentlige IP adressen til databaseinstansen. Den offentlige adressen for en database finner du i Cloud console. Finn database instansen din i listen, og finn adressen under <code>Public IP address</code>.</p> <p>For CloudSQL Postgres databaser er det n\u00f8dvendig \u00e5 \u00e5pne b\u00e5de port <code>443</code> og <code>3307</code>. Du m\u00e5 dermed legge til to separate innslag for dette:</p> <ul> <li><code>&lt;ip&gt;:3307</code></li> <li><code>&lt;ip&gt;:443</code></li> </ul>"},{"location":"analyse/allowlisting/#teknisk-lsning","title":"Teknisk l\u00f8sning","text":"<p>I Kubernetes bruker vi Network Policies for \u00e5 styre trafikken inn og ut til pods (les: apper). Ved \u00e5 spesifisere annotasjonen <code>allowlist</code> p\u00e5 en pod s\u00e5 vil tjenesten Knep lage <code>NetworkPolicy</code> basert p\u00e5 listen av <code>host:port</code>.</p>"},{"location":"analyse/datafortellinger/","title":"Datafortelling","text":"<p>Datafortellinger brukes til \u00e5 dele innsikt i form av statiske dokumenter. Datafortellinger kan enkelt deles med andre i NAV gjennom Datamarkedsplassen.</p>"},{"location":"analyse/datafortellinger/#installere-quarto","title":"Installere Quarto","text":""},{"location":"analyse/datafortellinger/#lokal-maskin","title":"Lokal maskin","text":"<p>F\u00f8lge installasjonsoppskriften p\u00e5 quarto.org/docs. Husk \u00e5 hold Quarto oppdatert.</p>"},{"location":"analyse/datafortellinger/#knast","title":"Knast","text":"<p>Vi anbefaler \u00e5 f\u00f8lge guiden Tarball Installation On Linux. For \u00e5 laste ned bin\u00e6ren trenger du f\u00f8lgende \u00e5pninger: - github.com/quarto-dev/quarto-cli/releases/download/ - objects.githubusercontent.com/</p> <p>Igjen m\u00e5 man selv huske \u00e5 holde Quarto oppdatert.</p>"},{"location":"analyse/datafortellinger/#docker-image","title":"Docker image","text":"<p>Vi anbefaler \u00e5 bruke kommandoen nedenfor i din <code>Dockerfile</code> for \u00e5 installere Quarto. Denne vil hente ned siste versjon av Quarto hver gang Docker-imaget blir bygd.</p> <pre><code># jq, wget, og tar m\u00e5 v\u00e6re installert for at kommandoen nedenfor skal fungere\nRUN cd /app &amp;&amp; \\\n    QUARTO_VERSION=$(curl https://api.github.com/repos/quarto-dev/quarto-cli/releases/latest | jq '.tag_name' | sed -e 's/[\\\"v]//g') &amp;&amp; \\\n    wget https://github.com/quarto-dev/quarto-cli/releases/download/v${QUARTO_VERSION}/quarto-${QUARTO_VERSION}-linux-amd64.tar.gz &amp;&amp; \\\n    tar -zxvf quarto-${QUARTO_VERSION}-linux-amd64.tar.gz &amp;&amp; \\\n    mv /app/quarto-${QUARTO_VERSION} /app/quarto\nENV PATH=\"${PATH}:/app/quarto/bin\"\n</code></pre>"},{"location":"analyse/datafortellinger/#team-tokens","title":"Team tokens","text":"<p>For \u00e5 programmatisk lage eller oppdatere datafortellinger trenger man \u00e5 autentisere seg med et team token. For \u00e5 finne team token for teamene du er medlem av kan du g\u00e5 til Mine team tokens i Datamarkedsplassen (krever innlogging). Det er forskjellig tokens for dev og prod, s\u00e5 dersom du \u00f8nsker \u00e5 lage eller oppdatere en datafortelling i dev finner du tokens i dev versjonen av Datamarkedsplassen. Samme token brukes b\u00e5de for intern og ekstern publisering av datafortellinger.</p>"},{"location":"analyse/datafortellinger/#rotere-token","title":"Rotere token","text":"<p>Dersom du har behov for \u00e5 rotere team tokenet til et av teamene dine (f.eks. dersom du har eksponert tokenet ved et uhell) kan dette gj\u00f8res fra Mine team tokens i Datamarkedsplassen.</p>"},{"location":"analyse/datafortellinger/#lage-datafortelling","title":"Lage Datafortelling","text":"<p>Man kan publisere datafortellinger enten internt for NAV ansatte eller eksternt.</p>"},{"location":"analyse/datafortellinger/#internt","title":"Internt","text":"<p>For datafortellinger som kun skal v\u00e6re tilgjengelig for ansatte i NAV kan kan man publisere denne til den interne datamarkedsplassen.</p> <p>I eksemplene som f\u00f8lger m\u00e5 f\u00f8lgende byttes ut med reelle verdier:</p> <ul> <li><code>${ENV}</code> <ul> <li>For <code>knada</code> VMer og jupyter notebooks/airflow i <code>knada-clusteret</code> settes dette til datamarkedsplassen.intern.dev.nav.no for dev og datamarkedsplassen.intern.nav.no for prod</li> <li>Ellers settes det til data.ekstern.dev.nav.no for dev og data.nav.no for prod</li> </ul> </li> <li><code>${STORY_ID}</code> - erstatt med ID p\u00e5 datafortellingen</li> <li><code>${TEAM_TOKEN}</code> - erstatt med team-token fra Datamarkedsplassen</li> <li><code>${TEAM_ID}</code> - erstatt med team ID for teamet ditt i teamkatalogen</li> </ul> <p>Se Get Started p\u00e5 Quarto sine sider for \u00e5 komme i gang med utvikling av datafortellingen.</p>"},{"location":"analyse/datafortellinger/#registrere-quarto-i-datamarkedsplassen","title":"Registrere Quarto i Datamarkedsplassen","text":"<p>N\u00e5r man skal registrere en quarto datafortelling i Datamarkedsplassen kan man enten gj\u00f8re dette gjennom brukergrensesnittet eller programmatisk.</p>"},{"location":"analyse/datafortellinger/#registrer-gjennom-brukergrensesnitt","title":"Registrer gjennom brukergrensesnitt","text":"<ol> <li>G\u00e5 til data.ansatt.nav.no for prod eller data.intern.dev.nav.no for dev.</li> <li>Logg inn</li> <li>Klikk hamburgermeny og velg <code>Legg til ny datafortelling</code></li> <li>Fyll inn metadata om datafortellingen</li> <li>Velg fil(er) du \u00f8nsker \u00e5 laste opp</li> <li>Trykk <code>Lagre</code></li> </ol> <p>Dersom du kun \u00f8nsker \u00e5 registere en tom datafortelling som siden skal oppdateres programmatisk kan man droppe steg (5) over</p>"},{"location":"analyse/datafortellinger/#registrer-programmatisk","title":"Registrer programmatisk","text":"<p>Du kan ogs\u00e5 programmatisk registrere en datafortelling.</p> <p>Request body parametere:</p> <ul> <li><code>name</code> (obligatrisk): Navn p\u00e5 datafortellingen</li> <li><code>description</code>: Beskrivelse av datafortellingen</li> <li><code>teamID</code>: ID i teamkatalogen for teamet som eier datafortellingen. N\u00f8dvendig \u00e5 spesifisere dersom datafortellingen skal sorteres riktig i produktomr\u00e5devisningen p\u00e5 data.ansatt.nav.no</li> <li><code>id</code>: Kan spesifiseres dersom du \u00f8nsker \u00e5 spesifisere ID for datafortellingen selv. Dersom den utelates genereres det en ny.</li> </ul> <p>Headers for requesten</p> <ul> <li><code>bearer token</code> (obligatorisk): Team tokenet for teamet som skal eie datafortellingen</li> </ul> <p>Merk: IDen for datafortellingen blir returnert n\u00e5r man gj\u00f8r en POST til <code>/quarto/create</code>. Denne m\u00e5 s\u00e5 brukes n\u00e5r datafortellingen skal oppdateres etterp\u00e5.</p>"},{"location":"analyse/datafortellinger/#med-curl","title":"Med curl","text":"<pre><code>$ curl -X POST \\\n    -d '{\"name\": \"min datafortelling\", \"description\": \"min beskrivelse\", \"teamID\": \"&lt;team-id&gt;\", \"id\": \"${STORY_ID}\"}' \\\n    -H \"Authorization: Bearer ${TEAM_TOKEN}\" \\\n    https://${ENV}/quarto/create\n</code></pre>"},{"location":"analyse/datafortellinger/#med-python","title":"Med python","text":"<pre><code>import requests\n\nres = requests.post(f\"https://${ENV}/quarto/create\", headers={\"Authorization\": \"bearer ${TEAM_TOKEN}\"}, json={\n    \"name\": \"min quarto\",\n    \"description\": \"min beskrivelse\",\n    \"teamID\": \"&lt;team-id&gt;\",\n    \"id\": \"${STORY_ID}\"\n})\n\nstory_id = res.json()[\"id\"]\n</code></pre>"},{"location":"analyse/datafortellinger/#oppdater-eksisterende-intern-datafortelling","title":"Oppdater eksisterende intern datafortelling","text":"<p>For \u00e5 oppdatere en eksisterende Quarto fortelling m\u00e5 man f\u00f8rst generere ressursfilene p\u00e5 nytt med <code>quarto render &lt;file&gt;</code>.</p> <p>Deretter m\u00e5 man hente ut ID for Quartoen man \u00f8nsker \u00e5 oppdatere og team-tokenet fra Datamarkedsplassen.</p> <p>Eksemplene tar utgangspunkt i at det er filen <code>index.html</code> som skal lastes opp og at man kj\u00f8rer kommandoene fra samme mappe som filen ligger.</p>"},{"location":"analyse/datafortellinger/#med-curl_1","title":"Med curl","text":"<pre><code>curl -X PUT -F index.html=@index.html \\\n    \"https://${ENV}/quarto/update/${QUARTO_ID}\" \\\n    -H \"Authorization:Bearer ${TEAM_TOKEN}\"\n</code></pre>"},{"location":"analyse/datafortellinger/#flere-filer","title":"Flere filer","text":"<pre><code>#!/bin/bash\nset -e\n\nFILES=\"\"\nfor file in &lt;mappe med filene&gt;/*\ndo\n  FILES+=\" -F $file=@$file\"\ndone\n\ncurl -X PUT $FILES \"https://${ENV}/quarto/update/${QUARTO_ID}\" \\\n    -H \"Authorization:Bearer ${TEAM_TOKEN}\"\n</code></pre>"},{"location":"analyse/datafortellinger/#med-python_1","title":"Med python","text":"<pre><code>import os\nimport requests\n\n# A list of file paths to be uploaded\nfiles_to_upload = [\n    \"PATH/index.html\"\n    \"PATH/SUB/FOLDER/some.html\"\n]\n\nmultipart_form_data = {}\nfor file_path in files_to_upload:\n    file_name = os.path.basename(file_path)\n    with open(file_path, 'rb') as file:\n        # Read the file contents and store them in the dictionary\n        file_contents = file.read()\n        multipart_form_data[file_name] = (file_name, file_contents)\n\n# Send the request with all files in the dictionary\nresponse = requests.put( f\"https://{ENV}/quarto/update/{QUARTO_ID}\", \n                        headers={\"Authorization\": f\"Bearer {TEAM_TOKEN}\"},\n                        files=multipart_form_data)\nresponse.raise_for_status()\n</code></pre>"},{"location":"analyse/datafortellinger/#oppdatere-quarto-med-naisjob","title":"Oppdatere Quarto med Naisjob","text":"<p>For \u00e5 produksjonsette oppdatering av en Quarto Datafortelling med Naisjob er det noe konfigurasjon man m\u00e5 spesifisere i NAIS manifestet og Dockerfilen til jobben.</p> <ul> <li><code>quarto render</code> resulterer i at det genereres noen filer som m\u00e5 lagres midlertidig i containermilj\u00f8et f\u00f8r publisering til Datamarkedsplassen. Man er derfor n\u00f8dt til \u00e5 legge til annotasjon i Naisjob manifestet for \u00e5 tillate skriving til filsystemet i containeren <pre><code>metadata:\n  annotations:\n    nais.io/read-only-file-system: \"false\"\n</code></pre></li> <li>All utg\u00e5ende trafikk fra Naisjobben vil by default stoppes, s\u00e5 man m\u00e5 legge til en outbound access policy til Markedsplass hosten man skal publisere til (dev/prod) <pre><code>spec:\n  accessPolicy:\n    outbound:\n      external:\n        - host: data.ekstern.dev.nav.no # for dev\n        - host: data.nav.no # for prod\n</code></pre></li> <li>I Dockerfilen m\u00e5 man lage en bruker med userid 1069 \u00e5 velge denne brukeren <pre><code>RUN groupadd -g 1069 python &amp;&amp; \\\n    useradd -r -u 1069 -g python python\n\nUSER python\n</code></pre></li> </ul> <p>Repoet navikt/nada-quarto har et fullstendig eksempel n\u00f8dvendig oppsett, se spesielt</p> <ul> <li>Naisjob manifest</li> <li>Dockerfile</li> <li>Publiseringsskript</li> <li>N\u00f8dvendige python biblioteker som m\u00e5 installeres</li> </ul> <p>I eksempelet hentes team-tokenet fra en kubernetes secret i clusteret og settes som milj\u00f8variabelen <code>NADA_TOKEN</code>.</p>"},{"location":"analyse/datafortellinger/#andre-eksempler-med-naisjob","title":"Andre eksempler med Naisjob","text":"<ul> <li>fia: Mer avansert eksempel med produksjonssatt datafortelling</li> </ul>"},{"location":"analyse/datafortellinger/#eksternt","title":"Eksternt","text":"<p>F\u00f8lgende beskriver hvordan man kan publisere datafortellinger eksternt p\u00e5 <code>data.nav.no</code>.</p> <p>For eksempler p\u00e5 datafortellinger publisert eksternt, se:</p> <ul> <li>NAVs omverdensanalyse 2023\u20132035 <ul> <li>repo: navikt/oma_2023</li> </ul> </li> <li>Utviklingstrekk i Folketrygden<ul> <li>repo: navikt/Utviklingstrekk</li> </ul> </li> <li>Veileder for generativ kunstig intelligens<ul> <li>repo: navikt/GKI-veil-bakgrunn</li> </ul> </li> </ul> <p>I eksemplene som f\u00f8lger m\u00e5 f\u00f8lgende byttes ut med reelle verdier:</p> <ul> <li><code>${ENV}</code> <ul> <li>data.ekstern.dev.nav.no for dev og data.nav.no for prod</li> </ul> </li> <li><code>${STORY_ID}</code> - erstatt med ID p\u00e5 datafortellingen</li> <li><code>${TEAM_TOKEN}</code> - erstatt med team-token fra Datamarkedsplassen</li> </ul>"},{"location":"analyse/datafortellinger/#registere-ekstern-datafortelling","title":"Registere ekstern datafortelling","text":"<p>Vi st\u00f8tter forel\u00f8pig kun programmatisk registrering av eksterne datafortellinger.</p> <p>Request body parametere:</p> <ul> <li><code>title</code>: Navn p\u00e5 datafortellingen</li> <li><code>slug</code>: Dersom du selv \u00f8nsker \u00e5 bestemme <code>slug</code> i URLen til datafortellingen</li> <li><code>team</code>: Navn p\u00e5 teamet som eier datafortellingen. Dette tilsvarer navnet som gjelder for tokenet du henter fra https://data.ansatt.nav.no/user/tokens (eventuelt https://data.intern.dev.nav.no/user/tokens for dev)</li> <li><code>published</code>: Dette flagget indikerer om datafortellingen skal listes opp p\u00e5 index siden til <code>data.nav.no</code>.</li> </ul> <p>Dersom en ikke oppgir verken <code>title</code> eller <code>slug</code> n\u00e5r datafortellingen registreres s\u00e5 vil det v\u00e6re den genererte UUIDen til datafortellingen som vil brukes for URLen til datafortellingen.</p> <p>Headers for requesten</p> <ul> <li><code>bearer token</code> (obligatorisk): Team tokenet for teamet som skal eie datafortellingen</li> </ul> <p>Merk: IDen for den genererte datafortellingen blir returnert n\u00e5r man gj\u00f8r en POST til <code>/api/v1/story</code>. Denne m\u00e5 s\u00e5 brukes n\u00e5r datafortellingen skal oppdateres senere.</p>"},{"location":"analyse/datafortellinger/#med-curl_2","title":"Med curl","text":"<pre><code>$ curl -X POST \\\n    -d '{\"title\": \"Min datafortelling om noe\", \"slug\": \"min-datafortelling\", \"team\": \"&lt;team-navn&gt;\"}' \\\n    -H \"Authorization: Bearer ${TEAM_TOKEN}\" \\\n    https://${ENV}/api/v1/story\n</code></pre>"},{"location":"analyse/datafortellinger/#med-python_2","title":"Med python","text":"<pre><code>import requests\n\nres = requests.post(f\"https://${ENV}/api/v1/story\", headers={\"Authorization\": \"bearer ${TEAM_TOKEN}\"}, json={\n    \"title\": \"Min datafortelling om noe\",\n    \"slug\": \"min-datafortelling\",\n    \"team\": \"&lt;team-navn&gt;\"\n})\n\nstory_id = res.json()[\"id\"]\n</code></pre>"},{"location":"analyse/datafortellinger/#oppdatere-en-ekstern-datafortelling","title":"Oppdatere en ekstern datafortelling","text":""},{"location":"analyse/datafortellinger/#med-curl_3","title":"Med curl","text":"<pre><code>curl -X PUT -F index.html=@index.html \\\n    \"https://${ENV}/api/v1/story/${STORY_ID}\" \\\n    -H \"Authorization:Bearer ${TEAM_TOKEN}\"\n</code></pre>"},{"location":"analyse/datafortellinger/#flere-filer_1","title":"Flere filer","text":"<pre><code>#!/bin/bash\nset -e\n\nFILES=\"\"\nfor file in &lt;mappe med filene&gt;/*\ndo\n  FILES+=\" -F $file=@$file\"\ndone\n\ncurl -X PUT $FILES \"https://${ENV}/api/v1/story/${STORY_ID}\" \\\n    -H \"Authorization:Bearer ${TEAM_TOKEN}\"\n</code></pre>"},{"location":"analyse/datafortellinger/#med-python_3","title":"Med python","text":"<pre><code>import os\nimport requests\n\n# A list of file paths to be uploaded\nfiles_to_upload = [\n    \"PATH/index.html\"\n    \"PATH/SUB/FOLDER/some.html\"\n]\n\nmultipart_form_data = {}\nfor file_path in files_to_upload:\n    file_name = os.path.basename(file_path)\n    with open(file_path, 'rb') as file:\n        # Read the file contents and store them in the dictionary\n        file_contents = file.read()\n        multipart_form_data[file_name] = (file_name, file_contents)\n\n# Send the request with all files in the dictionary\nresponse = requests.put( f\"https://{ENV}/api/v1/story/{STORY_ID}\", \n                        headers={\"Authorization\": f\"Bearer {TEAM_TOKEN}\"},\n                        files=multipart_form_data)\nresponse.raise_for_status()\n</code></pre>"},{"location":"analyse/datafortellinger/#oppdatere-datafortelling-med-github-action","title":"Oppdatere datafortelling med GitHub action","text":"<p>Vi har laget en egen GitHub action - navikt/story-upload - som kan brukes dersom man \u00f8nsker \u00e5 lagre datafortellingen sin i et GitHub repo.  Denne actionen vil publisere innholdet til en gcs bucket som NADA hoster datafortellinger fra.  Man kan bruke actionen til \u00e5 publisere b\u00e5de interne datafortellinger p\u00e5 <code>data.ansatt.nav.no</code> og eksterne datafortellinger p\u00e5 <code>data.nav.no</code>.</p> <p>Se README for github action for beskrivelse av de ulike konfigurerbare input parameterene til actionen</p> <p>Under er et eksempel p\u00e5 hvordan \u00e5 sette opp en enkel github action workflow som oppdaterer en datafortelling internt i dev l\u00f8sningen til datamarkedsplassen (dvs. <code>data.intern.dev.nav.no</code>) ved hver push til <code>main</code>. For \u00e5 bruke actionen m\u00e5 det eksistere en datafortelling som man \u00f8nsker \u00e5 oppdatere. Dersom det ikke finnes en datafortelling s\u00e5 m\u00e5 denne registeres f\u00f8rst, se her for \u00e5 registrere en intern datafortelling, eller her for \u00e5 registrere en ekstern. </p> <p>Erstatt <code>${STORY_ID}</code> i eksempelet med IDen p\u00e5 datafortellingen du \u00f8nsker \u00e5 oppdatere. Eksempelet tar ogs\u00e5 utgangspunkt i at team tokenet for teamet som eier datafortellingen er lagt inn som secret p\u00e5 github repoet med n\u00f8kkel <code>TEAM_TOKEN</code>.  Token for teamet ditt finner du ved \u00e5 g\u00e5 til https://data.ansatt.nav.no/user/tokens (eventuelt https://data.intern.dev.nav.no/user/tokens for dev).</p> <pre><code>name: Eksempel p\u00e5 opplasting av datafortelling\n\non: \n  push:\n    branches:\n      - main\n\njobs:\n  oppdater-datafortelling:\n    name: Oppdater datafortelling\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: navikt/story-upload@v1\n        with:\n          id: ${STORY_ID}\n          dir: src\n          team_token: ${{ secrets.TEAM_TOKEN }}\n          env: dev\n          public: \"false\"\n</code></pre>"},{"location":"analyse/datafortellinger/#knatch","title":"Knatch","text":"<p>Knatch - Knada batch - er et kommandolinjeverkt\u00f8y tiltenkt \u00e5 forenkle opplasting av datafortellinger til b\u00e5de den interne datamarkedsplassen og eksterne datafortellinger p\u00e5 <code>data.nav.no</code>.</p> <p>Det er s\u00e6rlig nyttig i tilfeller hvor en \u00f8nsker \u00e5 laste opp datafortellinger som best\u00e5r av flere filer da <code>knatch</code> tar som inputargument en mappe og vil automatisk dele opp filene i mappen og laste de opp i batcher til datamarkedsplassen. St\u00f8rrelsen p\u00e5 batchene kan du spesifisere med flagget <code>--batch-size</code>, dersom det utelates vil datafortellingen lastes opp i batcher p\u00e5 10 filer.</p>"},{"location":"analyse/datafortellinger/#installasjon","title":"Installasjon","text":"<pre><code>pip install knatch\n</code></pre>"},{"location":"analyse/datafortellinger/#eksempler-pa-bruk","title":"Eksempler p\u00e5 bruk","text":"<p><code>Knatch</code> kan brukes til \u00e5 oppdatere en datafortelling b\u00e5de internt i NAV og eksternt.</p> <p>Begge eksemplene tar utgangspunkt i f\u00f8lgende:</p> <ul> <li>Du har allerede opprettet en datafortelling du \u00f8nsker \u00e5 oppdatere, se her for \u00e5 registrere en intern datafortelling, eller her for \u00e5 registrere en ekstern. Erstatt <code>&lt;id&gt;</code> i eksemplene under med IDen til den eksisterende datafortellingen.</li> <li>Du har hentet ut team tokenet for teamet som eier datafortellingen. Erstatt <code>&lt;token&gt;</code> i eksemplene under med dette tokenet.</li> </ul>"},{"location":"analyse/datafortellinger/#publisering-til-intern-markedsplass","title":"Publisering til intern markedsplass","text":"<p>I eksempelet under publiseres det til dev-l\u00f8singen til den interne datamarkedsplassen (<code>datamarkedsplassen.intern.dev.nav.no</code>). Dersom en i stedet \u00f8nsker \u00e5 publisere til prod s\u00e5 m\u00e5 <code>--host</code> flagget settes til <code>datamarkedsplassen.intern.nav.no</code>.</p> <pre><code>knatch &lt;id&gt; sti/til/mappe/med/filer &lt;token&gt; --host datamarkedsplassen.intern.dev.nav.no\n</code></pre>"},{"location":"analyse/datafortellinger/#publisering-eksternt","title":"Publisering eksternt","text":"<p>I eksempelet under publiseres det til dev-l\u00f8singen for ekstern publisering (<code>data.ekstern.dev.nav.no</code>). Dersom en i stedet \u00f8nsker \u00e5 publisere til prod s\u00e5 m\u00e5 <code>--host</code> flagget settes til <code>data.nav.no</code>.</p> <pre><code>knatch &lt;id&gt; sti/til/mappe/med/filer &lt;token&gt; --host data.ekstern.dev.nav.no --path api/v1/story\n</code></pre>"},{"location":"analyse/eksempler/","title":"Kodeeksempler","text":""},{"location":"analyse/eksempler/#python","title":"Python","text":""},{"location":"analyse/eksempler/#cloud-sql-iam-database-authentication","title":"Cloud SQL IAM Database authentication","text":"<p>For \u00e5 slippe \u00e5 opprette og bruke builtin users i sql databaser p\u00e5 GCP b\u00f8r man i stedet bruke Cloud SQL IAM database authentication n\u00e5r man skal koble seg til Cloud SQL databaser for analyse. Da vil man unng\u00e5 \u00e5 m\u00e5tte lese inn passordet for brukeren fra hemmelighet i koden.</p> <p>Eksemplene som f\u00f8lger forutsetter:</p> <ul> <li> <p>At f\u00f8lgende python biblioteker er installert:     <pre><code>cloud-sql-python-connector\npandas\npg8000\nsqlalchemy\n</code></pre></p> </li> <li> <p>At den personlige brukeren eller IAM service accounten har rollene <code>Cloud SQL Instance User</code> og <code>Cloud SQL Client</code> i GCP prosjektet som eier database instansen du skal koble deg mot. Dette er prosjektniv\u00e5 roller du gir gjennom IAM i GCP prosjektet.</p> </li> <li> <p>At den personlige brukeren eller IAM service accounten er lagt til som en <code>Cloud IAM</code> bruker p\u00e5 database instansen. Se her for hvordan \u00e5 legge til dette.</p> </li> <li> <p>Enten manuelt eller med databasemigrasjon m\u00e5 man gi brukeren/service accounten tilgang til \u00e5 lese fra tabellene i databasen.</p> <ul> <li>For \u00e5 gi tilgang til personlige brukere:     <pre><code>GRANT SELECT ON ALL TABLES IN SCHEMA public to cloudsqliamuser;\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO cloudsqliamuser;\n</code></pre></li> <li>For \u00e5 gi tilgang til IAM service accounter:     <pre><code>GRANT SELECT ON ALL TABLES IN SCHEMA public to cloudsqliamserviceaccount;\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO cloudsqliamserviceaccount;\n</code></pre></li> </ul> </li> </ul>"},{"location":"analyse/eksempler/#lese-med-personlig-bruker","title":"Lese med personlig bruker","text":"<p>Hvis du ikke har gjort det i dag, kj\u00f8r f\u00f8rst kommandoen <code>gcloud auth login --update-adc</code> <pre><code>import os\n\nfrom google.cloud.sql.connector import Connector\nimport pg8000\nimport pandas as pd\nimport sqlalchemy\n\ninstance_connection_name = \"prosjektID:region:instans\" # Erstatt med database instansen du skal koble deg til\ndb_iam_user = \"epost@nav.no\" # Erstatt med din nav epost\ndb_name = \"navn\" # Erstatt med navn p\u00e5 databasen\n\nconnector = Connector()\n\ndef getconn() -&gt; pg8000.dbapi.Connection:\n    conn: pg8000.dbapi.Connection = connector.connect(\n        instance_connection_name,\n        \"pg8000\",\n        user=db_iam_user,\n        db=db_name,\n        enable_iam_auth=True,\n    )\n    return conn\n\nengine = sqlalchemy.create_engine(\n    \"postgresql+pg8000://\",\n    creator=getconn)\n\nquery = \"SELECT * FROM table\"\ndf = pd.read_sql_query(query, engine)\n</code></pre></p>"},{"location":"analyse/eksempler/#lese-med-service-account","title":"Lese med service account","text":"<p>Dette eksempelet er ment for airflow tasks i KNADA og vil ikke fungere fra notebooks da disse ikke har en binding mot en IAM service account. For notebooks i KNADA, se Lese med personlig bruker.</p> <pre><code>import os\n\nfrom google.cloud.sql.connector import Connector\nimport pg8000\nimport pandas as pd\nimport sqlalchemy\n\ninstance_connection_name = \"prosjektID:region:instans\" # Erstatt med database instansen du skal koble deg til\ndb_iam_user = \"sa@prosjekt.iam\" # Merk: Brukernavnet her skal settes til service account eposten uten .gserviceaccount.com. Alts\u00e5 er service account eposten din mitt-team@knada-gcp.iam.gserviceaccount.com s\u00e5 blir brukernavnet mitt-team@knada-gcp.iam\ndb_name = \"database\" # Erstatt med databasenavn\n\nconnector = Connector()\n\ndef getconn() -&gt; pg8000.dbapi.Connection:\n    conn: pg8000.dbapi.Connection = connector.connect(\n        instance_connection_name,\n        \"pg8000\",\n        user=db_iam_user,\n        db=db_name,\n        enable_iam_auth=True,\n    )\n    return conn\n\nengine = sqlalchemy.create_engine(\n    \"postgresql+pg8000://\",\n    creator=getconn)\n\nquery = \"SELECT * FROM table\"\ndf = pd.read_sql_query(query, engine)\n</code></pre>"},{"location":"analyse/eksempler/#r","title":"R","text":""},{"location":"analyse/eksempler/#lese-fra-google-cloud-storage-bucket","title":"Lese fra Google Cloud Storage bucket","text":"<ol> <li>Autentiser deg med <code>gcloud auth login --update-adc</code></li> <li>Installer f\u00f8lgende pakker <pre><code>install.packages(\"googleCloudStorageR\")\ninstall.packages(\"gargle\")\n</code></pre></li> <li>Les fra bucket <pre><code>library(googleCloudStorageR)\nlibrary(gargle)\n\nscope &lt;-c(\"https://www.googleapis.com/auth/cloud-platform\")\ntoken &lt;- token_fetch(scopes = scope)\n\ngcs_auth(token = token)\n\ngcs_global_bucket(\"my-bucket\")\nobj &lt;- gcs_get_object(\"file.txt\")\n</code></pre></li> </ol>"},{"location":"analyse/google-secret-manager/","title":"Google Secret Manager","text":"<p>Google Secret Manager er en tjeneste som gir en sikker og praktisk metode for \u00e5 lagre API-n\u00f8kler, passord, sertifikater og annen sensitiv data.</p>"},{"location":"analyse/google-secret-manager/#secrets-i-nais-team-prosjekt","title":"Secrets i NAIS team-prosjekt","text":"<p>Har du hemmeligheter i et eget NAIS team-prosjekt som du \u00f8nsker \u00e5 bruke fra Airflow, s\u00e5 m\u00e5 du gi service accounten for KNADA (denne finner du i Knorten) tilgang til hemmeligheter i ditt team-prosjekt.</p>"},{"location":"analyse/google-secret-manager/#secrets-i-knada","title":"Secrets i KNADA","text":"<p>I og med at noen av brukerne i KNADA ikke er knyttet til et NAIS team-prosjekt, tilbyr KNADA Google Secret Manager enten for team eller enkeltpersoner.</p> <p>Hvert team som blir opprettet i KNADA igjennom Knorten vil f\u00e5 opprettet sin team-hemmelighet i Google Secret Manager, denne er kun tilgjengelig fra Airflow. Hver enkelt KNADA-bruker har ogs\u00e5 muligheten til \u00e5 bestille sin egen personlige hemmelighet i Google Secret Manager. Denne er tenkt brukt til \u00e5 lagre hemmeligheter som kun du skal ha tilgang til.</p>"},{"location":"analyse/google-secret-manager/#fa-tilgang","title":"F\u00e5 tilgang","text":"<p>Det blir automatisk opprettet en hemmelighet for et team i Knorten, og alle medlemmer av teamet har tilgang. Personlige hemmeligheter m\u00e5 man selv aktivt opprette, og dette gj\u00f8r man under Personlige tjenester.</p>"},{"location":"analyse/google-secret-manager/#legge-til-en-ny-hemmelighet","title":"Legge til en ny hemmelighet","text":"<p>Det er en lenke fra Knorten til teamets og din personlige secret manager. Dokumentasjon for bruk av Google Secret Manager finner man hos Google Cloud. En viktig ting \u00e5 merke seg er at man skiller mellom en <code>secret</code> og <code>version</code>. For man har kun tilgang til en hemmelighet/<code>secret</code> igjennom Knorten, men denne kan ha forskjellige <code>version</code>. Vi anbefaler uansett ikke at man har forskjellige hemmeligheter i forskjellige <code>version</code>, da dette fort kan bli uoversiktlig. Det vi anbefaler er \u00e5 legge alle hemmelighetene deres som en liste i en <code>version</code>. Da kan man lett lese de inn i Python.</p>"},{"location":"analyse/google-secret-manager/#lese-hemmeligheter-fra-google-secret-manager","title":"Lese hemmeligheter fra Google Secret Manager","text":"<p>For \u00e5 lese hemmelighter fra Google Secret Manager m\u00e5 du installere Python-biblioteket google-cloud-secret-manager.</p> <pre><code>pip install --user google-cloud-secret-manager\n</code></pre> <p>Koden nedenfor henter alle hemmelighentene fra ditt omr\u00e5de og legger de inn i en variabel som heter <code>data</code>.</p> <pre><code>import os\nfrom google.cloud import secretmanager\n\nsecrets = secretmanager.SecretManagerServiceClient()\nresource_name = f\"{os.environ['KNADA_TEAM_SECRET']}/versions/latest\"\nsecret = secrets.access_secret_version(name=resource_name)\ndata = secret.payload.data.decode('UTF-8')\n</code></pre>"},{"location":"analyse/koble-pseudonymiserte/","title":"Koble sammen pseudonymiserte views","text":"<p>I Markedsplassen er det mulig \u00e5 tilrettelegge pseudonymiserte tabeller for sammenkobling. Du trenger tilgang til minst to pseudonymiserte tabeller registrert p\u00e5 Markedsplassen. Du spesifiserer hvilke tabeller du \u00f8nsker \u00e5 koble sammen. Du kan ogs\u00e5 velge \u00e5 lage konsistente id-er for personer som har byttet f\u00f8dselsnummer. For de tabellene som inneholder f\u00f8dselsnummer m\u00e5 du oppgi hvilken kolonne disse finnes i. Tabellene slettes etter 21 dager, med mindre du velger noe annet. N\u00e5r du bestiller tabellene skjer f\u00f8lgende:</p> <ol> <li>Et nytt <code>BigQuery-dataset</code> opprettes i et eget Markedsplassen-prosjekt i GCP. Du f\u00e5r tilgang til dette.</li> <li>Markedsplassen generer en verdi som brukes i pseudonymiseringen</li> <li>De opprinnelige tabellene som de pseudonymiserte tabellene er basert p\u00e5 leses av Markedsplassen</li> <li>Konsistente id-er lages ved at vi kobler inn mapping-tabell (ikke p\u00e5krevd)</li> <li>Markedsplassen pseudonymiserer kolonner som produsentene har merket som pseudonymiserte. SHA256 og den samme verdien for alle tabellene brukes i pseudonymiseringen.</li> <li>View opprettes i <code>BigQuery-dataset</code></li> </ol> <p>Tilganger til vises under \"mine tilganger\" p\u00e5 Markedsplassen.</p>"},{"location":"analyse/kom-i-gang/","title":"Kom i gang","text":"<p>For \u00e5 komme i gang med analysering tilbyr NADA dokumentasjon p\u00e5 hvordan man kan ta i bruk Jupyter Notebooks og Airflow i teamprosjektene p\u00e5 GCP, se managed Jupyter notebook og managed Airflow for mer informasjon.</p> <p>Dersom man har behov for \u00e5 n\u00e5 onprem kilder tilbyr vi ogs\u00e5 analyseverkt\u00f8y for dette i KNADA.</p>"},{"location":"analyse/kom-i-gang/#knada","title":"KNADA","text":"<p>KNADA er NADA sin analyseplattform kj\u00f8rende i GCP med kobling til datakilder i onprem. Man m\u00e5 ha Naisdevice for \u00e5 n\u00e5 tjenester i Knada. Tilgang til Jupyter Notebooks og Airflow i KNADA bestilles i Knorten.</p> <p>Gjennom Knorten oppretter man et team for en eller flere personer. Man kan s\u00e5 installere Jupyter notebook eller Airflow. Teamadministreringen skjer igjennom Knorten.</p>"},{"location":"analyse/kom-i-gang/#tilgang-utenfor-utvikling-og-data","title":"Tilgang utenfor Utvikling og data","text":"<p>Hvis du eller noen i teamet ditt ikke tilh\u00f8rer Utvikling og data (U&amp;D) m\u00e5 de manuelt bli lagt til Azure AD-gruppen <code>knada-gw-access</code>. Dette er en gruppe alle kan bli medlem av, og vi \u00f8nsker bare \u00e5 ha en god oversikt over hvem som ikke tilh\u00f8rer U&amp;D. Ta kontakt i Slack#nada for bistand.</p>"},{"location":"analyse/metabase/","title":"Metabase","text":"<p>Metabase er en opensource plattform for moderne datautforskning og visualisering.</p>"},{"location":"analyse/metabase/#kom-igang","title":"Kom igang","text":"<p>Metabase for interne data i NAV er tilgjengelig p\u00e5 metabase.ansatt.nav.no. Innloggingen gj\u00f8res med SSO.</p>"},{"location":"analyse/metabase/#hvordan-fungerer-tilgangsstyring-i-metabase","title":"Hvordan fungerer tilgangsstyring i Metabase?","text":"<p>Med unntak av <code>all-users@nav.no</code> s\u00e5 st\u00f8tter vi ikke at gruppetilganger gitt gjennom Datamarkedsplassen synkroniseres til Metabase. For \u00e5 f\u00e5 tilgang i Metabase m\u00e5 derfor hver enkelt bruker gis individuell tilgang til datasettet i Datamarkedsplassen. Dette inkluderer ogs\u00e5 eiere av datasettet.</p> <p>Dersom teamet legger til datasettet i Metabase (<code>Legg til i Metabase</code> p\u00e5 Datamarkedsplassen), vil det v\u00e6re tilgjengelig for de samme som har tilgang til datasettet p\u00e5 Datamarkedsplassen. N\u00e5r datasettet legges til i Metabase, vil det opprettes en database (<code>I</code> i figuren under) og en collection (<code>II</code> i figuren under) i Metabase. Begge deler er tilgangsbegrenset. Tilgangsstyringen gjelder b\u00e5de for \u00e5 lese Dashboard og for \u00e5 lage dem.</p> <pre><code>flowchart BT\nsubgraph Dataprodukt\nsubgraph Datasett 1\nA{Tilganger}\nB[(BigQuery-tabell)]\nend\nend\n\nsubgraph Metabase\nsubgraph II: Tilgangsstyrt collection\nC[Dashboard]\nD[Questions]\nend\nE[(I: Database)]\nF{Metabase-tilganger}\nend\n\nsubgraph Annen collection\nG[Questions]\nH[Dashboard]\n\nend\n\nA --Tilganger til Metabase er &lt;br&gt; er de samme som i BigQuery--&gt; F\nB --&gt; E\nF --&gt; D\nD --&gt; C\nG --Personer med tilgang til &lt;br&gt; collectionen har tilgang til &lt;br&gt; *resultatet* fra questionen &lt;br&gt; om den ligger i samme collection. &lt;br&gt; De kan ikke endre questionen &lt;br&gt; eller se data i underliggende tabell--&gt; H\nE --&gt; F\nF --Kan kun bruke data &lt;br&gt; andre steder om personen &lt;br&gt; har tilgang--&gt; G</code></pre> <p>Datasett som er \u00e5pne for alle i NAV (<code>all-users@nav.no</code>) synkroniseres automatisk til Metabase og \u00e5pnes for alle brukere.</p> <p>Tilgangsbegrensede elementer i \u00e5pent tilgjengelige dashboards vil fortsatt v\u00e6re tilgangsbegrenset. Det betyr at om du inkluderer data som kun er tilgjengelig for ditt team inn i et \u00e5pent dashboards, vil folk utenfor teamet f\u00e5 beskjed om at de ikke har tilgang til akkurat det dataene.</p>"},{"location":"analyse/metabase/#hvor-skal-sprsmal-og-dashboards-lagres","title":"Hvor skal sp\u00f8rsm\u00e5l og dashboards lagres?","text":"<p>Det er fra versjon 1.53 mulig \u00e5 lagre sp\u00f8rsm\u00e5l direkte i dashboardet. Dette er praktisk med tanke p\u00e5 orden, men sp\u00f8rsm\u00e5lene vil da ikke v\u00e6re tilgjengelig for bruk i andre dashboards.</p> <p>Tilgangen knyttet til mappen elementene er lagret i bestemmer hvem som kan se dem. Metabase har to toppniv\u00e5:</p> <ul> <li>Personal collections: Her kan du lagre alt som ikke skal v\u00e6re synlig for andre enn deg selv.</li> <li>Our analytics: Alt som skal v\u00e6re synlig for andre lagres her. Fortrinnvis nede i ditt teams undermappe\u00ae.</li> </ul> <p>Det er mulig \u00e5 flytte elementer mellom mapper og dashboards etter behov, men husk at det er tilgangen til mappen som bestemmer hvem som kan se sp\u00f8rsm\u00e5l og dashboard.</p>"},{"location":"analyse/metabase/#administere-datamodell","title":"Administere datamodell","text":"<p>N\u00e5r et datasett legges til i Metabase vil appen gi hvert felt en semantisk type som den tror passer. Hvis Metabase gjetter feil kan det f\u00f8re til problemer som at du ikke kan summere tall, filtrere p\u00e5 en kategori eller bruke tidsfunksjoner. Dette kan endres i adminmenyen:</p> <ol> <li>Trykk p\u00e5 tannhjulet oppe til h\u00f8yre og g\u00e5 inn i <code>Admin settings</code>. Her finner du alle datasett du har tilgang til via Datamarkedsplassen.</li> <li>Velg tabellen du \u00f8nsker \u00e5 administrere. </li> <li>Her kan du for hvert felt gj\u00f8re endringer som \u00e5 velge semantisk type og filtertype utifra hva du selv \u00f8nsker. Merk at disse endringene vil gjelde for alle som bruker dette datasettet til \u00e5 lage sp\u00f8rsm\u00e5l. </li> </ol> <p>Er du usikker p\u00e5 hvilken type som passer kan du pr\u00f8ve deg fram eller velge en av disse:</p> <ul> <li>Kategori: <code>Entity name</code> eller <code>Category</code></li> <li>Tid: <code>Creation timestamp</code> eller <code>Creation date</code></li> <li>Tall: <code>Quantity</code></li> </ul>"},{"location":"analyse/metabase/#sync-og-scan-av-tabeller","title":"Sync og scan av tabeller","text":"<p>Dersom du gj\u00f8r endringer p\u00e5 skjemaet til en tabell i BigQuery vil det ta inntil en time f\u00f8r Metabase oppdager endringen. Synkronisering av skjema gj\u00f8res alts\u00e5 en gang i timen.</p> <p>En gang i d\u00f8gnet gj\u00f8res det ogs\u00e5 en full table scan. Metabase sjekker da hvilke mulige verdier hver kolonne kan ha for \u00e5 populere nedtrekksmenyer og lignende. Har du behov for \u00e5 trigge en scan kan du gj\u00f8re f\u00f8lgende.</p> <ol> <li>Trykk p\u00e5 tannhjulet oppe til h\u00f8yre og g\u00e5 inn i <code>Admin settings</code>. Her finner du alle datasett du har tilgang til via Datamarkedsplassen.</li> <li>Velg tabellen du \u00f8nsker \u00e5 synkronisere og trykk p\u00e5 det nye tannhjulet som dukker opp i h\u00f8yre hj\u00f8rne.</li> <li>Trykk p\u00e5 <code>Re-scan this table</code>.</li> <li>Det kan v\u00e6re n\u00f8dvendig \u00e5 \u00e5pne nettleser p\u00e5 nytt for at den skal f\u00e5 med seg endringen.</li> </ol>"},{"location":"analyse/metabase/#faq","title":"FAQ","text":"<p>Q: Jeg f\u00e5r ikke logget inn. Hva kan jeg gj\u00f8re? A: Dersom du ikke har v\u00e6rt logget inn i Metabase p\u00e5 lang tid kan brukeren din bli deaktivert. Da m\u00e5 du ta kontakt med #nada p\u00e5 Slack.</p> <p>Q: Jeg har nettopp lagt til en ny kolonne i BigQuery-tabellen min. Hvorfor dukker den ikke opp i Metabase? A: Metabase kj\u00f8rer en synk hver time for \u00e5 sjekke om skjemaet har endret seg. Det vil derfor ta litt tid f\u00f8r det dukker opp i Metabase automatisk.</p> <p>Q: Filter-verdier i Metabase er ikke oppdatert? A: Metabase kj\u00f8rer en daglig scan av hele tabellen i BigQuery for \u00e5 finne ut av hvilke verdier som finnes. Dette brukes bl.a. til \u00e5 generere <code>options</code> i filter. Disse vil ogs\u00e5 oppdateres med <code>Re-scan this table</code> som forklart over.</p> <p>Q: Hvorfor f\u00e5r jeg ikke joinet datasett som er \u00e5pent tilgjengelig? A: Du kan det! Men du m\u00e5 gj\u00f8re det med <code>SQL query</code>. Et alternativ er \u00e5 joine tabeller i BigQuery, lage et nytt datasett og legge dette til i Metabase.</p> <p>Q: Kan jeg koble sammen datasett som er tilgangsbegrenset? A: Slik Metabase er satt opp, er det en unik service-bruker per tilgangsbegrensede datasett.  Det er mulig \u00e5 gj\u00f8re dette i Metabase ved \u00e5 be datasetteier om \u00e5 gi tilgang til service-account, men vi anbefaler \u00e5 lage et view i BigQuery. </p> <p>Q: Jeg har tilgang til et datasett i Datamarkedsplassen gjennom \u00e5 v\u00e6re medlem av en AD-gruppe og f\u00e5r lest data direkte fra BigQuery, hvorfor har jeg da ikke tilgang til samme datasett i Metabase? A: I Metabase leses data fra kilden med en service-bruker og ikke din personlige bruker. Vi har ikke synkronisering av AD-grupper til Metabase, s\u00e5 for \u00e5 f\u00e5 samme tilgang i Metabase m\u00e5 hver enkelt person legges til manuelt for \u00e5 inkluderes i korrekt tilgangsgruppe i Metabase.</p>"},{"location":"analyse/airflow/knada-airflow/","title":"Airflow i KNADA","text":"<p>Apache Airflow er et verkt\u00f8y for \u00e5 orkestrere, skedulere og monitorere datapipelines. Web-grensesnittet til Airflow gir brukeren enkel tilgang til \u00e5 lese logger fra de ulike stegene i pipelinen, trigge datapipelines manuelt og sjekke statistikk p\u00e5 tidligere kj\u00f8ringer.</p> <p>En datapipeline i Airflow, eller DAG (Directed Acyclic Graph), er et sett med oppgaver man \u00f8nsker \u00e5 kj\u00f8re som beskriver rekkef\u00f8lge og avhengigheter mellom oppgavene. Disse DAG-ene beskrives programmatisk i python filer og legges i et Github repo som periodisk synkroniseres med Airflow instansen. Nedenfor ser du en en grafisk representasjon av flyten i en DAG:</p> <pre><code>flowchart LR\n    A(email_start) --&gt; C(waiting_1)\n    B(slack_start) --&gt; C(waiting_1)\n    C --&gt; D(fetch_styrk)\n    C --&gt; E(fetch_nace)\n    C --&gt; F(fetch_pam)\n    D --&gt; G(waiting_2)\n    E --&gt; G(waiting_2)\n    F --&gt; G(waiting_2)\n    G --&gt; H(transform_styrk)\n    G --&gt; I(transform_nace)\n    G --&gt; J(transform_pam)\n    H --&gt; K(waiting_3)\n    I --&gt; K(waiting_3)\n    J --&gt; K(waiting_3)\n    K --&gt; L(slack_success)\n    K --&gt; M(email_success)</code></pre>"},{"location":"analyse/airflow/knada-airflow/#kom-i-gang","title":"Kom i gang","text":"<p>NADA tilbyr team eller enkeltpersoner \u00e5 sette opp Airflow instanser i KNADA gjennom Knorten.</p> <p>For mer informasjon om Airflow, se Airflow docs</p> <p>V\u00e6r oppmerksom p\u00e5 at alt av logger fra en Airflow task vil skrives til en bucket i <code>knada-gcp</code> prosjektet, og v\u00e6re tilgjengelig etterp\u00e5 for Airflow og direkte for NADA som er admins i <code>knada-gcp</code>. V\u00e6r derfor forsiktig s\u00e5 ikke sensitiv informasjon skrives til stdout i koden som kj\u00f8res.</p>"},{"location":"analyse/airflow/knada-airflow/#github-repo-for-dags","title":"Github repo for DAGs","text":"<p>For \u00e5 bruke Airflow i KNADA kreves det et Git-repo under <code>navikt</code> organisasjonen p\u00e5 Github.com som inneholder Python-filer med DAGer. </p> <p>Hvert minutt vil Github repoet bli synkronisert til Airflow instansen, og Airflow vil lese DAGene definert i repoet.</p>"},{"location":"analyse/airflow/knada-airflow/#eksempler-pa-dags-repoer","title":"Eksempler p\u00e5 DAGs repoer","text":"<ul> <li>nada-dags NADA sin eksempler for DAGer.</li> <li>knada-dags NADA sin lekekasse for DAGer, fungerende og ikke fungerende DAGer.</li> <li>Dataverk Airflow eksempel p\u00e5 intergrasjonstester av Airflow som kj\u00f8rer i Github.</li> <li>sykefravar-dags Team Sykefrav\u00e6r sine DAGer.</li> </ul>"},{"location":"analyse/airflow/knada-airflow/#dataverk-airflow","title":"Dataverk Airflow","text":"<p>Vi har laget et bibliotek med flere enkle operators for \u00e5 lette jobben n\u00e5r man lager DAGer. Dette ligger ute p\u00e5 PyPi.org og er dokumentert der.</p> <p>Forel\u00f8pig har vi fire operators, hvor alle st\u00f8tter \u00e5 klone et annet repo ved oppstart av en task, og installerer eksterne Python-avhengigheter via en <code>requirements.txt</code> fil i ditt repo.</p> <ul> <li>Quarto operator: Forenkler jobben med \u00e5 lage datafortellinger</li> <li>Notebook operator: Lar deg kj\u00f8re en Jupyter notebook i Airflow</li> <li>Python operator: Lar deg kj\u00f8re vilk\u00e5rlig Python-script</li> <li>Kubernetes operator: V\u00e5r base, som er en forenkling av den offisielle Kubernetes operator.</li> </ul>"},{"location":"analyse/airflow/knada-airflow/#konfigurasjon-av-airflow","title":"Konfigurasjon av Airflow","text":"<p>I KNADA er Airflow konfigurert til \u00e5 bruke Kubernetes Executor. Dette inneb\u00e6rer at hver task i en Airflow DAG vil spinne opp og kj\u00f8re en egen worker i en separat Kubernetes pod. Det gj\u00f8r at man st\u00e5r fritt til \u00e5 selv spesifisere milj\u00f8et til Airflow-workeren.</p> <p>Nedenfor har vi listet opp noen av de konfigurasjonen vi tror er nyttig \u00e5 vite om.</p> <p>Merk: Hovedcontaineren som worker-poden bruker vil alltid hete <code>base</code>, s\u00e5 dersom en \u00f8nsker \u00e5 overskrive noe som gjelder spesifikt for denne containeren m\u00e5 man referere til den med navn som i eksemplene under.</p>"},{"location":"analyse/airflow/knada-airflow/#ressursbehov-for-airflow","title":"Ressursbehov for Airflow","text":"<p>Dersom en ikke spesifiserer ressursbehov for Airflow taskene sine vil de kj\u00f8re med standard instillinger som er <code>512 MB</code> minne, <code>0.5</code> vCPU, og <code>1Gi</code> disk (<code>ephemeral-storage</code>). Dette kan man enkelt overstyre for alle operators gitt at de tar utgangspunkt i BaseOperator til Airflow. Under f\u00f8lger et eksempel p\u00e5 hvordan ressursbehov for en task endres til <code>2GB</code> minne,<code>2</code> vCPU, og <code>5Gi</code> disk:</p> <pre><code>from airflow import DAG\nfrom airflow.utils.dates import days_ago\nfrom airflow.operators.python_operator import PythonOperator\nfrom kubernetes import client as k8s\n\ndef myfunc():\n    print(\"kj\u00f8r task\")\n\nwith DAG('min-dag', start_date=days_ago(1), schedule_interval=None) as dag:\n    run_this = PythonOperator(\n        task_id='test',\n        python_callable=myfunc,\n        executor_config={\n           \"pod_override\": k8s.V1Pod(\n               spec=k8s.V1PodSpec(\n                   containers=[\n                      k8s.V1Container(\n                         name=\"base\",\n                         resources={\n                           \"requests\": {\n                               \"cpu\": \"2\",\n                               \"memory\": \"2Gi\",\n                               \"ephemeral-storage\": \"5Gi\"\n                           }\n                         }\n                      )\n                   ]\n               )\n           )\n        },\n        dag=dag\n    )\n</code></pre>"},{"location":"analyse/airflow/knada-airflow/#trafikk-ut-fra-airflow-aka-allow-list","title":"Trafikk ut fra Airflow (aka allow list)","text":"<p>For skallsikring av Airflow m\u00e5 man i hver task spesifisere hvilke eksterne tjenester (les: tjenester utenfor Airflow) man skal f\u00e5 lov til \u00e5 snakke med. Vi har stengt av muligheten for eksterne tjenester \u00e5 snakke inn til Airflow.</p> <p>I podene hvor Airflow tasken kj\u00f8rer blokkeres i utgangspunktet all trafikk ut, med f\u00f8lgende unntak:</p> <ul> <li>github.com: Airflow vil alltid trenge \u00e5 hente repoet som koden ligger i</li> <li>storage.googleapis.com: Airflow skriver loggene til en Google Cloud Storage bucket</li> <li>Knaudit: tjeneste som logger hvilke jobber som kj\u00f8res for hvert team til Oracle for DVH</li> </ul> <p>Utover dette er man n\u00f8dt til \u00e5 eksplisitt spesifisere hvilke kilder man trenger \u00e5 snakke med (gjelder b\u00e5de interne og eksterne addresser) for hver enkelt task i en DAG. Dette gj\u00f8r man ved \u00e5 legge p\u00e5 en <code>allowlist</code> annotasjon p\u00e5 pod ressursen med hostnavnet og porten p\u00e5 det man trenger \u00e5 n\u00e5.</p> <pre><code>from airflow import DAG\nfrom airflow.utils.dates import days_ago\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.contrib.operators.slack_webhook_operator import SlackWebhookOperator\nfrom kubernetes import client as k8s\nimport os\nimport logging\n\ndef myfunc():\n    import requests\n    res = requests.get(\"https://ssb.no/api\")\n    res.raise_for_status()\n\nwith DAG('min-dag', start_date=days_ago(1), schedule_interval=None) as dag:\n    slack = SlackWebhookOperator(\n        http_conn_id=None,\n        task_id=\"slack-message\",\n        webhook_token=os.environ[\"SLACK_TOKEN\"],\n        message=\"start min-dag\",\n        channel=\"#minkanal\",\n        link_names=True,\n        executor_config={\n            \"pod_override\": k8s.V1Pod(\n                metadata=k8s.V1ObjectMeta(annotations={\"allowlist\": \"hooks.slack.com\"})\n            )\n        }\n    )\n\n    run_this = PythonOperator(\n        task_id='test',\n        python_callable=myfunc,\n        executor_config={\n            \"pod_override\": k8s.V1Pod(\n                metadata=k8s.V1ObjectMeta(annotations={\"allowlist\": \"ssb.no,db.adeo.no:1521\"})\n            )\n        },\n    dag=dag)\n    \n    slack &gt;&gt; run_this\n</code></pre> <p><code>allowlist</code> er en kommaseparert liste med hostnavn og port p\u00e5 formatet <code>hostnavn:port</code>. Dersom man ikke angir port vil vi bruke <code>443</code> som standardport. N\u00e5r jobben er ferdig vil tilgangene bli fjernet.</p>"},{"location":"analyse/airflow/knada-airflow/#allow-list-ved-bruk-av-dataverk-airflow","title":"Allow list ved bruk av Dataverk Airflow","text":"<p>Man kan ogs\u00e5 sette <code>allowlist</code> for operators som lages med dataverk-airflow som i eksempelet under.</p> <pre><code>from airflow import DAG\nfrom airflow.utils.dates import days_ago\nfrom dataverk_airflow import notebook_operator\n\nwith DAG('dag', start_date=days_ago(1), schedule_interval=None) as dag:\n    task = notebook_operator(dag=dag,\n                             name=\"knada-pod-operator\",\n                             repo=\"navikt/repo\",\n                             nb_path=\"notebooks/mynb.ipynb\",\n                             allowlist=[\"ssb.no\", \"db.adeo.no:1521\"])\n</code></pre>"},{"location":"analyse/airflow/knada-airflow/#egne-docker-images-for-airflow","title":"Egne Docker images for Airflow","text":"<p>Hvis du kun har behov for andre Python-biblioteker s\u00e5 anbefaler vi p\u00e5 det sterkeste at du bruker Dataverk Airflow og sender med en <code>requirements.txt</code> fil i stedet for \u00e5 bygge ditt eget image.</p> <p>I noen tilfeller har du kanskje flere avhengigheter enn det vi tilbyr i standard Airflow-oppsett. Da kan det \u00e5 bygge sitt eget Docker image v\u00e6re en l\u00f8sning. Du kan se hva vi tilbyr i v\u00e5re images, og hvordan disse er bygget i navikt/knada-images. V\u00e5re Docker imager kommer med drivere for Oracle og Postgres, men inneholder ikke et stort utvalg av Python biblioteker.</p> <p>Se her for \u00e5 spesifisere eget image som brukes av standard Airflow workere. Se her for \u00e5 spesifisere eget image som brukes av dataverk-airflow workere.</p> <p>Har du behov for at hele Airflow instansen skal bruke ditt Docker image s\u00e5 spesifiseres det i Knorten.</p> <p>NB: Hvis du bygger image lokalt p\u00e5 en nyere Mac s\u00e5 er det viktig at du bygger imaget for riktig plattform. Legg til <code>--platform linux/amd64</code> i <code>docker build</code> kommandoen.</p> <p>Vi tillater ikke at Airflow worker containere kj\u00f8rer med root privilegier. Dersom du bygger ditt eget image m\u00e5 dette imaget ha en bruker <code>airflow</code> med uid <code>50000</code>.</p>"},{"location":"analyse/airflow/knada-airflow/#overstyring-av-default-worker-image","title":"Overstyring av default worker image","text":"<p>Skal man bygge eget image som skal overstyre standard worker imaget er man n\u00f8dt til \u00e5 ha apache-airflow installert. Dette vil man f\u00e5 dersom man tar utgangspunkt i enten v\u00e5rt base image eller det offisielle airflow imaget. I tillegg vil ogs\u00e5 n\u00f8dvendig <code>airflow</code> bruker med uid <code>50000</code> v\u00e6re opprettet i milj\u00f8et. Dersom man ikke tar utgangspunkt i et av disse imagene m\u00e5 man selv installere Apache Airflow i imaget samt opprette <code>airflow</code>-brukeren.</p> <p>Under f\u00f8lger et eksempel p\u00e5 hvordan \u00e5 overstyre imaget som Airflow worker containeren bruker med imaget du selv har bygget:</p> <pre><code>from airflow import DAG\nfrom airflow.utils.dates import days_ago\nfrom airflow.operators.python_operator import PythonOperator\nfrom kubernetes import client as k8s\n\ndef myfunc():\n    print(\"kj\u00f8r task\")\n\nwith DAG('min-dag', start_date=days_ago(1), schedule_interval=None) as dag:\n    run_this = PythonOperator(\n        task_id='test',\n        python_callable=myfunc,\n        executor_config={\n           \"pod_override\": k8s.V1Pod(\n               spec=k8s.V1PodSpec(\n                   containers=[\n                      k8s.V1Container(\n                         name=\"base\",\n                         image=\"ghcr.io/navikt/mitt-airflow-image:v1\"\n                      )\n                   ]\n               )\n           )\n        },\n        dag=dag\n    )\n</code></pre>"},{"location":"analyse/airflow/knada-airflow/#overstyring-av-dataverk-airflow-image","title":"Overstyring av dataverk-airflow image","text":"<p>Skal man bygge eget image for \u00e5 overstyre <code>dataverk-airflow</code> sitt standard image anbefaler vi \u00e5 ta utgangspunkt i et av v\u00e5re dataverk-airflow imager for den \u00f8nskede python versjonen. Dette imaget vil bygge p\u00e5 det offisielle python imaget samt inneholde drivere for oracle, postgres, i tillegg til quarto.</p> <p>Dersom du bygger eget image og \u00f8nsker \u00e5 bruke <code>quarto_operator</code> fra <code>dataverk-airflow</code> s\u00e5 har dette biblioteket en avhengighet til kommandolinjeverkt\u00f8yet knatch og m\u00e5 derfor ogs\u00e5 installeres i ditt image.</p> <p>Under f\u00f8lger et eksempel p\u00e5 hvordan \u00e5 overstyre imaget som <code>dataverk-airflow</code> containeren bruker med imaget du selv har bygget:</p> <pre><code>from airflow import DAG\nfrom airflow.utils.dates import days_ago\nfrom dataverk_airflow import notebook_operator\n\nwith DAG('dag', start_date=days_ago(1), schedule_interval=None) as dag:\n    task = notebook_operator(dag=dag,\n                             name=\"knada-pod-operator\",\n                             repo=\"navikt/repo\",\n                             nb_path=\"notebooks/mynb.ipynb\",\n                             image=\"ghcr.io/navikt/mitt-airflow-image:v1\")\n</code></pre>"},{"location":"analyse/airflow/knada-airflow/#api-tilgang-til-airflow","title":"API-tilgang til Airflow","text":"<p>Har man behov for at en ekstern tjeneste skal snakke med API-et til Airflow trenger Nada \u00e5 konfigurere noe p\u00e5 \"baksiden\" og lage en service bruker for dere. Ta kontakt i Slack#nada, s\u00e5 fikser vi dette for dere. Vi vil ta opprette en service account for deres Airflow, og lage en ekstern adresse (som tilgangsstyres med Cloud Armor).</p> <p>Et typisk scenario for dette er \u00e5 la IWS styre jobber i Airflow. Akkurat dette scenarioet er ogs\u00e5 dokumentert i Confluence/Analytisk Plattform.</p>"},{"location":"analyse/airflow/knada-airflow/#audit-logs-av-tasks","title":"Audit logs av tasks","text":"<p>Som et risikoreduserendetiltak logger vi hvem som kj\u00f8rer hvilke jobber i KNADA ned til Datavarehus. dette er for at Datavarehus skal ha bedre kontroll p\u00e5 hvem som snakker med de. Selve tjenesten heter knaudit, og det er kun Datavarehus og NADA som har tilgang til disse loggene.</p> <p>Eksempel p\u00e5 hva vi logger:</p> <pre><code>{\"commit_sha1\":[\"d19dcf695f043c6eff6b0cc2478b58d45299ca97\"],\"hostname\":[\"mycsvdag-starting-fc8dfe28afae414da33a5d2a57db85d1\"],\"run_id\":[\"scheduled__2023-05-03T05:30:00+00:00\"],\"timestamp\":[\"2023-05-03T05:35:11.000Z\"],\"git_repo\":[\"github.com/navikt/test-team-dag\"],\"ip\":[\"321.312.312.321\"],\"namespace\":[\"team-test-ncnv\"],\"task_id\":[\"starting\"],\"git_branch\":[\"main\"],\"dag_id\":[\"MyCSVDAG\"],\"triggered_by\":[\"airflow\"]}\n</code></pre> <p>Hvis det er en manuell kj\u00f8ring s\u00e5 vil <code>triggered_by</code> v\u00e6re satt til NAV-ident for den innlogget Airflow-bruker.</p>"},{"location":"analyse/airflow/knada-airflow/#airflow-service-account-impersonation","title":"Airflow service account impersonation","text":"<p>Hver enkelt Airflow-instans i KNADA har en egen IAM service account i <code>knada-gcp</code>-prosjektet som impersonates av teamets kubernetes service account i clusteret. Service accounten finner du under teamoversikten i Knorten. Dersom tilganger gis til denne IAM service accounten vil det delegeres til teamets kubernetes service account som igjen gj\u00f8r at Airflow workeren i clusteret f\u00e5r samme tilganger mot google APIer som IAM service accounten.</p> <p>Dersom man ikke \u00f8nsker \u00e5 gi masse tilganger til <code>knada-gcp</code> service accounten direkte, men i stedet \u00f8nsker \u00e5 gi tilgangene til en service account i sitt eget teamprosjekt kan man sette opp enda et ledd i impersonation chainen.</p>"},{"location":"analyse/airflow/knada-airflow/#eksempel-pa-impersonation-chain-med-service-account-i-team-prosjekt","title":"Eksempel p\u00e5 impersonation chain med service account i team prosjekt","text":"<p>Du har en IAM service account i team prosjektet ditt <code>min-sa@&lt;prosjekt-id&gt;.iam.gserviceaccount.com</code> som har diverse tilganger til google APIer (BigQuery, Storage buckets, etc.) og \u00f8nsker \u00e5 kunne delegere disse tilgangene til Airflow workerne dine, alts\u00e5:</p> <p><code>k8s service account -&gt; knada-gcp service account -&gt; min-sa@&lt;prosjekt-id&gt;.iam.gserviceaccount.com -&gt; Google APIer</code></p> <p>Det eneste du trenger \u00e5 gj\u00f8re er \u00e5 gi <code>Service Account Token Creator</code> rollen til <code>knada-gcp</code> service accounten under IAM for team service accounten, alts\u00e5:</p> <ol> <li>G\u00e5 til IAM &amp; Admin i team prosjektet ditt.</li> <li>Velg <code>Service Accounts</code> i menyen til venstre.</li> <li>Trykk p\u00e5 team service accounten du \u00f8nsker at knada service accounten skal impersonate.</li> <li>Trykk p\u00e5 <code>Permissions</code> og deretter <code>GRANT ACCESS</code>.</li> <li>Legg til <code>knada-gcp</code> service accounten med rollen <code>Service Account Token Creator</code>.</li> </ol> <p>Under er et eksempel p\u00e5 hvordan man kan autentisere seg mot Google med dette oppsettet i en Airflow task for \u00e5 lese fra BigQuery, Google Storage og Google Secret Manager:</p> <pre><code>from google.auth import impersonated_credentials, default\n\ndefault_creds, _ = default()\n\ntarget_credentials = impersonated_credentials.Credentials(\n  source_credentials=default_creds,\n  target_principal='min-sa@&lt;prosjekt-id&gt;.iam.gserviceaccount.com',\n  target_scopes=['https://www.googleapis.com/auth/cloud-platform'])\n\n# Les BigQuery\nfrom google.cloud.bigquery import Client as BQClient\n\nc = BQClient(project=\"&lt;prosjekt-id&gt;\", credentials=target_credentials)\njob = c.query(\"SELECT * FROM &lt;prosjekt-id&gt;.&lt;dataset&gt;.&lt;tabell&gt;\")\ndf = job.to_dataframe()\ndf.head()\n\n# Les Storage bucket\nfrom google.cloud.storage import Client as GCSClient\n\ngcs_client = GCSClient(credentials=target_credentials)\nbucket = gcs_client.bucket(\"&lt;navn-p\u00e5-bucket&gt;\")\nblob = bucket.blob(\"&lt;navn-p\u00e5-fil&gt;\")\nwith blob.open(\"r\") as f:\n    print(f.read())\n\n# Les Secret Manager secret\nfrom google.cloud.secretmanager import SecretManagerServiceClient\n\nsecrets = SecretManagerServiceClient(credentials=target_credentials)\nsecret = secrets.access_secret_version(name=\"projects/&lt;prosjekt-id&gt;/secrets/&lt;navn-p\u00e5-secret&gt;/versions/latest\")\nsecret_data = secret.payload.data.decode('UTF-8')\nprint(secret_data)\n</code></pre> <p>Fordelen med denne tiln\u00e6rmingen er at man enkelt kan bryte alle tilgangene som Airflow workeren har f\u00e5tt delegert ved \u00e5 kun fjerne <code>Service Account Token Creator</code> rollebindingen for team service accounten som du ga knada service accounten over.</p>"},{"location":"analyse/airflow/managed-airflow/","title":"Google managed Airflow (Cloud Composer)","text":"<p>Cloud Composer is a managed Apache Airflow service that helps you create, schedule, monitor and manage workflows. Cloud Composer automation helps you create Airflow environments quickly and use Airflow-native tools, such as the powerful Airflow web interface and command line tools, so you can focus on your workflows and not your infrastructure.</p> <p>Du finner den offisielle dokumentasjonen for Cloud Composer hos cloud.google.com.</p>"},{"location":"analyse/airflow/managed-airflow/#opprett-ny-composer-instans","title":"Opprett ny Composer instans","text":"<p>For \u00e5 sette opp en ny Cloud Composer instans gjennom Google Cloud Platform konsollen (GCP), g\u00e5 til Cloud Composer, trykk <code>CREATE</code> og velg <code>Composer 2</code></p> <p>F\u00f8lgende m\u00e5 spesifiseres</p> <ol> <li><code>Name</code> - navn p\u00e5 Cloud Composer instansen</li> <li><code>Location</code> - regionen hvor instansen settes opp (m\u00e5 velge Europa)</li> <li>Trykk <code>CREATE</code></li> </ol> <p>N\u00e5r man setter opp Cloud Composer s\u00e5 opprettes det automatisk en bucket som er knyttet til Composer instansen. F\u00f8r neste steg er det viktig \u00e5 notere seg navnet p\u00e5 bucketen som blir opprettet. Det gj\u00f8res ved \u00e5 g\u00e5 til Cloud Storage i konsollen og finne bucketen som har <code>goog-composer-environment</code> labels.</p>"},{"location":"analyse/airflow/managed-airflow/#github-repo-for-dags","title":"Github repo for DAGS","text":"<p>I bucketen som opprettes n\u00e5r man setter opp Cloud Composer i Opprett ny composer instans blir det automatisk laget en katalog som heter <code>dags</code>. Denne katalogen inneholder beskrivelsene av datapipelinene (DAGs) som man kan orkestrere med Cloud Composer og dette synkroniseres kontinuerlig med instansen.</p>"},{"location":"analyse/airflow/managed-airflow/#github-synk-mot-composer-bucket","title":"Github synk mot Composer bucket","text":"<p>For \u00e5 ha revisjonskontroll p\u00e5 disse pipelinebeskrivelsene l\u00f8nner det seg \u00e5 sette opp en synkronisering mot et Github repo.</p>"},{"location":"analyse/airflow/managed-airflow/#lag-service-account","title":"Lag service account","text":"<ol> <li>G\u00e5 til Google IAM og trykk p\u00e5 <code>CREATE SERVICE ACCOUNT</code></li> <li>Fyll in <code>Service account name</code> og en <code>Service account description</code></li> <li>Gi service accounten f\u00f8lgende rettigheter til bucketen opprettet i Opprett ny composer instans:<ul> <li><code>Storage Legacy Bucket Writer</code></li> <li><code>Storage Object Admin</code></li> </ul> </li> </ol> <p>Merk deg eposten som den nyopprettede service accounten f\u00e5r.</p>"},{"location":"analyse/airflow/managed-airflow/#last-ned-service-account-nkkel","title":"Last ned service account n\u00f8kkel","text":"<ol> <li>G\u00e5 til Google IAM</li> <li>Trykk p\u00e5 service accounten opprettet i Lag service account</li> <li>Trykk p\u00e5 <code>KEYS</code></li> <li>Trykk <code>ADD KEY</code> -&gt; <code>Create new key</code> -&gt; <code>JSON</code></li> <li>Ta vare p\u00e5 n\u00f8kkelen som blir lastet ned</li> </ol>"},{"location":"analyse/airflow/managed-airflow/#lag-et-github-repo","title":"Lag et Github repo","text":"<ol> <li>Opprett github repo under navikt-organisasjonen (eller bruk et du har fra f\u00f8r)</li> <li>Opprett f\u00f8lgende secret i Github repoet:<ul> <li><code>Name</code> satt til GCP_CREDENTIALS og <code>Value</code> til innholdet i JSON-n\u00f8kkelen lastet ned i Last ned service account n\u00f8kkel</li> </ul> </li> </ol>"},{"location":"analyse/airflow/managed-airflow/#oppsett-av-github-repo","title":"Oppsett av Github repo","text":"<ol> <li>Lag en katalog med navn <code>dags</code> i repoet</li> <li>Lag filen .github/workflows/sync-gcs-bucket.yaml med innhold som f\u00f8lger</li> </ol> <pre><code>name: Sync DAG-bucket\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - '.github/workflows/sync-gcs-bucket.yaml'\n      - 'dags/**'\n\njobs:\n  sync-gcs-bucket:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - uses: google-github-actions/auth@v2\n      with:\n        credentials_json: \"${{ secrets.GCP_CREDENTIALS }}\"\n    - name: \"Set up Cloud SDK\"\n      uses: google-github-actions/setup-gcloud@v2\n    - name: \"Specify GCP project\"\n      run: \"gcloud config set project PROJECT\"\n    - name: \"Sync DAGs to GCS bucket\"\n      run: gsutil cp -r dags gs://BUCKET\n</code></pre> <p>Erstatt BUCKET i workflowen over med navnet p\u00e5 bucketen som ble opprettet i Opprett ny composer instans og PROJECT med gcp prosjektet bucketen ligger i (finnes her)</p> <p>Ved push til main branch vil denne workflowen laste opp innholdet i <code>dags</code> katalogen i repoet til GCS bucketen  som igjen blir synkronisert  med Cloud Composer instansen.</p>"},{"location":"analyse/flyte/oppsett/","title":"Union autentisering fra Knast","text":"<p>Opprett en fil <code>~/.union/config.yaml</code> med f\u00f8lgende innhold:</p> <pre><code>union:\n  connection:\n    host: dns:///nav.eu-central-1.unionai.cloud\n    insecure: false\n  auth:\n    type: DeviceFlow\nadmin:\n  endpoint: dns:///nav.eu-central-1.unionai.cloud\n  insecure: false\n  authType: DeviceFlow\n</code></pre>"},{"location":"analyse/flyte/oppsett/#krav-til-allowlistede-hoster-for-knast","title":"Krav til allowlistede hoster for Knast","text":"<pre><code>nav.eu-central-1.unionai.cloud/*\nraw.githubusercontent.com/unionai/*\ngithub.com/unionai/uctl/releases/*\nrelease-assets.githubusercontent.com/github-production-release-asset/*\n</code></pre>"},{"location":"analyse/flyte/oppsett/#union-autentisering-fra-lokal-maskin","title":"Union autentisering fra lokal maskin","text":"<p>Opprett en fil <code>~/.union/config.yaml</code> med f\u00f8lgende innhold:</p> <pre><code>union:\n  connection:\n    host: dns:///nav.eu-central-1.unionai.cloud\n    insecure: false\n  auth:\n    type: Pkce\nadmin:\n  endpoint: dns:///nav.eu-central-1.unionai.cloud\n  insecure: false\n  authType: Pkce\n</code></pre>"},{"location":"analyse/flyte/oppsett/#ndvendige-verkty","title":"N\u00f8dvendige verkt\u00f8y","text":""},{"location":"analyse/flyte/oppsett/#union-cli","title":"Union CLI","text":"<p>Union CLIet kan installeres som en vanlig python pakke, men Union oppfordrer brukere til \u00e5 installere uv og deretter union CLI som et uv verkt\u00f8y. For \u00e5 installere uv se f\u00f8lgende doc. Med uv installert kan union CLI installeres som f\u00f8lger:</p> <pre><code>uv tool install union\n</code></pre> <p>For enkelhets skyld b\u00f8r du da ogs\u00e5 utvide path variablen til inkludere bin\u00e6rmappen til uv verkt\u00f8y</p> <pre><code>export PATH=\"${PATH}:${HOME}/.local/share/uv/tools/union/bin\"\n</code></pre>"},{"location":"analyse/flyte/oppsett/#uctl","title":"uctl","text":""},{"location":"analyse/flyte/oppsett/#mac","title":"MAC","text":"<pre><code>brew tap unionai/homebrew-tap\nbrew install uctl\n</code></pre>"},{"location":"analyse/flyte/oppsett/#linux","title":"Linux","text":"<pre><code>curl -sL https://raw.githubusercontent.com/unionai/uctl/main/install.sh | bash\n</code></pre> <pre><code>export PATH=\"${PATH}:${HOME}/bin\"\n</code></pre>"},{"location":"analyse/knast/generelt/","title":"Hva er Knast?","text":"<p>Knast er ditt eget personlige utviklingsmilj\u00f8 for analyse og behandling av data som bygges p\u00e5 toppen av Cloud Workstations i GCP. Med Knast kan du b\u00e5de jobbe i din foretrukne IDE i browser eller remote via din lokale VSCode eller Jetbrains IDE. Alt av oppsett rundt Knast styres fra \"Min Knast\" p\u00e5 Datamarkedsplassen. </p> <p>Hver Knast kj\u00f8rer i et felles workstations-cluster i prosjektet knada-gcp og har derfor tilgang til datakilder on-prem p\u00e5 linje med de andre tjenestene i KNADA, men du m\u00e5 selv oppgi hvilke kilder og URLer du skal snakke med. Les mer om nettverk her.</p>"},{"location":"analyse/knast/kom-i-gang/","title":"Komme i gang","text":"<p>For \u00e5 n\u00e5 din Knast m\u00e5 du ha naisdevice.</p> <p>For \u00e5 opprette en personlig Knast \u00e5pner du Datamarkedsplassen, logger inn og g\u00e5r til \"Min Knast\" i hamburgermenyen. Der vil du f\u00e5 opp en dialog som tar deg gjennom oppsettet f\u00f8rste gang. Alle valg kan endres ogs\u00e5 etter at Knasten er opprettet.</p>"},{"location":"analyse/knast/kom-i-gang/#dette-ma-du-velge","title":"Dette m\u00e5 du velge","text":""},{"location":"analyse/knast/kom-i-gang/#maskintype","title":"Maskintype","text":"<p>Du vet best hvor stor maskin du trenger. Husk at store maskiner er dyrere i drift. S\u00e5 hvis du er usikker er det lurt \u00e5 starte sm\u00e5tt.</p>"},{"location":"analyse/knast/kom-i-gang/#utviklingsmilj","title":"Utviklingsmilj\u00f8","text":"<p>Hvilken IDE vil du jobbe i? Nada tilbyr noen standardimages, men det er mulig \u00e5 lage custom images i https://github.com/navikt/knast-images.</p>"},{"location":"analyse/knast/kom-i-gang/#onprem-kilder-valgfritt","title":"Onprem-kilder (valgfritt)","text":"<p>Hvilke onprem-kilder har du behov for \u00e5 snakke med? Her kan du ogs\u00e5 velge nais-ingresser som \"intern.nav.no\", hvis du skal \u00e5pne mot f.eks https://teamkatalogen.intern.nav.no</p>"},{"location":"analyse/knast/kom-i-gang/#internett-urler-valgfritt","title":"Internett-URLer (valgfritt)","text":"<p>Her legger du til URL-stier som du trenger \u00e5 snakke med p\u00e5 internett. Det er god praksis \u00e5 \u00e5pne for minst mulig, for eksempel er <code>github.com/navikt/*</code>  bedre enn <code>github.com/*</code>.  Les mer om syntax her.</p>"},{"location":"analyse/knast/kom-i-gang/#sentralt-administrerte-apninger","title":"Sentralt administrerte \u00e5pninger","text":"<p>Nada vedlikeholder en liste med \u00e5pninger mot internett som vi anbefaler alle \u00e5 ha. \u00d8nsker du ingen eller bare noen fra den lista kan du velge skru av og velge alle \u00e5pninger selv.</p>"},{"location":"analyse/knast/kom-i-gang/#frste-gang-du-bruker-din-knast","title":"F\u00f8rste gang du bruker din Knast","text":""},{"location":"analyse/knast/kom-i-gang/#start-knast","title":"Start Knast","text":"<p>N\u00e5r du har trykket p\u00e5 \"Start opprettelse av Knast\" og ventet i noen minutter f\u00e5r du muligheten til \u00e5 starte Knasten din. Det tar et par minutter \u00e5 starte Knasten. N\u00e5r den er klar f\u00e5r du en lenke som du kan \u00e5pne for \u00e5 jobbe i nettleseren din. Du kan ogs\u00e5 koble til remote fra lokal VS Code ved \u00e5 trykke p\u00e5 \"Bruk Knast via VS Code lokalt\" og f\u00f8lge oppskriften der.</p> <p>Knast i nettleser nytes best hvis man installerer den som en PWA. Da vil den i st\u00f8rre grad oppf\u00f8re seg som en vanlig applikasjon og blant annet keybindings vil fungere bedre. Kj\u00f8r Knast som en PWA</p>"},{"location":"analyse/knast/kom-i-gang/#flgende-ma-gjres-pa-lokal-maskin-for-a-koble-vs-code-til-knast","title":"F\u00f8lgende m\u00e5 gj\u00f8res p\u00e5 lokal maskin for \u00e5 koble VS Code til Knast:","text":"<p>Hopp over steg 4-6 hvis du har gjort disse tidligere.</p> <ol> <li>Installere extension Remote - SSH i VS Code</li> <li>Logg inn i Google Cloud (kj\u00f8res lokalt)  <code>gcloud auth login</code></li> <li>Opprette SSH-tunnel (kj\u00f8res lokalt)  <code>gcloud workstations start-tcp-tunnel --cluster=knada --config=DIN_NAV_IDENT --region=europe-north1 --project knada-gcp --local-host-port=:33649 DIN_NAV_IDENT 22</code>  Husk \u00e5 sette inn Nav-identen din der det st\u00e5r <code>DIN_NAV_IDENT</code>. Porten 33649 er tilfeldig valgt og kan byttes med en annen port om du \u00f8nsker det.</li> <li>Opprette SSH-n\u00f8kkel (kj\u00f8res lokalt, hopp over om du allerede har gjort dette)  Sett et passord p\u00e5 SSH-n\u00f8kkelen. Du vil aldri bli bedt om \u00e5 bytte dette.  <code>ssh-keygen -t ed25519 -C \"din_epost_email@nav.no\"</code></li> <li>F\u00e5 Knast til \u00e5 stole p\u00e5 din SSH-n\u00f8kkel (kj\u00f8res p\u00e5 Knast, hopp over om du allerede har gjort dette)<ul> <li>Opprette directory ~/.ssh/ hvis det ikke allerede finnes</li> <li>Opprett filen authorized_keys i ~/.ssh/</li> <li>Lime inn innholdet fra public-delen av SSH-n\u00f8kkelen fra .ssh/id_ed25519.pub eller tilsvarende p\u00e5 lokal maskin inn i authorized_keys p\u00e5 Knast</li> </ul> </li> <li>Legg til knast i ssh-configen (kj\u00f8res lokalt, hopp over om du allerede har gjort dette)  <code>echo -e \"\\nHost knast\\n\\tHostName localhost\\n\\tPort 33649\\n\\tUser user\"&gt;&gt;~/.ssh/config</code>  Hvis valgte en annen port i steg 3 m\u00e5 du velge den her ogs\u00e5.</li> <li>Koble til knast<ul> <li>\u00c5pne Command Palette i VS Code (\u21e7\u2318P / Ctrl+Shift+P)</li> <li>Velg/Skriv inn: Remote - SSH: Connect to host...</li> <li>Skriv inn: knast</li> </ul> </li> </ol> <p>Dette er ogs\u00e5 beskrevet med skjermbilder i dokumentasjonen til Google Workstations.</p>"},{"location":"analyse/knast/kom-i-gang/#kjr-knast-som-en-pwa","title":"Kj\u00f8r Knast som en PWA","text":"<p>N\u00e5r man installerer Knast som en PWA vil Knast oppleves mer som en vanlig applikajson, og kan gi en mye bedre brukeropplevelse. Her er guider til hvordan man kan installere en PWA for noen av de mest brukte nettleserne.</p> <ul> <li>Generell guide</li> <li>Chrome</li> <li>Safari</li> <li>Vivaldi</li> <li>Edge</li> <li>Firefox st\u00f8tter installasjon av PWA bare gjennom extension</li> </ul>"},{"location":"analyse/knast/kom-i-gang/#bytte-shell-i-terminal","title":"Bytte shell i terminal","text":"<p>I Knast kan man bytte standard shell i terminalen ved \u00e5 \u00e5pne Command Palette (\u21e7\u2318P / Ctrl+Shift+P) og skrive <code>Terminal: Select Default Profile</code>.</p> <p>Man kan ogs\u00e5 gj\u00f8re dette fra dropdown ved siden av ny terminal-knappen: </p> <p>Les mer om Terminal Profiles i Visual Studio Code sin dokumentasjon.</p>"},{"location":"analyse/knast/kom-i-gang/#python","title":"Python","text":"<p>For \u00e5 kj\u00f8re pythonkode b\u00f8r du installere en egen pythonversjon. Les hvordan det gj\u00f8res best med uv.</p>"},{"location":"analyse/knast/kom-i-gang/#extensions","title":"Extensions","text":"<p>For at VSCode skal fungere godt m\u00e5 du installere noen extensions. Om du bruker VSCode i nettleser kj\u00f8rer du egentlig open source versjonen som kalles Code - OSS. Den st\u00f8rste forskjellen mellom disse to er at Code - OSS ikke st\u00f8tter alle extensions som VSCode gj\u00f8r. Om du derimot kobler til remote fra din lokale VSCode vil du kunne bruke alle extensions. Merk at mange extensions trenger \u00e5 snakke med internett. S\u00e5 hvis du opplever problemer med noen av dem b\u00f8r du f\u00f8lge med p\u00e5 \"blokkerte URLer\" p\u00e5 Min Knast. Les mer om nettverk her.</p>"},{"location":"analyse/knast/kom-i-gang/#sudo-rettigheter","title":"Sudo-rettigheter","text":"<p>Det er begrenset hvilke kommandoer man har lov til \u00e5 kj\u00f8re som sudo. Du kan se hvilke du har lov til \u00e5 kj\u00f8re ved \u00e5 kj\u00f8re <code>sudo -l</code>. Hver gang man kj\u00f8rer sudo vil man bli bedt om \u00e5 skrive inn en bekreftelseskode. Dette bekreftelseskoden er <code>husk ROS</code> og brukes utelukkende for \u00e5 bekrefte at man \u00f8nsker \u00e5 kj\u00f8re sudo. Dette gj\u00f8res for \u00e5 unng\u00e5 at script kj\u00f8rer sudo uten at man vet om det.</p>"},{"location":"analyse/knast/kom-i-gang/#generelle-rad","title":"Generelle r\u00e5d","text":"<p>Andre ting verdt \u00e5 tenke p\u00e5 er nbstripout, dependabot og autentisering mot github og gcp. Her gjelder det samme som i Generelle r\u00e5d for Jupyterhub.</p>"},{"location":"analyse/knast/miljo/","title":"Oppsett av milj\u00f8","text":""},{"location":"analyse/knast/miljo/#python-med-uv","title":"Python med uv","text":"<p>Vi oppfordrer brukere av Knast maskiner \u00e5 bruke uv for oppsett av virtuelle python milj\u00f8er og installasjon av pakker. Under f\u00f8lger en oppskrift for \u00e5 sette opp et slikt virtuelt milj\u00f8 for \u00e5 kunne kj\u00f8re python kode i en isolert kontekst. For mer informasjon om <code>uv</code>, se deres dokumentasjon.</p>"},{"location":"analyse/knast/miljo/#opprettelse-et-nytt-virtuelt-milj-med-spesifisert-python-versjon","title":"Opprettelse et nytt virtuelt milj\u00f8 med spesifisert python versjon","text":"<p>Merk for \u00e5 installere en annen python versjon kan det v\u00e6re at du m\u00e5 tillate utg\u00e5ende trafikk for \u00e5 hente ressursene du trenger. Denne allowlistingen gj\u00f8r du selv for Knast maskinen din i datamarkedsplassen under <code>\u00c5pninger mot internett</code> fanen. Hvis det ikke kommer tydelig frem av feilmeldingen hvilke hoster du ikke n\u00e5r vil du i denne fanen ogs\u00e5 kunne se alle blokkerte nettverkskall gjort fra maskinen din mot internett.</p> <pre><code># Setter opp et nytt venv og installerer python 3.11\nuv venv --python 3.11 myvenv\n\n# Aktiverer det virtuelle milj\u00f8et i gjeldende shell\nsource myvenv/bin/activate\n</code></pre>"},{"location":"analyse/knast/miljo/#lasing-og-installasjon-av-avhengigheter-i-virtuelt-milj","title":"L\u00e5sing og installasjon av avhengigheter i virtuelt milj\u00f8","text":"<p>Tar her utgangspunkt i at bruker har en requirements fil som heter <code>requirements.in</code> som inneholder en liste over avhengighetene det er behov for.</p> <pre><code># L\u00e5ser avhengigheter og lagrer i requirements.txt\nuv pip compile requirements.in -o requirements.txt\n\n# Installerer avhengigheter fra requirements.txt\nuv pip sync requirements.txt\n</code></pre>"},{"location":"analyse/knast/miljo/#bruke-det-virtuelle-miljet-i-en-notebook-kontekst","title":"Bruke det virtuelle milj\u00f8et i en notebook-kontekst","text":"<p>For \u00e5 bruke det virtuelle milj\u00f8et for notebooken konteksten din velger du <code>Select another kernel</code> -&gt; <code>Python environments</code> -&gt; <code>myvenv</code>.</p> <p>Hvis ikke det virtuelle milj\u00f8et dukker opp i listen over kan du legge til det manuelt ved \u00e5 kj\u00f8re f\u00f8lgende kommando:</p> <pre><code>ipython kernel install --name myvenv --user\n</code></pre>"},{"location":"analyse/knast/miljo/#vedlikehold-av-python-pakker-og-versjoner","title":"Vedlikehold av Python-pakker og versjoner","text":"<p>Man b\u00f8r regelmessig kj\u00f8re <code>uv pip list --outdated</code> for \u00e5 se hva slags pakker man trenger \u00e5 oppgradere. Enda bedre er \u00e5 ha en <code>requirements.txt</code> (eller tilsvarende for Poetry eller lignende verkt\u00f8y) sjekket inn i Github, og la Dependabot gj\u00f8re jobben. Husk ogs\u00e5 \u00e5 f\u00f8lge med p\u00e5 nye Python-versjoner! Det finnes en god oversikt hos Python developers guide. Per dags dato b\u00f8r ingen v\u00e6re p\u00e5 noe lavere enn 3.9, og man b\u00f8r jobbe med \u00e5 komme seg vekk fra 3.9 da den har EOL (end of life) oktober 2025.</p>"},{"location":"analyse/knast/miljo/#autentisering-mot-github","title":"Autentisering mot GitHub","text":"<p>Vi anbefaler \u00e5 bruke gh cli for \u00e5 autentisere seg mot GitHub. Dette kommandolinjeverkt\u00f8yet kommer preinstallert i Knast-milj\u00f8et ditt. For \u00e5 autentisere deg mot GitHub kj\u00f8rer du <code>gh auth login</code> fra en terminal p\u00e5 Knast-maskinen din og f\u00f8lger instruksjonene som kommer opp.</p>"},{"location":"analyse/knast/miljo/#github-copilot","title":"GitHub Copilot","text":"<p>GitHub Copilot fungerer, men GitHub Copilot Chat st\u00f8ttes forel\u00f8pig ikke.</p> <p>Brannmur\u00e5pninger er allerede inkludert i de sentralt administrerte \u00e5pningene, s\u00e5 om du bruker disse, s\u00e5 skal det v\u00e6re OK.</p> <p>I tillegg m\u00e5 du s\u00f8rge for at extensions bruker proxy. G\u00e5 til <code>File-&gt;Preferences-&gt;Settings</code> og s\u00f8k etter <code>http.proxySupport</code>. Denne m\u00e5 du sette til <code>on</code>.</p> <p>H\u00f8yreklikk p\u00e5 tannhjulet nederst til venstre og huk av for <code>Accounts</code>. N\u00e5 skal du kunne trykke p\u00e5 ikonet som dukker opp over tannhjulet og velge <code>Sign in to GitHub to use GitHub Copilot</code> og deretter f\u00f8lge anvisningene nederst i h\u00f8yre hj\u00f8rne. N\u00e5r du er innlogget i GitHub, s\u00e5 skal Copilot fungere.</p>"},{"location":"analyse/knast/nettverk/","title":"Nettverk","text":"<p>Siden Knast kj\u00f8rer i knada-gcp er det mulig \u00e5 n\u00e5 det meste av tjenester i Nav og alt som ligger p\u00e5 internett. For \u00e5 f\u00e5 til dette m\u00e5 du selv oppgi hva du \u00f8nsker \u00e5 snakke med.</p>"},{"location":"analyse/knast/nettverk/#apninger-mot-on-prem","title":"\u00c5pninger mot on-prem","text":"<p>Det er \u00f8nskelig \u00e5 begrense \u00e5pninger mot on-prem s\u00e5 mye som mulig. Derfor har du kun tilgang til de adressene du oppgir i din Knast-konfigurasjon. Her velger du fra en dropdown-liste med mulige kilder. Du ogs\u00e5 velge nais-ingresser som \"intern.nav.no\", hvis du skal \u00e5pne mot f.eks https://teamkatalogen.intern.nav.no. Dersom du ikke finner kilden du trenger ta kontakt med #nada p\u00e5 slack.</p>"},{"location":"analyse/knast/nettverk/#apninger-mot-internett","title":"\u00c5pninger mot internett","text":"<p>Det er ogs\u00e5 stengt av mot internett som default. Nada tilbyr en liste med \u00e5pninger som de aller fleste har behov for. Utover den m\u00e5 du legge til URLer du vil snakke med selv under fanen \"URL-h\u00e5ndtering\". URLene m\u00e5 oppgis med syntax beskrevet her. Det er god praksis \u00e5 \u00e5pne for minst mulig, for eksempel er <code>github.com/navikt/*</code>  bedre enn <code>github.com/*</code>. Det er ikke alltid \u00e5penbart hvilke URLer forskjellige klienter og extensions pr\u00f8ver \u00e5 snakke med. Hvis du opplever at noe ikke fungerer som forventet, sjekk ut \"Blokkerte URLer\" under \"URL-h\u00e5ndtering\". Der vil du se URLer som har blitt blokkert og kanskje m\u00e5 legges til i allowlisten din for full virk. Husk \u00e5 ha et bevisst forhold til hva du \u00e5pner for. </p>"},{"location":"analyse/knast/nettverk/#pypi-proxy","title":"PyPI proxy","text":"<p>Vi har laget en global deny regel mot pypi.org. For \u00e5 kunne laste ned Python pakker \u00f8nsker vi at dere g\u00e5r via v\u00e5r pypi-proxy. Vi har konfigurert en global pip config /etc/pip.conf, som ikke tar stilling til hvilken package manager (uv, pip, poetry) du bruker, s\u00e5 lenge den er kompatibel med pip. For \u00e5 kunne bruke denne configen m\u00e5 du kj\u00f8re f\u00f8lgende kommandoer: <pre><code>$ gcloud auth login --update-adc\n$ pypi-auth\n</code></pre></p>"},{"location":"analyse/knast/nettverk/#gcloud-auth-login-update-adc","title":"gcloud auth login --update-adc","text":"<p>Med denne kommandoen logger du inn p\u00e5 Google Cloud med din personlige bruker og oppdaterer Application Default Credentials (ADC).</p>"},{"location":"analyse/knast/nettverk/#pypi-auth","title":"pypi-auth","text":"<p>Denne kommandoen vil konfigurere .netrc filen i ditt $HOME directory for pypi artifact registry ved \u00e5 bruke en autentiseringsn\u00f8kkel som er hentet fra gcloud auth login --update-adc. Denne n\u00f8kkelen er kortlevd, 1 time, og du m\u00e5 oppdatere den etter denne perioden ved \u00e5 kj\u00f8re pypi-auth p\u00e5 nytt.</p>"},{"location":"analyse/notebook/","title":"Hva er Jupyter notebooks?","text":"<p>En Jupyter notebook er analytikerens fremste redskap for \u00e5 utforske og analysere data. Plattformen st\u00f8tter innlesing av dataprodukter registrert p\u00e5 Datamarkedsplassen og andre kilder, eksempelvis datavarehus (via KNADA).</p> <p>Jupyter notebooks er et godt verkt\u00f8y for \u00e5 utforske og finne innsikt i data. Deling av innsikt med andre kan enkelt gj\u00f8res med en datafortelling.</p>"},{"location":"analyse/notebook/generelt/","title":"Generelle r\u00e5d","text":""},{"location":"analyse/notebook/generelt/#sette-opp-nbstripout-i-notebook","title":"Sette opp nbstripout i notebook","text":"<p>nbstripout er et verkt\u00f8yet som s\u00f8rger for at output celler i Jupyter notebooks utelates fra Git commits.</p> <p>For \u00e5 unng\u00e5 at output celler fra Jupyter notebooks blir pushet sammen med kode til Github anbefaler vi \u00e5 installere nbstripout. Dette verkt\u00f8yet m\u00e5 installeres alle stedet du har repoet sjekket ut.</p> <p>For \u00e5 ta dette i bruk i din notebook:</p> <ul> <li><code>pip install nbstripout --user</code></li> <li>Kj\u00f8r kommandoen <code>nbstripout --install --global</code> fra repoet ditt lokalt</li> </ul>"},{"location":"analyse/notebook/generelt/#autentisering-mot-gcp","title":"Autentisering mot GCP","text":"<p>Vi anbefaler alle \u00e5 l\u00e6re seg \u00e5 bruke sin personlige bruker fra Jupyter notebooks, dette for \u00e5 sikre seg at man bruker kun de tilgangene man selv skal ha.</p>"},{"location":"analyse/notebook/generelt/#personlig-bruker","title":"Personlig bruker","text":"<ol> <li>I notebooken, \u00e5pne en terminal</li> <li>Kj\u00f8r kommandoen <code>gcloud auth login --update-adc</code></li> <li>G\u00e5 til lenken som vises i terminalen og logg inn med NAV-bruker</li> <li>Etter at du har logget inn kopierer du verifikasjonskoden du f\u00e5r inn i terminalen</li> </ol> <p>Etter \u00e5 ha utf\u00f8rt stegene over vil du i din notebook kunne jobbe med dine private Google credentials mot kilder. Denne tilgangen er kun midlertidig, og man m\u00e5 gj\u00f8re dette hver dag.</p>"},{"location":"analyse/notebook/generelt/#service-account","title":"Service account","text":"<p>Warning</p> <p>Dette gjelder kun for managed notebooks. Bruker du KNADA notebook, se autentisering med personlig bruker.</p> <p>En fersk managed notebook vil automatisk autentisere seg mot GCP-tjenester med service accountens credentials. Det betyr at man er tilkoblet GCP med en service accounten ut av boksen n\u00e5r man starter opp en notebook. Bruker du denne service accounten, s\u00e5 er det denne brukeren som m\u00e5 f\u00e5 tilgang til kildene du skal snakke med.</p> <p>Hvis du p\u00e5 et tidspunkt har logget p\u00e5 GCP med din personlige bruker fra notebooken, og har behov for \u00e5 bytte tilbake kan du f\u00f8lge oppskriften nedenfor.</p> <ol> <li>Sjekk hvilken bruker som er aktiv med <code>gcloud auth list</code>.</li> <li>Hvis det er din personlige, velg service accounten ved \u00e5 kj\u00f8re <code>gcloud config set account &lt;eposten til service accounten din&gt;</code>.</li> <li>Fjern tilgangen til din personlige bruker ved \u00e5 kj\u00f8re <code>gcloud auth application-default revoke --account &lt;din personlige nav-epost&gt;</code>.</li> </ol>"},{"location":"analyse/notebook/generelt/#tilpasse-oracle-connector-for-raskere-sprringer","title":"Tilpasse Oracle connector for raskere sp\u00f8rringer","text":"<p>Ved \u00e5 justere <code>arraysize</code> og <code>prefetchrows</code> kan sp\u00f8rringer mot Oracle databaser onprem forbedres markant! Se dokumentasjonen til oracledb-biblioteket for mer informasjon.</p>"},{"location":"analyse/notebook/generelt/#jupyter-extensions","title":"Jupyter extensions","text":"<p>Du kan installere extensions til Jupyter selv p\u00e5 samme m\u00e5te som du installere Python pakker. Etter man har installert en extension m\u00e5 du stoppe notebooken og starte den p\u00e5 nytt.</p> <p>Eksempel for <code>Git-extension</code> i KNADA:</p> <pre><code>pip install --upgrade jupyterlab jupyterlab-git --user\n</code></pre>"},{"location":"analyse/notebook/generelt/#bruk-av-github-advanced-security-og-dependabot-for-notebook-servere","title":"Bruk av Github Advanced Security og Dependabot for notebook servere","text":"<p>Dependabot st\u00f8tter per i dag ikke R, denne oppskriften funker kun for de som bruker kun spr\u00e5kene Ruby, JavaScript, Python, PHP, Dart, Elixir, Elm, Go, Rust, Java og .NET.</p> <p>Vi oppfordrer Jupyter notebook brukere til \u00e5 ha en <code>requirements.txt</code> fil med Python-bibliotekene som dere selv bruker i et Github-repo. Alle repoer i <code>navikt</code> har automatisk aktivert Github Advanced Security inkludert Dependabot. For \u00e5 enable security scan av en requirements.txt fil, m\u00e5 man lage en <code>dependabot.yml</code> fil i repoet under mappen <code>.github</code>, alts\u00e5: <pre><code>.github\n\u2514\u2500\u2500 dependabot.yml\nrequirement.txt\n</code></pre></p> <p>Under er et eksempel p\u00e5 en slik fil som vil scanne en requirements.txt fil p\u00e5 rotniv\u00e5 i repo ukentlig: <pre><code>version: 2\nupdates:\n  - package-ecosystem: \"pip\"\n    directory: \"/\"\n    schedule:\n      interval: \"weekly\"\n    groups:\n      pip:\n        patterns:\n        - '*'\n</code></pre> Bruker man dette vil man f\u00e5 varsler om s\u00e5rbarheter i bibliotekene som er i bruk, samt at det automatisk blir generert pull requests i repoet med versjon av biblioteket hvor s\u00e5rbarheten er fikset.</p> <p>Dersom man bygger egne Dockerimages for Jupyter eller Airflow tilbyr Dependabot ogs\u00e5 automatisk scanning etter s\u00e5rbarheter for disse.</p> <p>En kan ogs\u00e5 aktivere CodeQL for repoet som analyserer koden din og genererer alerts ved s\u00e5rbarheter. Se her for informasjon om oppsett av CodeQL.</p>"},{"location":"analyse/notebook/generelt/#autentisering-mot-github","title":"Autentisering mot Github","text":"<p>Det finnes flere m\u00e5ter \u00e5 autentisere seg mot Github, men vi anbefaler \u00e5 enten bruke SSH-n\u00f8kler eller fine-grained personal access tokens (PAT).</p> <p>Er du usikker p\u00e5 hva du trenger s\u00e5 anbefaler vi at du starter med fine-grained PAT med en varighet p\u00e5 7 dager. Da har du nok tid til \u00e5 utforske Jupyter, men ingen risiko for at dine tilgangsn\u00f8kler blir liggende til evig tid p\u00e5 Jupyter hvis du glemmer \u00e5 rydde opp.</p>"},{"location":"analyse/notebook/generelt/#ssh-nkkel","title":"SSH-n\u00f8kkel","text":"<p>Ved \u00e5 bruke SSH-n\u00f8kler s\u00e5 lager man et n\u00f8kkelpar, hvor Github f\u00e5r din offentlige n\u00f8kkel, og man har sin private n\u00f8kkel lagret i Jupyter notebooken sin. Vi anbefaler p\u00e5 det sterkeste \u00e5 ha en egen n\u00f8kkel for Jupyter, da kan man enkelt trekke tilbake tilgangen hvis den blir slettet, eller havner p\u00e5 avveie.</p> <p>Du kan f\u00f8lge Github sin Generating a new SSH key, eller kj\u00f8rende kommandoen nedenfor. Vi anbefaler \u00e5 bruke passord p\u00e5 SSH n\u00f8kkelen, dette er p\u00e5krevd for SSH-n\u00f8kler p\u00e5 lokal maskin.</p> <pre><code>ssh-keygen -t ed25519 -C \"din_epost_email@nav.no\"\n</code></pre> <p>Etter at du har generet et eget n\u00f8kkelpar m\u00e5 du legge den offentlige delen inn hos Github. Du kan f\u00f8lge Github sin Adding a new SSH key to your account, eller g\u00e5 direkte til SSH and GPG keys, og trykke p\u00e5 <code>New SSH key</code>.</p> <p>Etterp\u00e5 kan du bruke <code>git</code> som vanlig og klone ned med <code>SSH</code>-adressen (git@github.com:navikt/ditt-repo.git).</p> <p>Info</p> <p>SSH-n\u00f8kler m\u00e5 ligge i katalogen <code>~/.ssh</code> og kun lesbar av deg. Sette filrettigheter med <code>chmod 600 ~/.ssh/id_ed25519</code>.</p>"},{"location":"analyse/notebook/generelt/#whitelisting-av-port-22-mot-github","title":"Whitelisting av port 22 mot Github","text":"<p>Som default s\u00e5 har vi kun lagt til brannmur\u00e5pning mot Github p\u00e5 port 443. Du kan enten legge til en \u00e5pning mot  Github p\u00e5 port 22, eller f\u00f8lge denne guiden: https://docs.github.com/en/authentication/troubleshooting-ssh/using-ssh-over-the-https-port</p>"},{"location":"analyse/notebook/generelt/#fine-grained-pat","title":"Fine-grained PAT","text":"<p>Personal access tokens brukes for \u00e5 lage et token med en bestemt varighet, som gir alle som har ditt token mulighet til \u00e5 koble seg til Github. Med fine-grained tokens kan man spesifisere mer detaljert hva man skal ha tilgang til, for eksempel spesifisere hvilke Github repo man skal ha tilgang til.</p> <p>G\u00e5 til New fine-grained personal access token for \u00e5 komme i gang. Merk at du vil ikke kunne hente ut en PAT etter den har blitt generert, s\u00e5 hvis du mister den s\u00e5 er det bare \u00e5 rotere tokenet.</p> <p>For \u00e5 bruke PAT i Jupyter kan du opprette filen <code>.netrc</code> i ditt hjemmeomr\u00e5de i Jupyter med f\u00f8lgende innhold:</p> <pre><code>machine github.com login &lt;PAT&gt;\n</code></pre> <p>Etterp\u00e5 kan du bruke <code>git</code> som vanlig og klone ned med <code>HTTPS</code>-adressen (https://github.com/navikt/ditt-repo.git)</p>"},{"location":"analyse/notebook/knada-notebook/","title":"KNADA notebooks","text":"<p>KNADA notebooks bestilles gjennom Knorten. Disse notebookene kj\u00f8rer i et managed Kubernetes cluster i GCP som driftes av NADA.</p>"},{"location":"analyse/notebook/knada-notebook/#installasjon-av-python-pakker","title":"Installasjon av Python-pakker","text":"<p>For KNADA notebooks vil det kun v\u00e6re de Python-pakkene som blir lagret under <code>user</code>-stien som blir persistert n\u00e5r Notebook-en sl\u00e5s av. Derfor er det n\u00f8dvendig \u00e5 bruke <code>--user</code> flagget n\u00e5r du installere Python-pakker.</p> <p>Pakkeinstallasjon g\u00e5r gjennom en proxy s\u00e5 du er avhengig av \u00e5 autentisere deg mot GCP med <code>gcloud auth login --update-adc</code> for \u00e5 kunne installere pakker.</p> <pre><code>pip install google-cloud-bigquery --user\n</code></pre> <p>Glemmer du \u00e5 bruke <code>--user</code>, s\u00e5 blir pakkene installert globalt, og de vil forsvinne n\u00e5r notebook-en din blir skrudd av. Har du behov for \u00e5 ha globalt installerte pakker anbefaler vi at du bruker ditt eget Jupyter notebook image.</p>"},{"location":"analyse/notebook/knada-notebook/#automatisk-avslaing-av-notebook","title":"Automatisk avsl\u00e5ing av notebook","text":"<p>For \u00e5 spare ressurser vil en Jupyter notebook automatisk blir skrudd av etter en times inaktivitet. Har man behov for lengre levetid kan man spesifisere dette gjennom Knorten i feltet <code>Cull Timeout</code>.</p> <p>Du kan se ressursbruken din i Grafana/Jupyter notebook utilization.</p>"},{"location":"analyse/notebook/knada-notebook/#python-milj","title":"Python-milj\u00f8","text":"<p>N\u00e5r man logger inn i Jupyter s\u00e5 f\u00e5r man mulighet til \u00e5 velge hvilket Python milj\u00f8 man \u00f8nsker i sin notebook. Vi f\u00f8lger Python Release Cycle for imagene v\u00e5re. Det betyr at vi lager et image per Python-versjon som ikke har statusen end-of-life, og som ogs\u00e5 er st\u00f8ttet av Jupyter (se Docker Hub). Samtlige av image-ene man kan velge mellom kommer med drivere for oracle, postgres og TDV installert.</p>"},{"location":"analyse/notebook/knada-notebook/#eget-image-for-jupyter-notebook","title":"Eget image for Jupyter notebook","text":"<p>Har du behov for noe mer enn det vi tilbyr ut av boksen kan du lage ditt eget Jupyter notebook image. Ta gjerne utgangspunkt i v\u00e5rt image med den Python-versjonen du \u00f8nsker. Gj\u00f8r du det f\u00e5r du drivere for oracle, postgres og TDV, samt de vanligste kommandolinjeverkt\u00f8yene som er hendige \u00e5 ha i en notebook allerede installert.</p> <p>N\u00e5r du har laget et image kan du selv spesifisere at det er dette imaget som skal brukes for teamet ditt i Knorten.</p> <p>NB: Hvis du bygger image lokalt p\u00e5 en nyere Mac s\u00e5 er det viktig at du bygger imaget for riktig plattform. Legg til <code>--platform linux/amd64</code> i <code>docker build</code> kommandoen.</p>"},{"location":"analyse/notebook/knada-notebook/#eksempel-pa-dockerfile","title":"Eksempel p\u00e5 Dockerfile","text":"<p>La oss si at du har en <code>requirements.txt</code> fil med Python-pakker som under:</p> <pre><code>backoff==2.0.1\noracledb&gt;=1.4.2\ndatastory&gt;=0.1.12\ngoogle-cloud-bigquery&gt;3.0.0\ngoogle-cloud-storage==2.4.0\ngreat-expectations==0.15.34\ninfluxdb==5.3.1\n</code></pre> <p>Da kan du med f\u00f8lgende <code>Dockerfile</code> installere disse pakkene n\u00e5r du bygger ditt image:</p> <pre><code>FROM ghcr.io/navikt/knada-images/jupyter:2023-06-16-738148c-3.10\n\nUSER root\n\nCOPY requirements.txt requirements.txt\nRUN pip install -r requirements.txt\n\nUSER $NB_USER\n</code></pre>"},{"location":"analyse/notebook/knada-notebook/#lagring-av-image","title":"Lagring av image","text":"<p>Du kan selv velge om du \u00f8nsker \u00e5 lagre imaget ditt i Google Artifact Registry (GAR) eller i Github Container Registry (GHCR). I dette navikt/knada-image-eksempel er det eksempler p\u00e5 hvordan \u00e5 bygge et docker image og pushe til begge to docker repositories.  Begge pipelinene bygger image med samme Dockerfile og requirements.txt.</p> <p>N\u00e5r du s\u00e5 har bygget image ditt finner du det igjen ved \u00e5:</p> <ul> <li>For GAR - G\u00e5 til nais management og let opp teamet ditt.</li> <li>For GHCR - G\u00e5 til packages og s\u00f8k p\u00e5 repo navnet ditt.</li> </ul>"},{"location":"analyse/notebook/knada-notebook/#lese-hemmeligheter-fra-google-secret-manager","title":"Lese hemmeligheter fra Google Secret Manager","text":"<p>Du kan lese mer om hemmeligheter under Google Secret Manager.</p>"},{"location":"analyse/notebook/knada-notebook/#lagring-av-data","title":"Lagring av data","text":"<p>Data lagres i et omr\u00e5de som opprettes per team og teammedlem. Omr\u00e5dene blir ikke slettet n\u00e5r en Jupyter-instans fjernes eller n\u00e5r teammedlemmer forlater teamet, men kun n\u00e5r hele teamet slettes. N\u00e5r man installerer Jupyter-instansen p\u00e5 nytt, f\u00e5r man ogs\u00e5 tilgang til dataene igjen.</p> <p>V\u00e6r forsiktig med data som er lagret i .ipynb-filer n\u00e5r du bruker git. Se v\u00e5re generelle r\u00e5d.</p>"},{"location":"analyse/notebook/knada-notebook/#restarte-server","title":"Restarte server","text":"<p>For manuelt \u00e5 restarte en Jupyter notebook g\u00e5r man til kontrollpanelet ved \u00e5 velge <code>File</code> -&gt; <code>Hub Control Panel</code> -&gt; <code>Stop My Server</code>. Etter at serveren er stoppet vil man s\u00e5 kunne trykke <code>Start My Server</code>.</p> <p>Dersom jupyterhubben din har fryst seg og du ikke har mulighet til \u00e5 gj\u00f8re det over kan du g\u00e5 direkte til kontroll panelet hvis du g\u00e5r til stien <code>/hub/home</code> i nettleseren</p>"},{"location":"analyse/notebook/knada-notebook/#trafikk-fra-notebooks","title":"Trafikk fra notebooks","text":"<p>Man m\u00e5 eksplisitt oppgi hvilke hoster man \u00f8nsker \u00e5 snakke med fra notebooks i KNADA. Dette spesifiserer du gjennom knorten.</p> <p>Tilsvarende som for airflow legger du inn hostnavn og port p\u00e5 formatet <code>hostnavn:port</code>. Dersom man ikke angir port vil vi bruke <code>443</code> som standardport. Vi har en controller kj\u00f8rende i KNADA som vil lage en <code>NetworkPolicy</code> som tillater trafikk ut fra notebooken mot de hostene som legges til. N\u00e5r notebooken din sl\u00e5s av vil tilgangene bli fjernet.</p>"},{"location":"analyse/notebook/managed-notebook/","title":"Google managed notebooks","text":"<p>Vertex AI Workbench is a Jupyter notebook-based development environment for the entire data science workflow.  You can interact with Vertex AI and other Google Cloud services from within a Vertex AI Workbench instance's Jupyter notebook.</p> <p>Du finner den offisielle dokumentasjonen for managed notebooks hos cloud.google.com.</p> <p>Nedenfor har vi et forslag til innstillinger som passer for de fleste brukere.</p> <p>Det er mange ulike konfigurasjonsmuligheter for notebooks og man st\u00e5r fritt til \u00e5 sette de opp med de innstillingene man selv \u00f8nsker, men merk s\u00e6rlig det som presiseres under maskintype og GPU.</p> <p>Det er ogs\u00e5 kostnadsbesparende \u00e5 skru av notebooken p\u00e5 slutten av arbeidsdagen med mindre man trenger \u00e5 ha noe kj\u00f8rende utenfor arbeidstid.</p> Team-prosjekt notebook <p>Team-prosjekt</p> <p>Dette vil v\u00e6re en notebook server som settes opp i GCP prosjektet til teamet ditt. Man kan til enhver tid se hvilke prosjekter man er medlem av ved \u00e5 g\u00e5 til GCP Billing.</p> <ol> <li>Velg riktig prosjekt for teamet ditt i GCP Cloud console. Dette velger du i nedtrekksmenyen \u00f8verst til venstre.</li> <li>G\u00e5 s\u00e5 til Vertex-AI/Workbench</li> <li>Velg New Notebook og velg Customize</li> <li>Under Properties, spesifiser f\u00f8lgende:<ul> <li>Notebook name - Navn p\u00e5 kladdeboka</li> <li>Velg region og zone i Europe</li> </ul> </li> <li>Under Environment spesifiser f\u00f8lgende<ul> <li>Environment - med mindre man har spesielle behov kan man her velge et av Python-milj\u00f8ene</li> </ul> </li> <li>Under Permission and security<ul> <li>Under Access to JupyterLab velg<ul> <li>Single user only hvis det kun er du som skal ha tilgang til notebooken</li> <li>Service account hvis alle i teamet skal ha tilgang</li> </ul> </li> </ul> </li> <li>Trykk Create nederst</li> <li>N\u00e5r maskinen er ferdig laget, kan du finne og trykke p\u00e5 Open Jupyterlab for din notebook fra Workbench for \u00e5 f\u00e5 tilgang.</li> </ol>"},{"location":"analyse/notebook/managed-notebook/#maskintype-og-gpu","title":"Maskintype og GPU","text":"<p>Det er du som vet best hva du trenger, derfor er det ingen begrensninger p\u00e5 hva du kan velge av maskin og GPU. Bare husk at det kan bli veldig kostbart hvis du lar en maskin (med mye minne og GPU) st\u00e5 uten at den blir brukt.</p> <p>Merk ogs\u00e5 at notebooks som kj\u00f8rer i regionen north/Finland ikke har tilgang til GPU.</p>"},{"location":"analyse/notebook/managed-notebook/#stoppe-en-maskin","title":"Stoppe en maskin","text":"<p>Vi anbefaler alle \u00e5 stoppe maskinene utenom arbeidstid og n\u00e5r de ikke er i bruk. Stopping er ikke det samme som sletting, s\u00e5 alt er der n\u00e5r du starter den opp igjen.</p> <p>Velg maskinen i Vertex AI i oversikten og trykk STOP i toppen.</p>"},{"location":"analyse/notebook/managed-notebook/#slette-en-maskin","title":"Slette en maskin","text":"<p>Har du en maskin du ikke trenger lenger, s\u00e5 kan du slette den.</p> <p>Velg maskinen i Vertex AI i oversikten og trykk DELETE i toppen.</p>"},{"location":"analyse/notebook/managed-notebook/#installasjon-av-databasedrivere","title":"Installasjon av databasedrivere","text":"<p>For \u00e5 bruke python biblioteker til \u00e5 lese fra postgres og oracle kreves det at drivere for det er installert p\u00e5 notebook serveren. Dersom man bruker en Knada Notebook s\u00e5 kommer det milj\u00f8et man jobber i der allerede med disse driverne installert. Men dersom man jobber i en GCP Managed Notebook m\u00e5 man manuelt installere disse driverne.</p> <p>For \u00e5 gj\u00f8re det enkelt for dere \u00e5 komme i gang har vi lagd to scripts som begge m\u00e5 kj\u00f8res med root privilegier.</p> <p>Kj\u00f8r derfor f\u00f8rst kommandoen: <pre><code>sudo -i\n</code></pre></p>"},{"location":"analyse/notebook/managed-notebook/#postgres","title":"Postgres","text":"<p>Trenger du Postgres, lim inn f\u00f8lgende i terminalen din: <pre><code>apt-get update &amp;&amp; apt-get install -yq --no-install-recommends libpq-dev\n</code></pre></p>"},{"location":"analyse/notebook/managed-notebook/#oracle","title":"Oracle","text":"<ol> <li>Lag en tom fil og kall den setup_nb.sh</li> <li>Lim inn f\u00f8lgene kodesnutt: <pre><code>apt-get update &amp;&amp; apt-get install -yq --no-install-recommends \\\n    build-essential \\\n    curl \\\n    alien \\\n    libaio1 \\\n    libaio-dev &amp;&amp; \\\n    apt-get clean &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\ncurl https://download.oracle.com/otn_software/linux/instantclient/215000/oracle-instantclient-basic-21.9.0.0.0-1.x86_64.rpm &gt; /tmp/oracle-instantclient-basic-21.9.0.0.0-1.x86_64.rpm\n\nalien -i /tmp/oracle-instantclient-basic-21.9.0.0.0-1.x86_64.rpm &amp;&amp; \\\n    rm -rf /var/cache/yum &amp;&amp; \\\n    rm -f /tmp/oracle-instantclient-basic-21.9.0.0.0-1.x86_64.rpm &amp;&amp; \\\n    echo \"/usr/lib/oracle/21.9/client64/lib\" &gt; /etc/ld.so.conf.d/oracle-instantclient21.9.conf &amp;&amp; \\\n    /usr/sbin/ldconfig\n\nPATH=$PATH:/usr/lib/oracle/21.9/client64/bin\n</code></pre></li> </ol> <p>N\u00e5 vil skriptet installere versjon 21.9 av oracle klienten. Dersom du i stedet \u00f8nsker en annen versjon kan editere skriptet over med den versjonen du \u00f8nsker. Du finner en liste over tilgjengelige versjoner av oracle klienten her.</p>"},{"location":"dataprodukter/","title":"Kom i gang","text":""},{"location":"dataprodukter/#flytte-data-til-bigquery","title":"Flytte data til BigQuery","text":"<p>For \u00e5 flytte data til BigQuery m\u00e5 man f\u00f8rst ha tilgang til et prosjekt i GCP. Et s\u00e5nt prosjekt er typisk et NAIS-team, les mer om det i NAIS-dokumentasjonen. For \u00e5 f\u00e5 tilgang til GCP m\u00e5 man legge til Google Cloud Platform i myapps.microsoft.com.</p>"},{"location":"dataprodukter/#data-pa-innsiden-og-pa-utsiden","title":"Data p\u00e5 innsiden og p\u00e5 utsiden","text":"<p><code>Data p\u00e5 innsiden</code> = Teamets interne modell for \u00e5 levere verdi til brukerne innenfor domenet og endres typisk ofte.</p> <p><code>Data p\u00e5 utsiden</code> = Analytiske data som er mer stabile: Kan v\u00e6re begrenset til eget bruk i teamet.</p> <p>Teamene velger selv hvordan de etablerer skillet mellom innsiden og utsiden. Noen team velger \u00e5 flytte mer av data p\u00e5 innsiden ut til BigQuery, og s\u00e5 sammenstille og bearbeide data videre til analytiske produkter i BigQuery. \"R\u00e5sonen\" er der fortsatt en del av teamets interne modell. Figuren under illustrerer hvordan arkitekturen kan se ut.</p> <pre><code>flowchart BT\nclassDef tittel_styling font-weight:bold,font-size:14pt,margin:1em\nsubgraph intern[Data p\u00e5 innsiden]\n\nsubgraph Postgres-db\nA[(Tabell 1)]\nB[(Tabell 2)]\nend\n\nsubgraph Oracle-db on-prem\nC[(Tabell n)]\nend\n\nsubgraph Annen kilde\nC_1[(Kafka)]\nC_2[(DB2)]\nend\n\nX[Naisjob for &lt;br&gt; \u00e5 flytte data]\nX_1[Datastream for &lt;br&gt;\u00e5 str\u00f8mme endringer]\nX_2[Federated Query &lt;br&gt; for \u00e5 flytte data]\nX_3[Nais-app for \u00e5 &lt;br&gt; flytte data]\n\nsubgraph BigQuery: R\u00e5sone\nD[(Tabell 1)]\nE[(Tabell 2)]\nF[(Tabell 3)]\nF_2[Tabell m]\nend\nY(Sammenstilling og bearbeiding)\nZ(Bearbeiding)\nZ_1(Sammenstilling og bearbeiding)\nend\nclass intern tittel_styling\n\nsubgraph outside[\"Data p\u00e5 utsiden (BigQuery)\"]\nsubgraph Dataprodukt 1\nH[(Tabell X)]\nend\nsubgraph Dataprodukt 2\nI[(View Y)]\nend\nsubgraph Dataprodukt m\nI_1[(View Z)]\nend\nend\nclass outside tittel_styling\n\nA --&gt; X_1\nB --&gt; X_2\nC_1 --&gt; X_3\nC --&gt; X\nX --&gt; D\nX_1 --&gt; E\nX_2 --&gt; F\nX_3 --&gt; F_2\nD --&gt; Y\nE --&gt; Y\nF --&gt; Z\nF --&gt; Z_1\nF_2 --&gt; Z_1\nY --&gt; H\nZ --&gt; I\nZ_1 --&gt; I_1\n</code></pre> PostgresKafkaOnprem <p>Team bruker i hovedsak Federated Query til \u00e5 flytte data fra Postgres til BigQuery. Dette gj\u00f8res p\u00e5 f\u00f8lgende m\u00e5te:</p> <ol> <li>F\u00e5 tilgang til databasen </li> <li>Sett opp en dataoverf\u00f8ring</li> </ol> <p>Hvordan har andre team l\u00f8st dette?</p> <ul> <li>Team Flex sitt oppsett<ul> <li>Satt opp med Terraform</li> </ul> </li> <li>Digihot sitt oppsett<ul> <li>Kommandolinjeverkt\u00f8y for \u00e5 enkelt opprette BigQuery dataset, connection, og scheduled query</li> </ul> </li> <li>Team Sykmelding sitt oppsett<ul> <li>Satt opp Datastream med Terraform. Laster over alle endringer for aktuelle kolonner i Postgres (change data capture)</li> </ul> </li> <li>Team Risks sitt oppsett<ul> <li>Benytter Naisjob for \u00e5 flytte data</li> </ul> </li> </ul> <p>Kodeeksempler p\u00e5 hvordan du kan flytte data fra Kafka til BigQuery p\u00e5 NAIS finner du ved \u00e5 f\u00f8lge denne lenken.</p> <p>Hvordan har andre team l\u00f8st dette?</p> <ul> <li>Dagpenger sitt oppsett med Kafka Connect<ul> <li>Kubernetes-operator</li> </ul> </li> <li>Digihot sin sink fra Kafka</li> <li>B\u00f8mlo sitt oppsett: Kafka -&gt; Postgres -&gt; BigQuery </li> </ul> <p>Plattformen tilbyr to m\u00e5ter \u00e5 flytte data fra onprem til BigQuery:</p> <ol> <li>Naisjobs</li> <li>Knorten</li> </ol> <p>For \u00e5 lese fra databaser onprem og for \u00e5 f\u00e5 tilgang til \u00e5 skrive til BigQuery fra onprem kan du f\u00f8lge dokumentasjonen.</p> <p>Hvordan har andre team l\u00f8st dette?</p> <ul> <li>ereg dataprodukt</li> <li>aareg dataprodukt</li> <li>paw dataprodukt</li> <li>Helse Arbeidsgivers Naisjob som henter data fra Postgres</li> </ul>"},{"location":"dataprodukter/#opprett-et-dataprodukt","title":"Opprett et dataprodukt","text":"<ol> <li>Legg til et dataprodukt p\u00e5 Datamarkedsplassen</li> <li>(Valgfritt) Gi tilgang til datasett</li> </ol>"},{"location":"dataprodukter/dataprodukt/","title":"Hva er et dataprodukt?","text":"<p>Et dataprodukt best\u00e5r av ett eller flere datasett, samt en overordnet beskrivelse og et konsept om hvem som eier dataproduktet. Dataprodukt opprettes p\u00e5 Datamarkedsplassen (krever innlogging).</p>"},{"location":"dataprodukter/dataprodukt/#hva-er-et-datasett","title":"Hva er et datasett?","text":"<p>Datasett er et konsept i Datamarkedsplassen som beskriver en ekstern ressurs (data), pluss ekstra metadata. I dag kan en ekstern ressurs kun v\u00e6re en tabell eller et view i BigQuery.</p>"},{"location":"dataprodukter/dataprodukt/#metadata-i-et-datasett","title":"Metadata i et datasett","text":"<p>Et datasett inneholder</p> <ul> <li>en beskrivelse</li> <li>en peker til en tabell eller et view i BigQuery; den eksterne ressursen</li> <li>informasjon om hvem som har lesetilgang til den eksterne ressursen, og hvem som har s\u00f8kt om tilgang</li> <li>hvorvidt det eksisterer personopplysninger i den eksterne ressursen</li> <li>lenke til kildekode for det som genererer dataen som finnes i den eksterne ressursen</li> </ul>"},{"location":"dataprodukter/dataprodukt/#tilgangsstyring","title":"Tilgangsstyring","text":"<p>Et datasett er i utgangspunktet tilgangsstyrt. Det betyr at ingen kan se dataen uten at eier har godkjent en s\u00f8knad om tilgang. Les mer om tilgangsstyring.</p>"},{"location":"dataprodukter/kvalitetssikring/","title":"Kvalitetssikre data (Soda)","text":"<p>Vi kan overv\u00e5ke om BigQuery-tabellene st\u00e5r til forventningene v\u00e5re gjennom Soda (ekstern lenke). Sjekker evalueres, Slack-varslinger sendes og resultater tilgjengeliggj\u00f8res n\u00e5r dere endrer bittelitt config i navikt/dp-nada-soda og deployer Naisjoben.</p> <p>Sjekkene defineres i Yaml.</p> <p>Se for eksempel sjekken vi gj\u00f8r for \u00e5 se om tabellen <code>vedtak</code> er oppdatert siste d\u00f8gn ved \u00e5 se p\u00e5 observasjonene i kolonnen <code>innsamlet</code>:</p> <pre><code>checks for vedtak:\n  - freshness(innsamlet) &lt; 1d\n</code></pre> <p>Dokumentasjonen til Soda beskriver godt hvilke sjekker som kommer ut av boksen og hvordan dere kan lage egendefinerte.</p>"},{"location":"dataprodukter/kvalitetssikring/#oppsett-av-dependabot-for-a-automatisk-holde-soda-imaget-oppdatert","title":"Oppsett av Dependabot for \u00e5 automatisk holde Soda-imaget oppdatert","text":"<p>Dersom dependabot ikke kan konfigureres for docker imager som ligger i google artifact registry pusher vi Soda-imaget v\u00e5rt b\u00e5de til GAR og GHCR med samme tag. Men ettersom vi kun kan deploye p\u00e5 nais-platformen med imager lagret i GAR kan f\u00f8lgende fremgangsm\u00e5te benyttes for automatisk \u00e5 holde Soda-imaget oppdatert.</p> <ol> <li>Opprett en dummy Dockerfil p\u00e5 rot i repoet ditt, for eksempel <code>Dockerfile.dummy</code> med f\u00f8lgende innhold:</li> </ol> <p><pre><code>FROM ghcr.io/navikt/nada-soda/soda:2025.06.03-10.46-b16fa04\n</code></pre> 2. Opprett eller editer eksisterende <code>dependabot.yaml</code> i <code>.github</code>-mappen i repoet med f\u00f8lgende innhold:</p> <p><pre><code>version: 2\n\nregistries:\n  ghcr:\n    type: docker-registry\n    url: ghcr.io\n    username: user\n    password: ${{ secrets.READER_TOKEN }}\n\nupdates:\n  - package-ecosystem: \"docker\"\n    registries:\n      - ghcr\n    directory: \"/\"\n    schedule:\n      interval: \"daily\"\n</code></pre> 3. Opprett s\u00e5 en github action <code>.github/workflows/bump_soda_image.yaml</code> med f\u00f8lgende innhold:</p> <pre><code>name: Update Soda Image Tag\non: \n  push:\n    branches:\n      - 'main'\n    paths:\n      - 'Dockerfile.dummy'\n\npermissions:\n  contents: write\n\njobs:\n  deploy:\n    name: Update Soda Image Tag\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Commit tag changes\n        run: |\n          newtag=$(awk -F \"FROM ghcr.io/navikt/nada-soda/soda:\" '{print $2}' Dockerfile.dummy)\n          sed -i \"s|image: .*|image: europe-north1-docker.pkg.dev/nais-management-233d/nada/nada-soda:${newtag}|g\" .nais/naisjob.yaml\n          git config --global user.email ${{ github.actor }}@users.noreply.github.com\n          git config --global user.name ${{ github.actor }}\n          git add .nais/naisjob.yaml\n          git commit -m \"Updated Soda image tag to ${newtag}\"\n          git push\n</code></pre> <p>(forutsetter at manifestet til naisjobben ligger i <code>.nais/naisjob.yaml</code>, endre dette om n\u00f8dvendig) 4. Legg til en <code>workflow_run</code> trigger for github actionen som deployer naisjobben:</p> <pre><code>...\non:\n...\n  workflow_run:\n    workflows:\n      - Update Soda Image Tag\n    types:\n      - completed\n---\n</code></pre>"},{"location":"dataprodukter/tilgangsstyring/","title":"Tilgangsstyring","text":"<p>Datasett er i utgangspunktet kun tilgjengelig for teamet som eier dataene. Det betyr at ingen kan se dataene frem til eier gj\u00f8r et aktivt valg om \u00e5 gi andre tilgang.</p> <p>Dersom datasettet ikke inneholder personopplysninger, kan man ved oppretting av datasett gi tilgang til alle i NAV. I praksis betyr det at folk som har lagt til Google Cloud Platform i myapps.microsoft.com kan se dataen i datasettet.</p>"},{"location":"dataprodukter/tilgangsstyring/#gi-tilgang-til-viewtabell","title":"Gi tilgang til view/tabell","text":"<p>Tilganger gis per view/tabell i BigQuery. Det betyr at team kan ha view/tabeller i BigQuery som er tilgjengelig for forskjellige grupper. N\u00e5r en bruker f\u00e5r tilgang til dataene i et view/tabell, gis de de ogs\u00e5 <code>metadata viewer</code> i BigQuery-datasettet. Dette gir ikke tilgang til andre views/tabeller, men det er mulig \u00e5 se metadata for de andre viewene/tabellene i BigQuery-datasettet.</p> <p>Tilganger til viewene/tabellene som er del av datasettene forvaltes gjennom Datamarkedsplassen.</p> <p>Det er to m\u00e5ter \u00e5 gi tilgang til et datasett p\u00e5.</p>"},{"location":"dataprodukter/tilgangsstyring/#manuelt","title":"Manuelt","text":"<p>Som eier kan man manuelt gi tilgang for en annen bruker, en servicebruker eller ei gruppe. For \u00e5 f\u00e5 tilgang til datasett som inneholder personopplysninger m\u00e5 det finnes en relevant behandling i Behandlingskatalogen.</p> <ul> <li>Navig\u00e9r til datasettet</li> <li>Velg Legg til tilgang under Aktive tilganger-seksjonen</li> <li>Fyll ut skjema<ul> <li>Du kan gi tilgang for en annen bruker, en servicebruker eller ei gruppe. I alle tre tilfellene bruker du e-post-adressen.</li> <li>Du kan velge hvor lenge tilgangen skal vare; til en gitt dato eller for alltid.</li> </ul> </li> </ul>"},{"location":"dataprodukter/tilgangsstyring/#views-og-materialized-views","title":"Views og Materialized Views","text":"<p>N\u00e5r man oppretter Views/Materialized Views i BigQuery vil i utgangspunktet disse kreve at en bruker har tilgang til alle underliggende tabeller som viewet bygger p\u00e5 for \u00e5 kunne lese det. For \u00e5 unng\u00e5 det kan man autorisere viewet i datasett(ene) til de underliggende tabellene viewet bygger p\u00e5. \u00c5 gj\u00f8re dette gir mulighet for \u00e5 kunne gi brukere tilgang til viewet alene, og ikke de underliggende tabellene.</p> <p>N\u00e5r man i Datamarkedsplassen lager et datasett som er et BigQuery View eller Materialized View vil vi automatisk autorisere viewet i BigQuery datasettet til viewet. Det betyr at dersom alle underliggende tabeller finnes i samme BigQuery datasett s\u00e5 kan man uten videre gi tilgang til det p\u00e5 samme m\u00e5te som med tabeller gjennom Datamarkedsplassen. </p> <p>Men dersom viewet bygger p\u00e5 tabeller som ligger i andre BigQuery datasett enn det viewet selv ligger i m\u00e5 man manuelt autorisere viewet i disse BigQuery datasettene ogs\u00e5.</p>"},{"location":"dataprodukter/tilgangsstyring/#godkjenne-en-sknad","title":"Godkjenne en s\u00f8knad","text":"<p>Som eier kan man godkjenne tilgangss\u00f8knader.</p> <ul> <li>Navig\u00e9r til datasettet</li> <li>Under tilgangss\u00f8knader kan du se s\u00f8knader til godkjenning</li> <li>Bekreft at det finnes en relevant behandling i Behandlingskatalogen<ul> <li>Du trenger ikke kvalitetssikre innholdet i behandlingen</li> </ul> </li> <li>Trykk Godkjenn eller Avsl\u00e5<ul> <li>Dersom du avsl\u00e5r en s\u00f8knad har du mulighet til \u00e5 oppgi grunn</li> </ul> </li> </ul>"},{"location":"dataprodukter/tilgangsstyring/#fjern-tilgang","title":"Fjern tilgang","text":"<p>Som eier kan man fjerne tilgang.</p> <ul> <li>Navig\u00e9r til datasettet</li> <li>Under aktive tilganger har du et valg om \u00e5 fjerne tilgang</li> </ul>"},{"location":"dataprodukter/tilgangsstyring/#ske-om-tilgang","title":"S\u00f8ke om tilgang","text":"<p>Dersom man \u00f8nsker \u00e5 f\u00e5 tilgang til et datasett m\u00e5 man i utgangspunktet ha et behandlingsgrunnlag dokumentert i Behandlingskatalogen. For \u00e5 s\u00f8ke om tilgang til et datasett p\u00e5 Datamarkedsplassen:</p> <ul> <li>Navig\u00e9r til datasettet</li> <li>Dersom du ikke har lesetilgang til datasettet er det markert p\u00e5 toppen med en bl\u00e5 linje.</li> <li>Trykk p\u00e5 lenken S\u00f8k om tilgang</li> <li>Fyll ut skjema<ul> <li>Du kan s\u00f8ke om tilgang til deg selv, en annen bruker, en servicebruker eller ei gruppe</li> <li>Du kan velge hvor lenge tilgangen skal vare; til en gitt dato eller for alltid</li> <li>Du kan s\u00f8ke opp en behandling i Behandlingskatalogen ved \u00e5 s\u00f8ke p\u00e5 navnet p\u00e5 behandlingen</li> </ul> </li> </ul>"},{"location":"dataprodukter/tilgangsstyring/#tilgangsstyring-gjennom-datamarkedsplassen","title":"Tilgangsstyring gjennom Datamarkedsplassen","text":"<p>Under er en enkel skisse av hvordan tilgang til datasett i dataprodukter s\u00f8kes om og gis gjennom Datamarkedsplassen. Det er to m\u00e5ter \u00e5 f\u00e5 tilgang til et datasett i Datamarkedsplassen:</p> <ol> <li>En bruker kan initiere dette selv ved \u00e5 opprette en tilgangsforesp\u00f8rsel for enten enkeltbruker, en gruppe eller en service account. Denne tilgangsforesp\u00f8rselen m\u00e5 s\u00e5 godtas av en av eierene av dataproduktet datasettet er en del av. Dersom denne foresp\u00f8rselen godtas vil Datamarkedsplassen gi tilgangen i BigQuery til den eller de brukerene det ble s\u00f8kt om tilgang for.</li> <li>En eier kan ogs\u00e5 gi tilgang til enkeltbrukere, grupper eller service accounts direkte uten at det f\u00f8rst m\u00e5 bli laget en tilgangsforesp\u00f8rsel.</li> </ol> <pre><code>graph LR;\n    user(Bruker)\n    eier(Eier)\n    user==\"S\u00f8k om tilgang &lt;br&gt; til datasett for person, &lt;br&gt; gruppe eller service account\"==&gt;tf\n    eier==\"1: Godta tilgangsforesp\u00f8rsel\"==&gt;ds1\n    eier==\"2: Gi tilgang direkte\"==&gt;ds2\n    tf==&gt;eier\n    subgraph \"Datamarkedsplassen\"\n        subgraph \"Dataprodukt\"\n            tf[Foresp\u00f8rsel]\n            ds1[Datasett]\n            ds2[Datasett]\n        end\n    end\n    subgraph \"Google Cloud\"\n        subgraph \"BigQuery datasett\"\n            t1[Tabell/view]\n            t2[Tabell/view]\n            ds1==\"Gi tilgang til &lt;br&gt; person/gruppe/&lt;br&gt;service account\"==&gt;t1\n            ds2==\"Gi tilgang til &lt;br&gt; person/gruppe/&lt;br&gt;service account\"==&gt;t2\n        end\n    end</code></pre>"},{"location":"dataprodukter/tilgangsstyring/#gi-tilganger-i-gcp-konsoll-direkte","title":"Gi tilganger i GCP konsoll direkte","text":"<p>Dersom du \u00f8nsker \u00e5 se tilganger gitt eller gi tilganger til en bigquery tabell direkte utenom Datamarkedsplassen, se google docs</p>"},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/","title":"Laste data fra kilde til BigQuery","text":""},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#flytte-data-fra-postgres-til-bigquery","title":"Flytte data fra Postgres til BigQuery","text":""},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#datastream","title":"Datastream","text":"<p>Google tilbyr Datastream for \u00e5 str\u00f8mme data fra f.eks. Postgres til BigQuery. Dataen str\u00f8mmes til en samling (<code>dataset</code>) i BigQuery hvor kun teamet har tilgang. Fra samlingen kan man gj\u00f8re transformasjoner og gj\u00f8re tabeller/view klare for bruk internt i teamet. Tabeller/view kan ogs\u00e5 tilgjengeliggj\u00f8res for andre.</p> <p>Vi anbefaler at <code>diskAutoresize</code> for Postgres-databasen settes til <code>true</code> siden Datastream bruker en del lagringsplass.</p>"},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#hjelp-til-oppsett-av-datastream","title":"Hjelp til oppsett av Datastream","text":"<p>Det er laget to l\u00f8sninger i Nav for \u00e5 forenkle oppsett av dette. Vi anbefaler bruk av terraform-modulen.</p> <p>Link til terraform-modul</p> <p>Link til cli</p> <pre><code>flowchart LR\n    A[(Postgres 1)] --&gt; C(Datastream)\n    B[(Postgres 2)] --&gt; C\n\n    C --&gt; D\n    C --&gt; E\n    D --transformasjon--&gt; F\n    E --transformasjon--&gt; G\n\n\n    subgraph BigQuery\n       D[(Tabell 1)]\n       E[(Tabell 2)]\n\n       F[(Dataprodukt 1)]\n       G[(Dataprodukt 2)]\n    end</code></pre>"},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#federated-query","title":"Federated query","text":"<p>Federated query brukes typisk til \u00e5 lese data fra en postgres-database i GCP, transformere disse og skrive til BigQuery.</p> <pre><code>graph TD\npostgres[(Postgres)] --Sp\u00f8rring mot Postgres-database i GCP--&gt; federated_query[Federated query]\nfederated_query --Ytterligere transformasjoner kan gj\u00f8res i BigQuery--&gt; BQ_query[BQ-query]\nSchedule --Regelbasert styring av kj\u00f8ringen--&gt; BQ_query\nBQ_query --Tabell skrives til BigQuery--&gt; BigQuery[(BigQuery-tabell)]</code></pre> <p>For \u00e5 sette opp federated query:</p> <ol> <li>F\u00f8lg Google sin guide for \u00e5 sette opp Cloud SQL databasetilkobling</li> <li> <p>Gi generert service account roller for \u00e5 kunne utf\u00f8re external queries</p> <ul> <li>N\u00e5r man i (1) aktiverer <code>BigQuery Connection API</code> blir det automatisk generert en service account p\u00e5 formatet <code>service-&lt;projectNumber&gt;@gcp-sa-bigqueryconnection.iam.gserviceaccount.com</code>. Denne m\u00e5 gis f\u00f8lgende roller i prosjektet:<ul> <li><code>Bigquery Connection Admin</code></li> <li><code>Cloud SQL Client</code></li> </ul> </li> </ul> <p><code>projectNumber</code> over er prosjektnummeret, ikke prosjekt ID. Du finner prosjektnummer her.</p> </li> <li> <p>F\u00f8lg Google sin guide for \u00e5 opprette et BigQuery dataset</p> <ul> <li>Merk at dataset i denne konteksten er noe annet enn datasett i Datamarkedsplassen</li> <li>Forel\u00f8pig kan vi ikke gjenbruke datasets som har blitt opprettet av en nais-applikasjon, da denne overstyrer tilgangene vi oppretter senere i denne guiden</li> </ul> </li> <li>F\u00f8lg Google sin guide for \u00e5 lage en Google servicebruker for \u00e5 kj\u00f8re en skedulert federated query<ul> <li>Gi serviceaccounten f\u00f8lgende tilganger p\u00e5 prosjektniv\u00e5:<ul> <li>BigQuery Connection User</li> <li>BigQuery Job User</li> <li>BigQuery Metadata Viewer</li> </ul> </li> </ul> </li> <li>F\u00f8lg Google sin guide for \u00e5 gi tilganger til servicebrukeren p\u00e5 datasett<ul> <li>Serviceaccounten trenger rollen BigQuery Data Editor</li> </ul> </li> </ol> <p>Etter at servicebrukeren har tilgang til datasettet kan man sette opp en sp\u00f8rring som henter data via external connection.</p> <p>Gjennom Google Cloud Console kan man velge prosjektet som datasettet tilh\u00f8rer, g\u00e5 inn p\u00e5 BigQuery og klikke \"Compose New Query\" til h\u00f8yre.</p> <p>Eksempelvis: <pre><code>SELECT * FROM EXTERNAL_QUERY(\n'europe-north1.&lt;connection_name&gt;',\n'''\n\n-- Lag en variabel for versjonering \nWITH constants (version) as (\n    values (now())\n)\n\n-- Legg inn rader fra Postgres-tabellen med et felt for version-variablen vi definerte over.\nSELECT \n    id::text, \n    name, \n    \"group\", \n    pii, \n    created, \n    last_modified, \n    \"type\"::text, \n    version\nFROM dataproducts, constants\n''');\n</code></pre></p>"},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#kjre-sprring-pa-tidsintervall","title":"Kj\u00f8re sp\u00f8rring p\u00e5 tidsintervall","text":"<p>For \u00e5 kj\u00f8re en sp\u00f8rring p\u00e5 intervall, s\u00e5 kan du i Query Explorer i Cloud Console velge \u00e5 definere en \"Schedule\".</p> <p>For \u00e5 f\u00e5 lov til \u00e5 sette opp eller oppdatere en schedule m\u00e5 din personlige bruker ha noen rettigheter ogs\u00e5.  Disse er for det meste dekket av Bigquery Admin, men hvis du setter opp jobben med en servicebruker (anbefalt) m\u00e5 du ogs\u00e5 ha tilgang til denne, for eksempel via en midlertidig Service Account Admin.</p> <p>Klikk \"Schedule\" og \"Create new schedule\"</p> <ul> <li>Name: et passende navn </li> <li>Repeats: Det som passer produktet</li> <li>Dataset name: datasettet som ble laget tidligere</li> <li>Table name: navn p\u00e5 produkt-tabell</li> <li>Advanced options:<ul> <li>Service account: servicebrukeren som ble laget tidligere</li> </ul> </li> </ul>"},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#flytte-data-fra-kafka-til-bigquery","title":"Flytte data fra Kafka til BigQuery","text":"<p>For \u00e5 ta data fra en Kafka-str\u00f8m til BigQuery, trenger du \u00e5 sette opp en applikasjon. Under f\u00f8lger enkle eksempler p\u00e5 hvordan \u00e5 lese fra Kafka og skrive til BigQuery i forskjellige programmeringsspr\u00e5k.  Alle eksemplene forutsetter at en p\u00e5 forh\u00e5nd har laget datasettet BigQuery tabellen skal opprettes i og at man har tilgang til \u00e5 skrive til/opprette tabeller i datasettet. Opprettelsen av datasettet og tilgangene ordnes automatisk n\u00e5r appen deployes til GCP-clusterne til nais med nais.yaml. </p>"},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#kodeeksempler","title":"Kodeeksempler","text":"<p>Eksemplene tar ikke hensyn til autentisering mot Kafka s\u00e5 det antas at man kan lese fra kafka topicet anonymt. For mer informasjon om oppsett av app og autentisering for Kafka i NAV, se nais docs.</p> <p>Topicet det leses fra i eksemplene har JSON schema og inneholder fire felter: et tekstfelt, et boolean felt, et numerisk felt og et timestamp.</p> PythonKotlinGo <p>Avhengigheter: <pre><code>pip install google-cloud-bigquery kafka-python\n</code></pre> Kode: <pre><code>from kafka import KafkaConsumer\nfrom google.cloud import bigquery\nimport json\n\ndef create_kafka_consumer(topic: str, kafka_brokers: []) -&gt; KafkaConsumer:\n    return KafkaConsumer(\n        topic,\n        bootstrap_servers=kafka_brokers,\n        api_version=(0, 10),\n        auto_offset_reset='earliest',\n        enable_auto_commit=True,\n        value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n    )\n\n\ndef create_bq_table_if_not_exists(bq_client: bigquery.Client, project_id: str, dataset_id: str, table: str) -&gt; bigquery.Table:\n    table_uri = f\"{project_id}.{dataset_id}.{table}\"\n\n    schema = [\n        bigquery.SchemaField(\"stringValue\", \"STRING\", mode=\"REQUIRED\"),\n        bigquery.SchemaField(\"booleanValue\", \"BOOLEAN\"),\n        bigquery.SchemaField(\"numericValue\", \"INTEGER\"),\n        bigquery.SchemaField(\"timestampValue\", \"TIMESTAMP\"),\n    ]\n\n    table = bigquery.Table(table_uri, schema=schema)\n    return bq_client.create_table(table, exists_ok=True)\n\n\nif __name__ == \"__main__\":\n    project_id = \"PROJECT\" # erstatt med prosjekt id\n    dataset_id = \"DATASET\" # erstatt med dataset id\n    table_name = \"TABLE\" # erstatt med tabellnavn\n    bq_client = bigquery.Client(project=project_id)\n    table_id = create_bq_table_if_not_exists(bq_client, project_id, dataset_id, table_name)\n\n    topic_name = \"TOPIC\" # erstatt med topic navn\n    kafka_brokers = [\"BROKER1\"] # erstatt med liste av brokere\n    consumer = create_kafka_consumer(topic_name, kafka_brokers)\n    for mesg in consumer:\n        print(mesg.value)\n        errors = bq_client.insert_rows_json(table_id, [mesg.value])\n        if errors != []:\n            raise Exception(errors)\n</code></pre></p> <p>Avhengigheter: <pre><code>implementation(\"com.google.cloud:google-cloud-bigquery:2.22.0\")\nimplementation(\"org.apache.kafka:kafka-clients:3.4.0\")\n</code></pre></p> <p>Kode: <pre><code>import com.fasterxml.jackson.databind.JsonNode\nimport com.fasterxml.jackson.databind.ObjectMapper\nimport com.google.cloud.bigquery.*\nimport java.time.Duration\nimport java.util.*\nimport org.apache.kafka.clients.consumer.ConsumerRecords\nimport org.apache.kafka.clients.consumer.KafkaConsumer\nimport java.time.LocalDateTime\nimport java.time.temporal.ChronoUnit\n\nfun main() {\n\n    val bigQueryClient = BigQueryClient()\n\n    val tableId = bigQueryClient.getOrCreateBigQueryTable(\"TABLE\" /* erstatt med tabellnavn */)\n\n    val kafkaConsumer = createKafkaConsumer()\n\n    while (true) {\n        val records: ConsumerRecords&lt;String?, String?&gt; = kafkaConsumer.poll(Duration.ofMillis(100))\n        for (record in records) {\n            storeRecordInBigQuery(record, bigQueryClient, tableId)\n        }\n    }\n}\n\nprivate fun setupBigQueryClient(): BigQueryClient {\nval bqClient = BigQueryClient(projectId, datasetId)\nreturn bqClient\n}\n\nfun createKafkaConsumer(): KafkaConsumer&lt;String, String&gt; {\nval topicName = \"TOPIC\" // erstatt med navn p\u00e5 Kafka topic\nval kafkaBrokers = \"BROKERS\" // erstatt med navn p\u00e5 brokers\nval props = Properties()\nprops.setProperty(\"bootstrap.servers\", kafkaBrokers)\nprops.setProperty(\"group.id\", \"mygroup\")\nprops.setProperty(\"auto.offset.reset\", \"earliest\")\nprops.setProperty(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\")\nprops.setProperty(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\")\n\n    val consumer = KafkaConsumer&lt;String, String&gt;(props)\n    consumer.subscribe(Arrays.asList(topicName))\n\n    return consumer\n}\n\nprivate fun storeRecordInBigQuery(record: ConsumerRecord&lt;String? String?&gt;, bigQueryClient: BigQueryClient, tableId: Unit) {\nSystem.out.printf(\n\"offset = %d, key = %s, value = %s%n\",\nrecord.offset(),\nrecord.key(),\nrecord.value()\n)\nval value = ObjectMapper().readValue(record.value(), JsonNode::class.java)\nbigQueryClient.insert(tableId, value)\n}\n\nclass BigQueryClient() {\nprivate val projectId = \"PROJECT\" // erstatt med prosjektets id\nprivate val datasetId = \"DATASET\" // erstatt med datasett id\nprivate val bigQuery = BigQueryOptions.newBuilder()\n.setProjectId(projectId)\n.build()\n.service\n\n    fun getOrCreateTable(tableName: String): TableId {\n        val tableId = TableId.of(datasetId, tableName)\n        val table = bigQuery.getTable(tableId)\n        return if (table != null) {\n            table.tableId\n        }\n        else {\n            return createTable(tableName)\n        }\n    }\n\n    private fun createTable(tableName: String): TableId {\n        val schema = Schema.of(\n            Field.newBuilder(\"stringValue\", StandardSQLTypeName.STRING).setMode(Field.Mode.REQUIRED).build(),\n            Field.of(\"booleanValue\", StandardSQLTypeName.BOOL),\n            Field.of(\"numericValue\", StandardSQLTypeName.INT64),\n            Field.of(\"timestampValue\", StandardSQLTypeName.TIMESTAMP),\n        )\n\n        val tableId = TableId.of(datasetId, tableName)\n        val tableDefinition = StandardTableDefinition.of(schema)\n        val tableInfo = TableInfo.newBuilder(tableId, tableDefinition).build()\n\n        return bigQuery.create(tableInfo).tableId\n    }\n\n    fun insert(tableId: TableId, value: JsonNode) {\n        val row = InsertAllRequest.RowToInsert.of(mapOf(\n            value.use(\"stringValue\") { textValue() },\n            value.use(\"booleanValue\") { booleanValue() },\n            value.use(\"numericValue\") { intValue() },\n            value.use(\"timestampValue\") { LocalDateTime.parse(asText()).truncatedTo(ChronoUnit.MICROS).toString() },\n        ))\n\n        val table = bigQuery.getTable(tableId)\n        val rows = listOf(row)\n        val response = table.insert(rows)\n        when {\n            response.hasErrors() -&gt; throw RuntimeException(\n                \"Lagring i BigQuery feilet: '${response.insertErrors}'\"\n            )\n        }\n    }\n}\n\nfun &lt;T&gt; JsonNode.use(key: String, transform: JsonNode.() -&gt; T): Pair&lt;String, T?&gt; = key to get(key)?.let {\ntransform(it)\n}\n</code></pre></p> <p>Avhengigheter: <pre><code>go get \"cloud.google.com/go/bigquery\"\ngo get \"github.com/confluentinc/confluent-kafka-go/kafka\"\ngo get \"google.golang.org/api/googleapi\"\n</code></pre></p> <p>Kode: <pre><code>package main\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"os\"\n\n    \"cloud.google.com/go/bigquery\"\n    \"github.com/confluentinc/confluent-kafka-go/kafka\"\n    \"golang.org/x/xerrors\"\n    \"google.golang.org/api/googleapi\"\n)\n\ntype mesg struct {\n    StringValue    string `json:\"stringValue\"`\n    BooleanValue   bool   `json:\"booleanValue\"`\n    NumericValue   int    `json:\"numericValue\"`\n    TimestampValue string `json:\"timestampValue\"`\n}\n\nconst (\n    kafkaBroker = \"BROKER\" // erstatt med kafka broker\n    topicName   = \"TOPIC\" // erstatt med navn p\u00e5 topic\n\n    projectID = \"PROJECT\" // erstatt med prosjekt id\n    datasetID = \"DATASET\" // erstatt med dataset id\n    tableName = \"TABLE\" // erstatt med navn p\u00e5 tabell\n)\n\nfunc main() {\n    ctx := context.Background()\n    consumer, err := createKafkaConsumer()\n    if err != nil {\n        panic(err)\n    }\n    defer consumer.Close()\n\n    bqClient, err := bigquery.NewClient(ctx, projectID)\n    if err != nil {\n        panic(err)\n    }\n    defer bqClient.Close()\n\n    table, err := createTableIfNotExists(ctx, bqClient)\n    if err != nil {\n        panic(err)\n    }\n    inserter := table.Inserter()\n\n    for {\n        event := consumer.Poll(100)\n        switch e := event.(type) {\n        case *kafka.Message:\n            data := mesg{}\n            if err := json.Unmarshal(e.Value, &amp;data); err != nil {\n                panic(err)\n            }\n            fmt.Println(data)\n            if err := inserter.Put(ctx, data); err != nil {\n                panic(err)\n            }\n        case kafka.Error:\n            fmt.Fprintf(os.Stderr, \"%% Error: %v\\n\", e)\n        default:\n            continue\n        }\n    }\n}\n\nfunc createKafkaConsumer() (*kafka.Consumer, error) {\n    consumer, err := kafka.NewConsumer(&amp;kafka.ConfigMap{\n        \"bootstrap.servers\": kafkaBroker,\n        \"group.id\":          \"mygroup\",\n        \"auto.offset.reset\": \"earliest\",\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    err = consumer.SubscribeTopics([]string{topicName}, nil)\n    if err != nil {\n        return nil, err\n    }\n\n    return consumer, nil\n}\n\nfunc createTableIfNotExists(ctx context.Context, bqClient *bigquery.Client) (*bigquery.Table, error) {\n    schema := bigquery.Schema{\n        {Name: \"stringValue\", Type: bigquery.StringFieldType},\n        {Name: \"booleanValue\", Type: bigquery.BooleanFieldType},\n        {Name: \"numericValue\", Type: bigquery.IntegerFieldType},\n        {Name: \"timestampValue\", Type: bigquery.TimestampFieldType},\n    }\n\n    metadata := &amp;bigquery.TableMetadata{\n        Schema: schema,\n    }\n\n    tableRef := bqClient.Dataset(datasetID).Table(tableName)\n    if err := tableRef.Create(ctx, metadata); err != nil {\n        var e *googleapi.Error\n        if ok := xerrors.As(err, &amp;e); ok {\n            if e.Code == 409 {\n                // already exists\n                return tableRef, nil\n            }\n        }\n        return nil, err\n    }\n\n    return tableRef, nil\n}\n</code></pre></p>"},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#naisjob","title":"Naisjob","text":"<p>NAIS-plattformen tilbyr skedulering av workloads med deres naisjob-ressurs.</p> <p>Denne ressurstypen er en abstraksjon p\u00e5 Kubernetes sin Cronjob som gir deg de samme konfigurasjonsmulighetene som man f\u00e5r med NAIS applikasjoner, eksempelvis muligheten til \u00e5 provisjonere buckets, postgres/BigQuery og kafka-brukere, samt injeksjon av hemmeligheter i kj\u00f8remilj\u00f8et til jobben ved runtime.</p>"},{"location":"dataprodukter/dele/dataoverf%C3%B8ring/#bruksomrade","title":"Bruksomr\u00e5de","text":"<p>Naisjob egner seg godt dersom du trenger \u00e5 skedulere kj\u00f8ring av kode, f.eks. periodisk oppdatering av dataprodukter eller datafortellinger.</p>"},{"location":"dataprodukter/dele/dataprodukt/","title":"Registrere dataprodukt","text":"<p>Etter at teamet har laget BigQuery-tabellene med analytiske data, kan disse registreres p\u00e5 Datamarkedsplassen. Dette gj\u00f8res ved at man registrerer <code>datasettet</code> som del av et <code>dataprodukt</code>.</p>"},{"location":"dataprodukter/dele/dataprodukt/#i-dataprodukt","title":"I: Dataprodukt","text":"<p>Dataproduktet er en samling av et eller flere datasett som naturlig h\u00f8rer sammen. Teamet velger selv hvilke tabeller som naturlig h\u00f8rer sammen, men tabellene m\u00e5 v\u00e6re i samme GCP-prosjekt. Dataprodukter registreres p\u00e5 Datamarkedsplassen under <code>Legg til nytt dataprodukt</code> i headeren. Der oppgis navn, beskrivelse, team i Teamkatalogen samt kontaktpunkt til teamet.</p>"},{"location":"dataprodukter/dele/dataprodukt/#ii-datasett","title":"II: Datasett","text":"<p>Datasett legges til ved at man klikker seg inn p\u00e5 et <code>dataprodukt</code> p\u00e5 Datamarkedsplassen. Under <code>Legg til datasett</code> kan man registrere den aktuelle tabellen fra BigQuery sammen med metadata som gj\u00f8r det enklere for teamet \u00e5 beholde oversikten. Metadata gj\u00f8r det ogs\u00e5 enklere for folk utenfor teamet \u00e5 finne dataene. Beskrivelser av kolonnene i tabellen kan legges inn i BigQuery-konsollet. Metadata fra BigQuery (blant annet tabellskjema) synces med Markedsplassen \u00e8n gang i timen.</p> <p>I Markedsplassen vil vi kun vise den metadataen som er i BigQuery. Ettersom views ikke f\u00e5r skjemaet sitt oppdatert i BigQuery som beskrevet her s\u00e5 vil heller ikke oppdateringer i skjemaet for views vises i Markedsplassen. For \u00e5 trigge en oppdatering av skjemaet for et view i BigQuery er man avhengig av \u00e5 oppdatere selve viewet.</p>"},{"location":"dataprodukter/dele/dataprodukt/#pseudonymisering-av-tabeller","title":"Pseudonymisering av tabeller","text":"<p>Team har ofte data om enkeltpersoner der vi trenger identifikatorer for \u00e5 kunne koble tabeller sammen og f\u00f8lge personer over tid. Vi tilbyr en l\u00f8sning for \u00e5 registrere BigQuery-view der valgte kolonner pseudonymiseres. Pseudonymiserte views baserer seg p\u00e5 en hvilken som helst BigQuery-tabell/view i teamets prosjekt. Ved registrering av <code>datasett</code>, kan du velge \u00e5 pseudonymisere tabellen. Du m\u00e5 velge minst \u00e8n kolonne som skal pseudonymiseres. Vi oppretter et eget view i et separat <code>BigQuery-dataset</code> i teamets prosjekt. Her opprettes view der kolonnene er pseuodnymisert. Kolonnene pseudonymiseres med SHA256-algoritmen og en tilfeldig verdi som er forskjellig for hver tabell. Metadata som vises p\u00e5 Markedsplassen inneholder adressen til det pseudonymiserte viewet.</p> <p>Til tross for at tabellene pseudonymiseres med forskjellige verdier, kan de likevel kobles sammen gjennom en tjenesten vi tilbyr for \u00e5 koble sammen pseudonymiserte tabeller.</p>"},{"location":"dataprodukter/dele/f%C3%A5-tilgang/","title":"F\u00e5 tilgang til datakilder","text":""},{"location":"dataprodukter/dele/f%C3%A5-tilgang/#fa-tilgang-til-data-i-sky","title":"F\u00e5 tilgang til data i sky","text":""},{"location":"dataprodukter/dele/f%C3%A5-tilgang/#postgres-gcp","title":"Postgres GCP","text":"<p>For \u00e5 lage dataprodukter med data fra databaser i sky trenger man f\u00f8rst og fremst en bruker for \u00e5 lese data fra databasen. Selv om det er teknisk mulig \u00e5 benytte database-brukernavn og passord fra applikasjoner som har tilgang er dette ikke anbefalt. Oppretting av egen bruker for dette behovet er anbefalt. Det fins to metoder for \u00e5 opprette bruker.</p>"},{"location":"dataprodukter/dele/f%C3%A5-tilgang/#nais-cli","title":"nais-cli","text":"<p>Man kan benytte <code>nais-cli</code> som har en egen kommando for tilgang til postgres-databaser i sky. For \u00e5 opprette en bruker med <code>select</code> privilegier, se dokumentasjon for <code>users add</code></p>"},{"location":"dataprodukter/dele/f%C3%A5-tilgang/#manuelt","title":"Manuelt","text":"<p>For manuell opprettelse av bruker m\u00e5 du f\u00f8rst opprette personlig tilgang til databasen. F\u00f8lg instruksjonene i NAIS-dokumentasjonen for \u00e5 koble til. N\u00e5r du er inne i databasen, oppretter du og gir tilgang til databasebrukeren med kommandoene nedenfor.</p> <pre><code>CREATE USER &lt;brukernavn&gt; WITH ENCRYPTED PASSWORD '&lt;passord&gt;';\nGRANT CONNECT ON DATABASE &lt;databasenavn&gt; TO &lt;brukernavn&gt;;\nGRANT USAGE ON SCHEMA public TO &lt;brukernavn&gt;;\n</code></pre> <p>Videre kan du gi brukeren rettigheter til \u00e5 lese alle tabeller: <pre><code>GRANT SELECT ON ALL TABLES IN SCHEMA public TO &lt;brukernavn&gt;;\n</code></pre></p> <p>eller utvalgte tabeller: <pre><code>GRANT SELECT ON &lt;tabellnavn&gt; TO &lt;brukernavn&gt;;\n</code></pre></p>"},{"location":"dataprodukter/dele/f%C3%A5-tilgang/#fa-tilgang-til-data-on-prem","title":"F\u00e5 tilgang til data on-prem","text":""},{"location":"dataprodukter/dele/f%C3%A5-tilgang/#hvordan-snakke-med-vault-fra-on-prem-naisjob","title":"Hvordan snakke med Vault fra on-prem Naisjob?","text":"<p>N\u00e5r man kj\u00f8rer en Naisjob i on-prem og har hemmeligheter i Vault m\u00e5 disse bli hentet ved oppstart av jobben. Dette kan l\u00f8ses ved bruk av Vault-config i applikasjonsmanifestet. Da vil hemmelighetene dine lastes inn som filer som du kan lese fra din kode. \u00d8nsker du \u00e5 ha de som milj\u00f8variabler s\u00e5 kan dere bruke navikt/baseimages, som har st\u00f8tte for \u00e5 transformere Vault-hemmeligheter som slutter p\u00e5 <code>.env</code> til milj\u00f8variabler.</p>"},{"location":"dataprodukter/dele/f%C3%A5-tilgang/#hvordan-fa-tilgang-til-bigquery-fra-en-naisjob-i-on-prem","title":"Hvordan f\u00e5 tilgang til BigQuery fra en Naisjob i on-prem?","text":"<p>For \u00e5 kunne snakke med BigQuery trenger dere et token for en service account som har tilgang til \u00e5 lese BigQuery. F\u00f8lg guiden Creating a service account hos Google, og s\u00e5 f\u00f8lger dere guiden Creating service account keys.</p> <p>N\u00e5r dette er gjort s\u00e5 ender dere opp med en JSON-fil som er hemmeligheten dere trenger \u00e5 legge inn i Vault, som igjen da blir eksponert i jobben deres. For at Pandas eller andre rammeverk skal plukke denne opp automatisk s\u00e5 m\u00e5 den v\u00e6re eksponert som en milj\u00f8variabel som heter <code>GOOGLE_APPLICATION_CREDENTIALS</code>.</p>"},{"location":"juridisk/dokumentasjon/","title":"Hva trenger jeg av dokumentasjon?","text":""},{"location":"juridisk/dokumentasjon/#det-du-ma-gjre","title":"Det du m\u00e5 gj\u00f8re","text":"<p>Nesten alt du kan gj\u00f8re med en personopplysning er \u00e5 regne som en behandling: se p\u00e5, lagre, flytte, vaske, telle. All behandling er ulovlig med mindre du har et behandlingsgrunnlag.</p> <p>Behandling av personopplysninger krever et s\u00e5kalt rettslig grunnlag (behandlingsgrunnlag) for \u00e5 v\u00e6re lovlig.</p> <p>For \u00e5 kunne behandle data m\u00e5 du ha:</p> <ul> <li>en behandling i Behandlingskatalogen. Se dokumentasjon til registrering</li> <li>grunnleggende personvernavklaringer (GPA) eller tatt stilling til personvernskravene p\u00e5 etterlevelse.intern.nav.no<ul> <li>Dersom behandling av personopplysninger vil medf\u00f8re h\u00f8y risiko, kreves det en personvernkonsekvensvurdering (PVK). Les om kravet p\u00e5 etterlevelse.intern.nav.no.</li> </ul> </li> </ul> <p>Du kan ogs\u00e5 lese mer om behandlinger i playbook for ansvarlig datascience.</p>"},{"location":"juridisk/dokumentasjon/#det-nada-har-gjort-allerede","title":"Det NADA har gjort allerede","text":"<p>Kommentar</p> <p>Hvis du f\u00e5r en feilmelding n\u00e5r du fors\u00f8ker \u00e5 lese ROSene, m\u00e5 du f\u00f8rst be om tilgang til TryggNok.</p> <p>Vi har gjort en rekke risiko- og s\u00e5rbarhetsanalyse (ROS) av verkt\u00f8y som NADA tilbyr, og verkt\u00f8y vi mener er relevant for \u00e5 gj\u00f8re dataanalyser. All ROS er gjort i TryggNok.</p> <ul> <li>Dataanalyseverkt\u00f8y i GCP (ROS #607)</li> <li>KNADA GKE (ROS #1239)</li> <li>Knast (ROS #1884)</li> <li>Datamarkedsplassen (ROS #1005)</li> <li>Metabase (ROS #988)</li> <li>Quarto (ROS #1347)</li> <li>Soda (ROS #1418)</li> <li>Pseudonymiseringsl\u00f8sningen (ROS #1525)</li> </ul> <p>Du kan lese om behandlingene NADA gj\u00f8r i Behandlingskatalogen.</p>"},{"location":"juridisk/dokumentasjon/#andre-relevante-roser","title":"Andre relevante ROSer","text":"<ul> <li>Bruk av Airflow via KNADA-GKE i Datavarehus (ROS #1252)</li> <li>Bruk av Knast mot Datavarehus (ROS #1897)</li> </ul>"},{"location":"juridisk/hvem/","title":"Spilleregler p\u00e5 NADA-plattformen","text":"<p>Vi \u00f8nsker at spillereglene lages sammen med brukerne v\u00e5re, slik at hvert enkelt team gj\u00f8r trygge og gode valg med st\u00f8tte av plattformen.</p>"},{"location":"juridisk/hvem/#roller","title":"Roller","text":"<p>Utformingen av spilleregler gj\u00f8res av et forum satt sammen av ulike perspektiver p\u00e5 Datamarkedsplassen.</p> <ul> <li>Konsument: Representerer verdi fra et analytisk perspektiv</li> <li>Produsent: Representerer verdi fra produsentens st\u00e5sted samt kostnaden av \u00e5 innf\u00f8re spilleregler</li> <li>Plattform: Representerer mulighetsrommet for \u00e5 tilby plattformst\u00f8tte for tiltak</li> <li>Jurist: Representerer verdi i form av compliance</li> <li>Dataambisjonseier: Beslutningsmyndighet og ansvarlig for at spillereglene gir verdi</li> </ul> <p>I tillegg er det avgj\u00f8rende med innspill fra folk utenfor dette forumet.</p>"},{"location":"juridisk/hvem/#prosess","title":"Prosess","text":"<ol> <li>Brukere p\u00e5 plattformen sender innspill i Slack#nada-spilleregler eller direkte til medlemmer av forumet.</li> <li>Innspill diskuteres i forumet, og det utarbeides en architectural decision record. Du kan lese publiserte ADR-dokumenter p\u00e5 GitHub.</li> <li>Brukere p\u00e5 plattformen gir innspill til ADR</li> <li>Beslutning tas i forumet</li> <li>Policy implementeres, fortrinnsvis st\u00f8ttet i plattformen</li> </ol>"},{"location":"juridisk/pvk/","title":"Hvordan fyller jeg ut PVK?","text":"<p>Denne artikkelen tar utgangspunkt i mal for PVK. Overskrifter korresponderer til overskrifter i malen, og vi tar kun for oss seksjoner som vi har kommentarer til.</p> <p>V\u00e6r oppmerksom</p> <p>Teamet ditt m\u00e5 selv ta ansvar for at PVK beskriver deres l\u00f8sning. Hvis du bruker v\u00e5r plattform kan du ta utgangspunkt i dette som beskrivelse.</p> <p>Tekst som er markert er ment som noe man b\u00f8r ta stilling til. Kanskje det er noe som ikke gjelder dere, eller kanskje det er en eller flere av alternativene som er beskrevet som passer deres situasjon.</p> <p>Kommentarer fra NADA er ofte i bokser som denne, men ikke alltid. </p>"},{"location":"juridisk/pvk/#dokumentasjon-og-ajourhold","title":"Dokumentasjon og ajourhold","text":""},{"location":"juridisk/pvk/#eksterne-deltagere","title":"Eksterne deltagere","text":""},{"location":"juridisk/pvk/#representant-for-databehandler","title":"Representant for databehandler","text":"<p>Kommentar</p> <p>Teamet m\u00e5 gj\u00f8re en vurdering av involvering av egne databehandlere.</p> <p>Nada-plattformen bygger p\u00e5 GCP som har egen databehandleravtale. Dokumentert etterlevelse p\u00e5 NADA (B532, krever innlogging).</p>"},{"location":"juridisk/pvk/#beskrivelse-av-behandlingen","title":"Beskrivelse av behandlingen","text":""},{"location":"juridisk/pvk/#behandlingskatalogen","title":"Behandlingskatalogen","text":""},{"location":"juridisk/pvk/#referansenummer-i-behandlingskatalogen","title":"Referansenummer i Behandlingskatalogen","text":"<p>fyll inn aktuelle behandlinger</p> <p>Dokumentert behandling for NADA-plattformen.</p>"},{"location":"juridisk/pvk/#sttte-til-etterlevelse","title":"St\u00f8tte til etterlevelse","text":""},{"location":"juridisk/pvk/#urllenke-til-dokumentasjonen-i-sttte-til-etterlevelse","title":"URL/Lenke til dokumentasjonen i St\u00f8tte til etterlevelse","text":"<p>fyll inn aktuell etterlevelsesdokumentasjon</p> <p>Dokumentert etterlevelse for NADA.</p>"},{"location":"juridisk/pvk/#risikovurdering-av-informasjonssikkerhet-personopplysningssikkerhet","title":"Risikovurdering av informasjonssikkerhet (personopplysningssikkerhet)","text":""},{"location":"juridisk/pvk/#referanse-til-relevante-risikovurderinger-lenke-websaksnummer-eller-vedlegg","title":"Referanse til relevante risikovurderinger (lenke, WebSaksnummer eller vedlegg)","text":"<p>fyll inn aktuelle risikovurderinger</p> <ul> <li>Risikovurderinger for ulike plattformer fra NAIS</li> <li>Risikovurderinger gjort av NADA (Datamarkedsplassen og KNADA)</li> </ul> <p>Relevante risikovurderinger gjort av andre team</p> <ul> <li>DBT med Airflow p\u00e5 KNADA (ROS 1045)</li> </ul>"},{"location":"juridisk/pvk/#behandlingens-art-og-omfang","title":"Behandlingens art og omfang","text":""},{"location":"juridisk/pvk/#hvordan-skal-personopplysningene-samles-inn","title":"Hvordan skal personopplysningene samles inn?","text":"<p>Vi samler ikke inn nye opplysninger. Vi behandler personopplysninger som allerede er samlet inn i forbindelse med at bruker har [sendt inn s\u00f8knad / sendt inn meldekort / registrert seg / sendt opplysninger / f\u00e5tt vurdering / eller lignende ]. Dette betyr at vi ikke samler inn noen data, vi kun gjenbruker data som allerede er samlet inn.</p> <p>Behandling av data</p> <p>Hvor har dere data?</p> <p>Vi har beskrevet ulike m\u00e5ter \u00e5 hente ut data p\u00e5. Velg den som passer for deg! </p> Data fra produktteamData fra DatavarehusData fra GCP <p>Dataene som behandles hentes fra fyll inn applikasjon som eies av fyll inn team. Data leses fra [Kafka / BigQuery / database]. Opplysninger er [pseudonymisert ved innhenting (Anbefalt) / blir pseudonymisert etter innhenting], og er dermed \u00e5 anse som personopplysninger.</p> <p>Kun analytiker har tilgang til data fra kilden.</p> <p>For sammenstilling av data mellom disse kildene eller for videre analyse utover eksisterende funksjonalitet i innsamlingsverkt\u00f8y benyttes KNADA som er NADA sin analyseplattform i GCP.</p> <p>I KNADA har man muligheten til \u00e5 opprette private Jupyter notebooks for \u00e5 manuelt bearbeide data, mens man tilbyr det teambaserte orkestreringsverkt\u00f8yet Airflow for \u00e5 skedulere jobber for behandling av data.</p> <p>KNADA brukes til \u00e5 jobbe med kilder on-premis, som [Oracle / Postgres], og kilder i GCP, som [Kafka / BigQuery / Postgres]. For \u00e5 f\u00e5 tilgang til KNADA m\u00e5 man registrere et team i Knorten, da vil man f\u00e5 muligheten til \u00e5 installere Jupyter og Airflow.</p> <p>Hemmeligheter i notebook</p> <p>Har man behov for hemmeligheter i notebooken s\u00e5 anbefaler vi at man bruker Google Secret Manager (GSM) i teamets prosjekt. En hemmelighet opprettet i GSM vil kun v\u00e6re tilgjengelig for de som har gitt seg tilgang til den, derfor anbefaler vi ikke at team opererer med admin-tilganger i sitt prosjekt.</p> <p>Man har mulighet til \u00e5 gi en service account, opprettet i KNADA for teamet, tilgang til teamets hemmeligheter eller kilder i GCP.</p> <p>Det gj\u00f8res sp\u00f8rringer mot en klone av databasen som oppdateres hver natt.</p> <p>Opplysninger leses fra DVH. Data ligger i en Oracle-database. Opplysningene er [psuedonymisert ved innhenting (Anbefalt) / blir pseudonymisert etter innhenting], og er dermed \u00e5 anse som personopplysninger. Analytiker har lesetilgang.</p> <p>For sammenstilling av data mellom disse kildene eller for videre analyse utover eksisterende funksjonalitet i innsamlingsverkt\u00f8y benyttes KNADA som er NADA sin analyseplattform i GCP. I KNADA har man muligheten til \u00e5 opprette private Jupyter notebooks for \u00e5 manuelt bearbeide data, mens man tilbyr det teambaserte orkestreringsverkt\u00f8yet Airflow for \u00e5 skedulere jobber for behandling av data.</p> <p>KNADA brukes til \u00e5 jobbe med kilder on-premis, som [Oracle / Postgres].</p> <p>Det gj\u00f8res sp\u00f8rringer mot databasen med dataanalytikers bruker.</p> <p>Teamet har et eget prosjekt i GCP, fyll inn navn p\u00e5 prosjekt, der data er lagret i BigQuery. Det hentes ikke data som er eldre enn fra fyll inn \u00e5r. Person-ID er [pseudonymisert ved innhenting (Anbefalt) / blir pseudonymisert etter innhenting], og er dermed \u00e5 anse som personopplysninger.</p> <p>For sammenstilling av data mellom disse kildene eller for videre analyse utover eksisterende funksjonalitet i innsamlingsverkt\u00f8y benyttes KNADA som er NADA sin analyseplattform i GCP. I KNADA har man muligheten til \u00e5 opprette private Jupyter notebooks for \u00e5 manuelt bearbeide data, mens man tilbyr det teambaserte orkestreringsverkt\u00f8yet Airflow for \u00e5 skedulere jobber for behandling av data.</p> <p>KNADA brukes til \u00e5 jobbe med kilder i GCP, som [Kafka / BigQuery / Postgres]. For \u00e5 f\u00e5 tilgang til KNADA m\u00e5 man registrere et team i Knorten, da vil man f\u00e5 muligheten til \u00e5 installere Jupyter og Airflow.</p> <p>Hemmeligheter i notebook</p> <p>Har man behov for hemmeligheter i notebooken s\u00e5 anbefaler vi at man bruker Google Secret Manager (GSM) i teamets prosjekt. En hemmelighet opprettet i GSM vil kun v\u00e6re tilgjengelig for de som har gitt seg tilgang til den, derfor anbefaler vi ikke at team opererer med admin-tilganger i sitt prosjekt.</p> <p>Man har mulighet til \u00e5 gi en service account, opprettet i KNADA for teamet, tilgang til teamets hemmeligheter eller kilder i GCP.</p> <p>Det gj\u00f8res sp\u00f8rringer mot BigQuery med BigQuery API klient og servicebruker.</p>"},{"location":"juridisk/pvk/#hvordan-og-hvor-lenge-skal-personopplysningene-lagres","title":"Hvordan og hvor lenge skal personopplysningene lagres?","text":"<p>Personopplysningene blir midlertidig lagret i en periode p\u00e5 fyll inn varighet Vi lagrer kun sluttresultatet, som er statistikk (aggregert og ikke personidentifiserende). Tidvis mellomlagres resultat ved spesielt tunge sp\u00f8rringer.</p> <p>Anbefaling</p> <p>Dette vil i s\u00e5 tilfelle kun mellomlagres mens analysen p\u00e5g\u00e5r og det brukes en p\u00e5minnelse for gjennomgang av sletting av data minst en gang i m\u00e5neden (Sletterutiner versus arkiveringslov).</p>"},{"location":"juridisk/pvk/#behandlingens-livslp","title":"Behandlingens livsl\u00f8p","text":""},{"location":"juridisk/pvk/#gi-en-beskrivelse-av-behandlingens-livslp","title":"Gi en beskrivelse av behandlingens livsl\u00f8p","text":"GCPOn-prem <p>Behandling av data i Analyseplattform i GCP utf\u00f8res av x dataanalytikere i teamet. Det opprettes en egen notebookinstans for dette arbeidet som kun dataanalytikeren(e) har tilgang til.</p> <p>Behandlingen foreg\u00e5r i f\u00f8lgende steg:</p> <ol> <li>Innsamling av data<ul> <li>Se sp\u00f8rsm\u00e5let over, hvordan skal personopplysningene samles inn</li> </ul> </li> <li>Lagring av data<ul> <li>Se sp\u00f8rsm\u00e5let over, hvordan og hvor lenge skal personopplysningene lagres</li> </ul> </li> <li>Pseudonymisering/anonymisering<ul> <li>Hvis aktuelt, beskriv metode for pseudonymisering og/eller anonymisering gjort av analytiker.</li> <li>Referer til TADA ved sp\u00f8rsm\u00e5l for valg av metode.</li> <li>Alternativt beskriv hvorfor det ikke blir gjort, eller beskriv at det er gjort i kildesystemet ved innsamling av data, steg 1</li> </ul> </li> <li>Sammenstilling av data i notebook<ul> <li>Dataene som samles inn fra databaser leses fra en notebook, ved at det gj\u00f8res sp\u00f8rringer mot en kilde.</li> <li>Fyll inn navn p\u00e5 datakilder, feks l\u00f8sning, datavarehus, BigQuery.</li> <li>Se beskrivelser av innsamling av data og lagring av data.<ul> <li>Unders\u00f8ker, formaterer, sammenstiller, aggregerer og anonymiserer hentede data, dette skjer hovedsakelig i sp\u00f8rring mot databaser eller i notebook.</li> </ul> </li> </ul> </li> <li>Resultater publiseres og deles<ul> <li>Data blir aggregert og anonymisert f\u00f8r publisering av datasett og visualiseringer som rapporter (datafortellinger tilgjengelig p\u00e5 Datamarkedsplassen) eller interaktive dashboards (metabase). Aggregerte resultater kan ogs\u00e5 deles p\u00e5 andre m\u00e5ter (f.eks ved \u00e5 sende datasett).</li> </ul> </li> <li>Automatisk publisering av data<ul> <li>Det skeduleres til \u00e5 oppdateres jevnlig med orkestreringsverkt\u00f8yet Airflow (del av Analyseplattform) eller i GCP.</li> </ul> </li> <li>Sletting av data<ul> <li>N\u00e5r man ikke lenger har behov for \u00e5 utvikle ny statistikk, slettes personopplysninger og data som er grunnlag for analysen i henhold til sletterutiner, (legg ved rutine).</li> </ul> </li> </ol> <p>Under arbeid</p> <p>Her er det ikke noe enda! </p>"},{"location":"juridisk/pvk/#referanse-til-supplerende-vedlegg","title":"Referanse til supplerende vedlegg","text":"<p>Dataprodukt og Datamarkedsplassen er beskrevet i dokumentasjonen til NADA.</p>"},{"location":"juridisk/pvk/#oppgi-eventuelle-opplysninger-for-denne-vurderingen-sammenlignet-med-beskrivelsen-av-hele-verdikjeden-eller-beskrivelsen-av-aktuell-behandling-i-behandlingskatalogen","title":"Oppgi eventuelle opplysninger for denne vurderingen sammenlignet med beskrivelsen av hele verdikjeden eller beskrivelsen av aktuell behandling i behandlingskatalogen","text":"<p>Vurderingen gjelder behandling fra uttrekk fra database, til visualisering av statistikk i dashboard og/eller innsiktsprodukter som oppdateres [daglig / ukentlig / m\u00e5nedlig].</p> <p>Vurderingen baserer seg p\u00e5 dataplattformen sine l\u00f8sninger, som er beskrevet i [behandlingskatalogen / etterlevelseskatalogen / egen PVK / f\u00f8lgende ROSer]</p> <p>Dataplattformen baserer seg p\u00e5 databehandleravtaler for [GCP / on-prem], og eventuelt andre vurderinger.</p> <p>Disse er lenket til over i form av behandlingskatalog, etterlevelses-verkt\u00f8y, ROSer og lenke til aktuelle ROSer fra plattformtjenestene til nais</p>"},{"location":"juridisk/pvk/#konsekvenser-og-tiltak","title":"Konsekvenser og tiltak","text":"<p>V\u00e6r oppmerksom</p> <p>Denne seksjonen handler om overskriftene Konsekvenser for den enkelte og Tiltak. Scenariene er eksempler, og passer ikke n\u00f8dvendigvis l\u00f8sningen deres. Likevel kan det hende at de kan v\u00e6re til inspirasjon! </p> <p>Hvert scenario inneholder tekst som passer i konsekvensdelen: beskrivelse, forslag til konsekvens- og risikoniv\u00e5, vurdering av konsekvens og risko. I tillegg inneholder visse scenario tiltak, som h\u00f8rer til i tabell for risikoreduserende tiltak.</p> Scenario 1Scenario 2Scenario 3Scenario 4Scenario 5Scenario 6Scenario 7Scenario 8Scenario 9Scenario 10Scenario 11 <p>Den registrerte f\u00e5r ikke tilstrekkelig informasjon om hvordan deres personopplysninger behandles fordi...</p> <p>Det blir ikke gitt tilstrekkelig informasjon om at data benyttes til statistikk og analyse. Den registrerte blir informert om behandlingen gjennom den generelle personvernerkl\u00e6ringen.</p> <p>Velg hvilket scenario som passer deres l\u00f8sning best:</p> Personvernerkl\u00e6ringen finnes p\u00e5 nav.noPersonvernerkl\u00e6ringen finnes i s\u00f8knadsdialogenS\u00f8knadsdialogen gir info om behandling av personopplysninger <p>Den generelle personv\u00e6rnerkl\u00e6ringen kan finnes p\u00e5 nav.no.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 4</li> <li>Konsekvensniv\u00e5: 3</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Ettersom det forutsetter at brukeren opps\u00f8ker informasjon om personvernserkl\u00e6ringen p\u00e5 nav.no, er det en stor sannsynlighet for at bruker ikke f\u00e5r tilstrekkelig informasjon om behandlingen av personopplysninger til statistikk og analyseform\u00e5l. Det er sannsynlig at informasjonen ikke er spesifikk nok med tanke p\u00e5 hvordan personopplysningene faktisk behandles.</p> <p>Beskriv deres vurdering av konsekvens</p> <p>En konsekvens for bruker er at retten til informasjon ikke er innfridd som videre kan gj\u00f8re det vanskelig for dem \u00e5 ivareta sine personvernrettigheter. Den registrertes rett til personvern krenkes i en st\u00f8rre periode eller involverer s\u00e6rlige kategorier/s\u00e5rbare grupper</p> <p>Tiltak</p> <p>S\u00f8rge for at det kommer p\u00e5 plass en henvisning til NAVs personvernerkl\u00e6ring i forbindelse med innhenting av opplysninger. I personvernerkl\u00e6ringen er bruk av personopplysninger til statistikk og analyseform\u00e5l n\u00e6rmere beskrevet.</p> <p>Den generelle personvernerkl\u00e6ringen er lenket til fra s\u00f8knadsdialogen</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 3</li> <li>Konsekvensniv\u00e5: 3</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Ettersom det ikke gis informasjon om utarbeidelse av statistikk og analyse i forbindelse med innhenting av opplysninger for er det en viss sannsynlighet for at bruker ikke f\u00e5r tilstrekkelig informasjon om behandlingen av personopplysninger til dette form\u00e5let. Dessuten er det en sannsynlighet for at informasjonen ikke er spesifikk nok med tanke p\u00e5 hvordan personopplysningene faktisk behandles.</p> <p>Beskriv deres vurdering av konsekvens</p> <p>En konsekvens for bruker er at retten til informasjon ikke er innfridd som videre kan gj\u00f8re det vanskelig for dem \u00e5 ivareta sine personvernrettigheter. Den registrertes rett til personvern krenkes i en st\u00f8rre periode eller involverer s\u00e6rlige kategorier/s\u00e5rbare grupper</p> <p>Det gis informasjon i s\u00f8knadsdialogen om at opplysningene behandles til utarbeidelse av anonymisert statistikk og analyse.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 2</li> <li>Konsekvensniv\u00e5: 3</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Det er en viss sannsynlighet for at bruker ikke f\u00e5r tilstrekkelig informasjon om behandlingen av personopplysninger til dette form\u00e5let eller ikke forst\u00e5r informasjonen. Dessuten er det en sannsynlighet for at informasjonen ikke er spesifikk nok med tanke p\u00e5 hvordan personopplysningene faktisk behandles.</p> <p>Beskriv deres vurdering av konsekvens</p> <p>En konsekvens for bruker er at retten til informasjon ikke er innfridd som videre kan gj\u00f8re det vanskelig for dem \u00e5 ivareta sine personvernrettigheter. Den registrertes rett til personvern krenkes i en st\u00f8rre periode eller involverer s\u00e6rlige kategorier/s\u00e5rbare grupper</p> <p>Det samles inn flere personopplysninger enn det som er n\u00f8dvendig for form\u00e5let fordi...</p> <p>Erfaringsmessig vil det forekomme overskuddsinformasjon, til tross for at teamet i forkant har definert hvilke kategorier personopplysninger som er n\u00f8dvendig for \u00e5 gjennomf\u00f8re analysen.</p> <p>Dette skyldes ofte manglende oversikt over hva som finnes i NAVs datakilder. Det er derfor mulig at vi henter ut flere opplysninger og/eller opplysninger p\u00e5 et detaljniv\u00e5 som senere viser seg \u00e5 v\u00e6re un\u00f8dvendig detaljert.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 5</li> <li>Konsekvensniv\u00e5: 3</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Det er sannsynlig at dette skjer fordi l\u00e6ring underveis og resultatet av analysen kan vise at vi hadde f\u00e5tt samme innsikt ved \u00e5 bruke f\u00e6rre opplysninger og /eller mindre detaljerte opplysninger.</p> <p>Dersom det benyttes flere pseudonymiserte personopplysninger enn n\u00f8dvendig for form\u00e5let vil dette kun skje i en begrenset periode fra data hentes til analyse og statistikk utarbeidet.</p> <p>Dataen vil kun ligge i minnet p\u00e5 arbeidsinstansen frem til analysen er ferdigstilt. I denne perioden er det utelukkende datascientisten som har tilgang til denne dataen. Personopplysninger som eventuelt vil g\u00e5 ut over det som er n\u00f8dvendig for form\u00e5let vil ikke bli brukt videre i annen form enn eventuelt anonymisert og konsekvensen vil dermed v\u00e6re begrenset.</p> <p>I informasjonen som er innhentet er det fritekstfelter og vedlegg, hvor man p\u00e5 forh\u00e5nd ikke kan vite hva som st\u00e5r. Det kan gj\u00f8res feil ved \u00e5 hente inn deler av disse som ikke er n\u00f8dvendige for \u00e5 utarbeide den aktuelle statistikken. Dataene som blir hentet inn overskrives (slettes fra minnet) hvis</p> <p>I de tilfeller der det viser seg i etterkant at analysen kan gj\u00f8res med mindre data vil vi fortl\u00f8pende endre analysen til ikke \u00e5 inkludere denne dataen. Dette gj\u00f8res fortl\u00f8pende og vil derfor kun i en kort periode utfordre den registrertes rett til personvern.</p> <p>Beskriv deres vurdering av konsekvens</p> <ul> <li>Den registrertes rett til personvern krenkes i en st\u00f8rre periode eller involverer s\u00e6rlige kategorier/s\u00e5rbare grupper</li> <li>Den registrertes tillit til NAV utfordres</li> </ul> <p>Prinsippet om dataminimering er vanskelig \u00e5 gjennomf\u00f8re. \u00d8kt mengde personopplysninger gir \u00f8kt risiko for reidentifisering og at opplysninger brukes til andre form\u00e5l. Perioden det skjer i vil v\u00e6re begrenset, og blir ikke brukt videre i annen form enn eventuelt anonymisert.</p> <p>Tiltak</p> <ol> <li>At tabellene som brukes er tilstrekkelig dokumentert og at personen som bruker dem kjenner til denne dokumentasjonen.<ul> <li>Det utarbeides en oversikt over hva de ulike tabellene inneholder, for \u00e5 unng\u00e5 \u00e5 hente opplysninger det ikke er behov for. Dialog med fagpersoner for \u00e5 f\u00e5 klarhet i innholdet.</li> <li>I tillegg er det inntatt beskrivelser om hvordan sp\u00f8rringer skal gj\u00f8res i rutine.</li> </ul> </li> <li>Begrense tilgang til tabeller som brukes<ul> <li>Rutiner for tilgang til tabeller.</li> <li>Dialog med databaseteam.</li> </ul> </li> <li>Kunnskap og bevissthet rundt hvordan slette data, hvis det er kommet inn for mye opplysninger</li> </ol> <p>Personopplysninger lagres lengre enn det som er n\u00f8dvendig for form\u00e5let fordi...</p> <p>Det er en risiko for at manuelle sletterutiner ikke gjennomf\u00f8res, eller at de gjennomf\u00f8res for sjeldent.</p> <ul> <li>Personopplysninger som mellomlagres for \u00e5 gjennomf\u00f8re analyser i [Notebook / BigQuery] blir ikke slettet manuelt etter gjennomf\u00f8rt analyse.</li> <li>Personopplysninger som er i minnet i Notebookinstansen (dvs at det lages en visning av dataene i minnet) underveis i arbeids\u00f8kten ikke slettes manuelt etter endt arbeids\u00f8kt.</li> </ul> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 3</li> <li>Konsekvensniv\u00e5: 3</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Det er utarbeidet sletterutiner, (legg ved sletterutine). Det er imidlertid alltid en risiko for at rutiner ikke f\u00f8lges og at de manuelle sletterutinene ikke gjennomf\u00f8res. Sannsynlighetsniv\u00e5et settes til niv\u00e5 tre ettersom ikke alle sletterutinene er automatisert</p> <p>Beskriv deres vurdering av konsekvens</p> <p>En konsekvens er at personopplysninger lagres lenger enn n\u00f8dvendig for form\u00e5let, som bryter med lagringsprinsippet og dataminimeringsprinsippet. Personopplysningene vil imidlertid ikke kunne benyttes til andre form\u00e5l n\u00e5r de er lagret i GCP, og det er kun teamet som har tilgang til lagringsstedene.</p> <p>Tiltak</p> <p>Sletterutiner er utarbeidet, (legg ved letterutine).</p> <p>Personopplysningene som behandles er ikke korrekte fordi...</p> <p>Analyse og statistikk tar utgangspunkt i informasjon som er gitt fra bruker eller saksbehandler, og en eventuell feil vil v\u00e6re basert p\u00e5 at brukere har gitt feil informasjon eller saksbehandler har fylt inn feil.</p> <p>Teknisk kan det ogs\u00e5 skje feil avlesninger n\u00e5r det er felter som skrives inn manuelt, slikt som antall timer som kan skrives med punkt, komma osv. Dette kan medf\u00f8re at informasjonen tolkes feil.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 1</li> <li>Konsekvensniv\u00e5: 1</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>P\u00e5 bakgrunn av personopplysningene som behandles gis direkte fra den registrerte er det lite sannsynlig at denne ikke er korrekt, og det er for alle tilfeller noe som er utenfor NAVs kontroll.</p> <p>Tekniske feil ved avlesning vil i sv\u00e6rt liten grad skje, og er i stor grad kun aktuelt for fritekstfelt.</p> <p>Beskriv deres vurdering av konsekvens</p> <p>Eventuelle feil i personopplysninger vil kun f\u00e5 betydning for de analysene som gjennomf\u00f8res, ved at statistikken ikke blir korrekt. Behandling av ukorrekte opplysninger ved utarbeidelse av statistikk og analyse gir imidlertid ingen direkte konsekvenser for den registrerte, og konsekvensniv\u00e5et settes dermed lavt.</p> <p>Rolle- og ansvarsforholdet for personvern i behandlingen er ikke avklart fordi...</p> <p>Risikoeier er PO, v/PO leder. St\u00f8rre risikoer l\u00f8ftes til ytelsesdirekt\u00f8r. Arbeidet med statistikk og analyse skjer i [team / PO], og det er dataanalytiker og andre medlemmer i teamet som jobber med dataen som er ansvarlig for behandlingene.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 2</li> <li>Konsekvensniv\u00e5: 3</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Det kan bli endringer i intern organisering i NAV som kan medf\u00f8re endringer i rolle- og ansvarsforholdet. Dersom en som er ny i rollen behandler dataene kan dette medf\u00f8re at vedkommende bruker data som han/hun ikke har hjemmelsgrunnlag til \u00e5 bruke.</p> <p>Beskriv deres vurdering av konsekvens</p> <p>P\u00e5 bakgrunn av at behandlingen ikke f\u00e5r noen direkte konsekvenser for individet anses konsekvensen lav dersom rolle- og ansvarsforholdene ikke er avklart anses konsekvensene som minimale.</p> <p>Tiltak</p> <p>Gj\u00f8re retningslinjer kjent p\u00e5 tvers av teamet, samt ledelse i PO.</p> <p>Den registrerte f\u00e5r ikke innsyn i alle sine personopplysninger i behandlingen fordi...</p> <p>Den registrerte i innsynsl\u00f8sningen ikke f\u00e5r vite hva slags opplysninger som er brukt til analyse og statistikk. Programvaren som benyttes til analysearbeid har ikke funksjonalitet for dette.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 3</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Analyse i denne sammenhengen medf\u00f8rer at det trekkes ut en kopi av personopplysninger. Personopplysningene kan i en kort periode lagres pseudonymisert i NAVs Analyseplattform i GCP f\u00f8r de slettes. Den registrertes mulighet for innsyn forutsettes h\u00e5ndtert der informasjonen samles inn og vurderes ikke s\u00e6rskilt i denne PVK.</p> <p>Da det ikke gis innsyn i hvilke personopplysninger som er gjenstand for statistikk og analyse, settes sannsynlighetsniv\u00e5et deretter.</p> <p>Beskriv deres vurdering av konsekvens</p> Konsekvensniv\u00e5 1Konsekvensniv\u00e5 2 <p>Den registrerte f\u00e5r innsyn i sine personopplysninger gjennom innsynsl\u00f8sningen og/eller systeml\u00f8sningene hvor informasjonen innhentes.</p> <p>Konsekvensene ved manglende innsyn i behandlingen som gj\u00f8res for statistikk og analyse anses derfor som lav.</p> <p>Dette scenarioet m\u00e5 imidlertid ses i sammenheng med scenario om rett til informasjon, da informasjon om behandlingen ogs\u00e5 vil avhjelpe brukers behov for innsyn.</p> <p>Det finnes ikke innsynsl\u00f8sninger. Den registrerte kan kun f\u00e5 innsyn i sine personopplysninger ved \u00e5 gj\u00f8re manuelle uttrekk av der informasjonen innhentes.</p> <p>Konsekvensene ved manglende innsyn i behandlingen som gj\u00f8res for statistikk og analyse anses derfor som middels.</p> <p>Dette scenarioet m\u00e5 imidlertid ses i sammenheng med scenario om rett til informasjon, da informasjon om behandlingen ogs\u00e5 vil avhjelpe brukers behov for innsyn.</p> <p>Det er en risiko for at personopplysninger kommer p\u00e5 avveie fordi..</p> <ul> <li>Tilgangsstyringen til personopplysningene er ikke god nok, herunder rutiner for \u00e5 fjerne tilganger</li> <li>Personopplysninger publiseres eller deles ved feil.</li> <li>Credentials for tilgang til personopplysninger kommer p\u00e5 avveie, f.eks at de publiseres i kode.</li> </ul> <p>Notebook er eksponert til internett (kan kobles p\u00e5 internett utenfor organisasjonen). Hvilket medf\u00f8rer en \u00f8kt risiko for at data kommer p\u00e5 avveie, som f\u00f8lge misbruk av data av en ansatt i NAV (utro tjener).</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 4</li> <li>Konsekvensniv\u00e5: 4</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Tilgang:</p> <ul> <li>I de fleste tilfeller m\u00e5 tilgang gis til enkelt ansatte med tjenstlig behov. Da er det mulig \u00e5 f\u00e5 tilgang til mer enn det som er n\u00f8dvendig.</li> <li>En person m\u00e5 ofte bli lagt til i et team for \u00e5 f\u00e5 teamtilganger. Da er det mulig \u00e5 bli gitt for store tilganger.</li> <li>I GCP er det mulig \u00e5 gi seg selv tilganger. Dette m\u00e5 gj\u00f8res aktivt, ogs\u00e5 her er det mulig \u00e5 gi seg selv for vide tilganger.</li> <li>Etter at en ikke lenger er medlem av team eller en ikke lenger trenger tilganger en er blitt gitt manuelt kan det ta tid f\u00f8r tilgangene blir fjernet. En ansatt i NAV kan dermed ha tilgang til data uten tjenstlig behov.</li> </ul> <p>Sannsynligheten for at en ansatt i NAV har for store tilganger og dermed har tilgang til personopplysninger uten tjenstlig behov anses som relativt h\u00f8y.</p> <p>Deling ved feil:</p> <ul> <li>Personopplysninger kan publiseres ved feil og bli tilgjengelige der fordi koden som ble pushet eller dataene som ble publisert ikke ble sjekket godt nok.</li> <li>Tilganger kan ogs\u00e5 ved feil bli publisert til github og dermed bli tilgjengelig for andre uten tjenstlig behov. Dette avhjelpes med at kode for behandling av data lagres i privat repo i GitHub.</li> <li>Det kan ikke utelukkes at menneskelige feil skjer.</li> </ul> <p>Misbruk:</p> <ul> <li>GCP er eksponert til internett slik at det er mulig \u00e5 dele data ut av NAV. Det skal imidlertid mye til for at dette skjer, og vil kun v\u00e6re aktuelt ved misbruk. Sannsynligheten for misbruk av data av NAV-ansatte m\u00e5 imidlertid anses som lav (Se ROS med ID 607).</li> </ul> <p>Beskriv deres vurdering av konsekvens</p> <p>Personopplysninger som kommer p\u00e5 avveie vil kunne ha konsekvenser for den registrerte, herunder tap av konfidensialitet. Det kan igjen medf\u00f8re andre negative konsekvenser for den registrerte som sosiale ulemper, identitetstyveri, bedrageri, stigmatisering og lavere tillitt til NAV.</p> <p>Tiltak</p> <p>Det kj\u00f8res script som forhindrer at notebookfiler pushes med output som kan inneholde personopplysninger.</p> <ol> <li>Credentials eller personopplysninger kommer p\u00e5 avveie<ul> <li>Lagre tilganger i secret manager som vault eller google secret manager.</li> <li>Rutine for \u00e5 sjekke kode som lagres i github.</li> </ul> </li> <li>Data deles eller publiseres ved feil<ul> <li>Rutine for \u00e5 sjekke kode som lagres i github, publiseres i datapakke eller deles f\u00f8r publisering/deling.</li> </ul> </li> <li>Tilgang i GCP eller andre databaser<ul> <li>Gi seg selv eller f\u00e5 minst mulig tilganger for \u00e5 oppn\u00e5 form\u00e5let.</li> </ul> </li> </ol> <p>Behandlingen av personopplysninger brukes til et annet form\u00e5l enn de ble innsamlet for.</p> <p>Det er en risiko for at opplysninger innhentet for en analyse kan bli brukt til analyser for andre form\u00e5l enn det de ble innsamlet for.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 2</li> <li>Konsekvensniv\u00e5: 3</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Teamet har et tydelig fastsatt form\u00e5l for behandlingen. Det er imidlertid alltid en fare for at man i et slikt manuelt analysearbeid beveger seg utenfor det beskrevne form\u00e5let. Ettersom det er stor bevissthet i teamet og det er f\u00e5 som har tilgang til, og analyserer denne dataen, er det liten sannsynlighet for at man beveger seg utenfor det beskrevne form\u00e5l.</p> <p>Beskriv deres vurdering av konsekvens</p> <p>Dersom opplysningene gjenbrukes til analyser med et annet form\u00e5l enn det fastsatte, vil dette ikke f\u00e5 direkte konsekvenser for bruker. Det strider mot personvernprinsippet, at man bruker personopplysninger som er avgitt til noe annet enn det det er gitt informasjon om.</p> <p>Tiltak</p> <p>Alle p\u00e5 teamet skal gj\u00f8res godt kjent med form\u00e5let for arbeidet.</p> <p>Analyse og statistikk blir ikke tilstrekkelig anonymisert fordi...</p> <p>Datasettene inneholder et lavt antall rader, slik at personer kan bli re-identifisert.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 1</li> <li>Konsekvensniv\u00e5: 4</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>I de fleste tilfeller vil det behandles store mengder data n\u00e5r det skal foretas analyse, men det gj\u00f8res ogs\u00e5 analyser p\u00e5 sm\u00e5 grupper (mindre enn fire personer) som det vil v\u00e6re mulig \u00e5 re-identifisere.</p> <p>Sm\u00e5 grupper er med i tellingen, men fjernes fra statistikken.</p> <p>Beskriv deres vurdering av konsekvens</p> <p>For det tilfelle at statistikken som utarbeides ikke er anonymisert vil det kunne fremg\u00e5 mye informasjon fra den enkelte registrerte (dersom det er mulig \u00e5 lese dette ut av statistikken). For det tilfelle at statistikken deles bredt vil personopplysninger kunne eksponeres for mange som ikke har noe tjenstlig behov for disse.</p> <p>Tiltak</p> <p>Vi lagrer ikke grupper p\u00e5 mindre enn fem personer, hverken i tabeller eller i plott.</p> <p>Det oppbevares flere kopier av samme informasjon i form av mellomlagring som ikke er omfattet av slettereglene.</p> <p>I de fleste tilfeller benyttes det data som kan hentes programmatisk for analyse. Men det forekommer at grunnlagsdata med personinformasjon (hovedsakelig i fritekstfelt) lastes opp og lagres p\u00e5 lokal PC og deretter i notebook for \u00e5 utf\u00f8re analyse og/eller lage statistikk.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 2</li> <li>Konsekvensniv\u00e5: 2</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>De aktuelle lagringsstedene er dekket av manuell sletterutine, se rutine for statistikk og analyse.</p> <p>Det er risiko forbundet med manuelle sletterutiner, og det er en h\u00f8yere sannsynlighet for at disse ikke gjennomf\u00f8res enn ved automatisk sletting.</p> <p>Beskriv deres vurdering av konsekvens</p> <p>Data med personopplysninger lagres og mellomlagres i hovedsak p\u00e5 omr\u00e5der som kun dataanalytiker eller teamet har tilgang til. Tilgangen er dermed sv\u00e6rt begrenset.</p> <p>Dersom personopplysningene ikke slettes behandler NAV personopplysninger i strid med personvernprinsippene og i st\u00f8rre grad enn n\u00f8dvendig.</p> <p>Tiltak</p> <p>Nye lagringssteder skal inkluderes i lagrings- og sletterutiner, dette er beskrevet i rutine.</p> <p>Konfidensiell informasjon om personer med kode 6/7 og egen ansatt blir tilgjengelig for personer som ikke skal ha tilgang fordi...</p> <p>Det hentes data fra databaser, herunder fyll inn navn p\u00e5 databaser, som inneholder data om personer med kode 6/7 og egen ansatt.</p> <p>Foresl\u00e5tt niv\u00e5</p> <ul> <li>Sannsynlighetsniv\u00e5: 3</li> <li>Konsekvensniv\u00e5: 5</li> </ul> <p>Beskriv deres vurdering av sannsynlighet</p> <p>Bosted, konfidensiell informasjon for personer med kode 6 eller 7, vil sjeldent hentes for analyse og statistikk.  Fordi de kan finnes i databasene vil det v\u00e6re en mulighet for at de hentes. Eksempelvis kan slik informasjon v\u00e6re oppgitt i dokumenter, henvendelser eller andre fritekstfelt. Det kan ogs\u00e5 hentes data som indirekte kan identifisere lokasjon, som NAV-kontor.</p> <p>Det er utarbeidet rutiner for \u00e5 forhindre at det behandles personopplysninger med kode 6 og kode 7, (legg ved rutine). </p> <p>Sannsynlighetsniv\u00e5et settes relativt lavt, men ikke p\u00e5 laveste niv\u00e5 da det alltid vil v\u00e6re en risiko for menneskelige feil.  </p> <p>Beskriv deres vurdering av konsekvens</p> <p>Ved sammenstilling av data benyttes som hovedregel en unik ID/n\u00f8kkel som ikke er identifiserende eller inneholder personopplysninger. </p> <p>Resultatene, aggregert statistikk vil i seg selv ikke v\u00e6re identifiserende.  </p> <p>Dersom rutine for henting av data ikke blir fulgt, kan det f\u00e5 den konsekvens at det behandles personopplysninger knyttet til kode 6 og kode 7.</p> <p>Tiltak</p> <p>Filtrere bort personer med diskresjonskode n\u00e5r data som inneholder personidentifiserende informasjon og saksopplysninger om person hentes.</p> <p>Unng\u00e5 \u00e5 utf\u00f8re analyser der informasjon om person, f.eks. lokasjon, aggregeres slik at datasett f\u00e5r sm\u00e5 antall.</p> <p>Det m\u00e5 inntas beskrivelser i rutine. </p>"},{"location":"juridisk/spilleregler/","title":"Spilleregler","text":"<p>Spillereglene er laget for \u00e5 hjelpe teamene \u00e5 gj\u00f8re rett hva gjelder juss. Dette er ikke en utt\u00f8mmende liste over regler, men heller en slags FAQ; sp\u00f8rsm\u00e5l og svar om deling og bruk av data.</p>"},{"location":"juridisk/spilleregler/#hva-ma-jeg-som-produsent-dokumentere-om-dataene-jeg-behandler","title":"Hva m\u00e5 jeg som produsent dokumentere om dataene jeg behandler?","text":"<p>Produksjon av data dekker innlesing, bearbeiding og lagring av data p\u00e5 <code>BigQuery</code> f\u00f8r eventuell deling utenfor teamet. Denne behandlingen av personopplysninger dokumenteres sammen med eksisterende registrering i Behandlingskatalogen knyttet til systemet der data oppst\u00e5r. I beskrivelsen av behandlingen m\u00e5 det fremkomme at data registreres p\u00e5 Datamarkedsplassen og til hvilket form\u00e5l. Form\u00e5let med delingen av data kan her v\u00e6re tjenesteutvikling og/eller statistikkproduksjon. Om behandlingsgrunnlaget er forskjellig fra opprinnelig registrering, m\u00e5 dette oppgis. Informasjon om hvilke opplysningstyper som inng\u00e5r i datasettet oppgis ved registrering p\u00e5 Datamarkedsplassen.</p>"},{"location":"juridisk/spilleregler/#er-det-begrensninger-pa-hvilke-data-vi-kan-flytte-til-sky","title":"Er det begrensninger p\u00e5 hvilke data vi kan flytte til sky?","text":"<p>Nei.</p>"},{"location":"juridisk/spilleregler/#kan-jeg-dele-data-med-fdselsnummer","title":"Kan jeg dele data med f\u00f8dselsnummer?","text":"<p>Ja, men det m\u00e5 foreligge et behandlingsgrunnlag, se Hva m\u00e5 jeg som produsent dokumentere om dataene jeg behandler?. Det er viktig at data beskrives slik at konsumenter vet hva de forholder seg til.</p>"},{"location":"juridisk/spilleregler/#hvordan-fjerner-jeg-personopplysninger","title":"Hvordan fjerner jeg personopplysninger?","text":"<p>Det finnes teknikker for anonymisering av data. Ta kontakt med Team Ansvarlig Data og AI (TADA) p\u00e5 Slack for bistand. Metoden for anonymisering dokumenteres ved registrering av datasett.</p>"},{"location":"juridisk/spilleregler/#hvordan-er-ansvarsdelingen-mellom-produsent-og-konsument-ved-deling-av-data","title":"Hvordan er ansvarsdelingen mellom produsent og konsument ved deling av data?","text":"<p>En typisk situasjon er slik: Team Sko har behov for tilgang til produksjonsdata med personopplysninger fra team Hanske</p> <ol> <li>Det forutsettes at team Sko har gjennomf\u00f8rt GPA og evt. PVK, hvor de blant annet dokumenterer hjemmel og form\u00e5l med analysen.</li> <li>Team Hanske, som eier produksjonsdata, mottar foresp\u00f8rsel om produksjonsdata og verifiserer at det foreligger GPA/PVK (referanse til PVK er registrert i behandlingskatalogen). En viktig presisering er at team Hanske kun skal verfisere at GPA/PVK samt behandlingsgrunnlag foreligger\u2014ikke selve innholdet.</li> <li>Dersom team Hanske ikke har filtrert ut kode 6 og 7 fra datagrunnlaget, skal team Sko informeres om det.</li> <li>Team Sko overtar behandlingsansvaret for datasettet som er delt eller utlevert, og personidentifiserende informasjon i datagrunnlaget fjernes i den grad det er mulig.</li> </ol> <p>Dersom konsumenten skal koble datasett med personopplysninger sammen med andre kilder, m\u00e5 konsumenten v\u00e6re spesielt oppmerksom p\u00e5 personvernrisikoen. Produsenten er ikke forventet \u00e5 kunne hensynta dette ved vurdering av tilgangsforesp\u00f8rsel.</p>"},{"location":"juridisk/spilleregler/#har-vi-retningslinjer-i-forbindelse-med-schrems-ii-dommen","title":"Har vi retningslinjer i forbindelse med Schrems II-dommen?","text":"<p>Svaret til dette sp\u00f8rsm\u00e5let m\u00e5 holdes internt, men du kan lese svaret p\u00e5 retningslinjer for Schrems II-dommen p\u00e5 Slack.</p>"},{"location":"juridisk/spilleregler/#ma-jeg-arkivere-data-pa-nada","title":"M\u00e5 jeg arkivere data p\u00e5 nada?","text":"<p>Data arkiveres typisk fra teamenes egne databaser som er master.  Denne arkiveringen skjer f\u00f8r data behandles p\u00e5 nada-plattformen.</p>"},{"location":"visjon/brukerforventninger/","title":"Brukerforventinger","text":"<p>For brukere av Nada sine tjenester har vi lagd en oversikt over programmeringsspr\u00e5k, rammeverk, og verkt\u00f8y som man b\u00f8r ha kjennskap til. Denne oversikten er ikke ment som en utt\u00f8mmende liste over hva du m\u00e5 kunne for \u00e5 bruke v\u00e5re tjenester. Den er heller ment som en oversikt over hva som kan v\u00e6re nyttig for \u00e5 bruke Nada sine tjenester effektivt og trygt.</p>"},{"location":"visjon/brukerforventninger/#programmeringssprak","title":"Programmeringsspr\u00e5k","text":"<p>SQL brukes til \u00e5 lage dataprodukter i BigQuery og til \u00e5 analysere data enten i Metabase eller gjennom en Jupyter Notebook.</p> <p>Nesten alle brukere av KNADA bruker Python som sitt programmeringsspr\u00e5k, men vi har ogs\u00e5 st\u00f8tte for R. Ellers bruker de fleste databasene man jobber med SQL, dette inkluderer BigQuery, Oracle, og Postgres.</p> <ul> <li>Python</li> <li>R</li> <li>SQL</li> </ul> <p>Vi anbefaler at du setter deg inn i SQL for \u00e5 lage dataprodukter/analysere data i Metabase, og Python dersom du skal analysere data i Jupyter notebooks, eller Airflow.</p>"},{"location":"visjon/brukerforventninger/#rammeverk","title":"Rammeverk","text":"<ul> <li>Airflow<ul> <li>Dataverk Airflow</li> </ul> </li> <li>Pandas<ul> <li>Pandas is a Python package that provides fast, flexible, and expressive data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive.</li> </ul> </li> <li>Plotly<ul> <li>Bibliotek for \u00e5 enkelt plotte diagrammer og grafer, mye brukt med datafortellinger via Quarto.</li> </ul> </li> <li>Quarto</li> <li>DBT<ul> <li>Rammeverk for \u00e5 gj\u00f8re ETL operasjoner.</li> </ul> </li> <li>Docker<ul> <li>Kan v\u00e6re nyttig n\u00e5r du trenger noe mer enn Knada tilbyr, for eksempel tredjepartsrammeverk som Plotly og Pandas.</li> </ul> </li> <li>Pythonbiblioteker for \u00e5 koble seg til din database (Oracle, Postgres, Redis)</li> <li>Pip for \u00e5 installere tredjepartspakker for Python (https://pypi.org/project/pip/)</li> </ul>"},{"location":"visjon/brukerforventninger/#ideverkty","title":"IDE/verkt\u00f8y","text":"<ul> <li>Datastream</li> <li>Brukes for \u00e5 enkelt og automatisk flytte data fra Postgres til BigQuery, kun st\u00f8ttet i GCP.</li> <li>Naisjob</li> <li>NAIS-plattformen tilbyr skedulering av workloads med deres Naisjob-ressurs.</li> <li>Metabase</li> <li>Brukes av b\u00e5de avanserte og mindre tekniske brukere for \u00e5 analysere data registrert p\u00e5 Markedsplassen</li> <li>Jupyter notebooks<ul> <li>Notebooks er en interaktiv Python IDE i nettleseren din.</li> </ul> </li> <li>Knada VM<ul> <li>Et alternativ til Jupyter notebooks som lar deg skrive Pythonkoden p\u00e5 din lokale maskin, og kj\u00f8re analysen i Knada.</li> </ul> </li> <li> <p>Airflow</p> <ul> <li>Airflow er et verkt\u00f8y for \u00e5 orkestrere, skedulere og monitorere datapipelines.</li> </ul> </li> <li> <p>Soda</p> <ul> <li>Rammeverk for \u00e5 kontrollere datakvalitet</li> </ul> </li> <li>Google integrasjoner og verkt\u00f8y<ul> <li>Gcloud CLI<ul> <li>For innlogging og administrasjon fra terminalen</li> </ul> </li> <li>BigQuery</li> <li>Google Secret Manager</li> </ul> </li> </ul>"},{"location":"visjon/brukerforventninger/#oppsummering","title":"Oppsummering","text":"<p>Hvis du har lyst til \u00e5 raskt komme i gang med</p> <ul> <li>\u00e5 lage et dataprodukt s\u00e5 har vi flere oppskrifter basert p\u00e5 hvor datakilden er.</li> <li>utforskende analyse av dine on-prem datakilder, s\u00e5 anbefaler vi at du starter med en Jupyter notebook i Knada.</li> <li>utforskende analyse av data i skyen, s\u00e5 anbefaler vi Managed notebook i GCP.</li> <li>utforskende analyse av data i skyen n\u00e5r du ikke kan python, s\u00e5 anbefaler vi Metabase</li> <li>dele tilgangsstyrte eller \u00e5pne dashboard med interaktivitet, s\u00e5 anbefaler vi Metabase.</li> <li>dele analyserapporter s\u00e5 b\u00f8r du starte med Quarto, og publisere den p\u00e5 Datamarkedsplassen.</li> </ul>"},{"location":"visjon/data_mesh/","title":"Data mesh","text":"<p>Vi \u00f8nsker \u00e5 flytte ansvaret for produktutvikling av data til produktteamene, slik det er beskrevet i data mesh-paradigmet. For at dette skal lykkes, f\u00f8lger vi de fire prinsippene beskrevet:</p>"},{"location":"visjon/data_mesh/#i-data-som-produkt","title":"I: Data som produkt","text":"<p>For at data skal kunne brukes til \u00e5 l\u00f8se NAVs samfunnsoppdrag p\u00e5 en bedre m\u00e5te, m\u00e5 dataene v\u00e6re tilpasset behovene. Teamene m\u00e5 derfor bruke erfaringen med produktutviklingen fra den operasjonelle verden over p\u00e5 data. Dataproduktene m\u00e5 v\u00e6re mulig \u00e5:</p> <ul> <li>...finne</li> <li>...forst\u00e5</li> <li>...stole p\u00e5</li> <li>...koble sammen</li> <li>...innhente</li> <li>...bruke p\u00e5 en sikker m\u00e5te</li> </ul> <p>P\u00e5 en m\u00e5te som svarer til behov. For eksempel vil et dataprodukt som kun brukes internt i et team gi verdi uten at det n\u00f8dvendigvis er veldig godt dokumentert. Produkutviklingen gj\u00f8r at produktteamene klarer \u00e5 tilpasse dataproduktene til behovene.</p>"},{"location":"visjon/data_mesh/#ii-domene-orientert-eierskap-til-data","title":"II: Domene-orientert eierskap til data","text":"<p>Eierskapet til data b\u00f8r v\u00e6re plassert s\u00e5 n\u00e6rt kilden som mulig.  Dette skyldes skyldes b\u00e5de at produktteamene har inng\u00e5ende kjenskap til \u00e5 tilpasse produktet og at dette er en l\u00f8sning som skalerer. I NAV er vi s\u00e5 heldige at vi allerede er organisert i produktteam. P\u00e5 data-omr\u00e5det vil vi i st\u00f8rst mulig grad etterstrebe \u00e5 f\u00f8lge denne modellen. Samtidig ser vi at det vil v\u00e6re behov for f.eks. egne data-team som aggreger data fra flere produktteam.</p>"},{"location":"visjon/data_mesh/#iii-selvbetjent-dataplattform","title":"III: Selvbetjent dataplattform","text":"<p>Skiftet vekk fra en sentralisert modell for produksjon av data flytter mye ansvar og arbeid over p\u00e5 produktteamene. Mye av arbeidet vil v\u00e6re spesifikt for de forskjellige produktteamene. Samtidig vil det v\u00e6re en del aktivitet som er felles for alle. Deployment og overv\u00e5king av dataprodukter, registrering av dataprodukter i en s\u00f8kbar katalog og tilgangskontroller er eksempler p\u00e5 dette. For \u00e5 redusere byrden p\u00e5 teamene og samtidig gj\u00f8re det enklere for brukerne \u00e5 konsumere data, m\u00e5 det etableres en plattform som dekker dette.</p> <p>Dokumentasjonen handler om denne plattformen.</p>"},{"location":"visjon/data_mesh/#iv-desentralisert-dataforvaltning","title":"IV: Desentralisert dataforvaltning","text":"<p>Vi har en grunnleggende tro p\u00e5 at produktteamene selv er best rustet til \u00e5 ta valg for \u00e5 tilby gode dataprodukter. Vi erkjenner likevel at det oppst\u00e5r situasjoner der teams tilpasninger ikke er optimale. Dette kan v\u00e6re bevisste valg, der teamenes incentiver ikke harmonerer med organisasjonens. Det kan ogs\u00e5 v\u00e6re ubevisste valg, enten som f\u00f8lge av mangel p\u00e5 koordinering eller spesifikk kompetanse.</p> <p>For \u00e5 korrigere for dette, har vi spilleregler p\u00e5 plattformen. Disse utformes av akt\u00f8rer p\u00e5 plattformen i fellesskap. Implementeringen av disse skal i st\u00f8rst mulig grad st\u00f8ttes i plattformen.</p>"}]}